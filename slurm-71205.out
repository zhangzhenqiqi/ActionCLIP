Loading cudnn7.6-cuda10.2/7.6.5.32
  Loading requirement: cuda10.2/toolkit/10.2.89
Loading nccl2-cuda10.2-gcc/2.6.4
  Loading requirement: gcc5/5.5.0
ActionClip boot~
<string>:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
<string>:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
<string>:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
/home/10501001/projects/ActionCLIP/train.py:53: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  config = yaml.load(f)
wandb: Currently logged in as: wozzq (use `wandb login --relogin` to force relogin)
wandb: Tracking run with wandb version 0.12.4
wandb: Syncing run 20211019_194518_clip_ucf_RN50_ucf101
wandb:  View project at https://wandb.ai/wozzq/clip_ucf
wandb:  View run at https://wandb.ai/wozzq/clip_ucf/runs/pdx9bt8l
wandb: Run data is saved locally in /home/10501001/projects/ActionCLIP/wandb/run-20211019_194635-pdx9bt8l
wandb: Run `wandb offline` to turn off syncing.

--------------------------------------------------------------------------------
                     working dir: ./exp/clip_ucf/RN50/ucf101/20211019_194518
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
                               Config
{   'data': {   'batch_size': 32,
                'dataset': 'ucf101',
                'gpus': 2,
                'image_tmpl': 'img_{:05d}.jpg',
                'index_bias': 1,
                'input_size': 224,
                'label_list': 'lists/ucf_labels.csv',
                'modality': 'RGB',
                'num_classes': 101,
                'num_segments': 8,
                'randaug': {'M': 0, 'N': 0},
                'seg_length': 1,
                'split': 1,
                'train_list': '/home/10501001/datasets/ucf101/ucfTrainTestlist/train_rgb_split1.txt',
                'val_list': '/home/10501001/datasets/ucf101/ucfTrainTestlist/val_rgb_split1.txt',
                'workers': 8},
    'logging': {'eval_freq': 1, 'print_freq': 10},
    'network': {   'arch': 'RN50',
                   'describe': None,
                   'drop_out': 0.0,
                   'emb_dropout': 0.0,
                   'fix_img': False,
                   'fix_text': False,
                   'init': False,
                   'sim_header': 'Transf',
                   'type': 'clip_ucf'},
    'resume': None,
    'seed': 1024,
    'solver': {   'clip_gradient': 20,
                  'epoch_offset': 0,
                  'epochs': 100,
                  'evaluate': False,
                  'f_ratio': 10,
                  'loss_type': 'nll',
                  'lr': 5e-06,
                  'lr_decay_factor': 0.1,
                  'lr_decay_step': 15,
                  'lr_warmup_step': 5,
                  'momentum': 0.9,
                  'optim': 'adamw',
                  'ratio': 1,
                  'start_epoch': 0,
                  'type': 'cosine',
                  'weight_decay': 0.2}}
--------------------------------------------------------------------------------
dropout used:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Adding action...
params in make_temporal_shift: 
n_segment:  8
n_div:  8
place:  blockres
temporal_pool:  False
=> n_segment per stage: [8, 8, 8, 8]
=> Processing stage with 3 blocks residual
SA:  1644167168
8
64
=> Using ACTION
SA:  26306674688
8
256
=> Using ACTION
SA:  26306674688
8
256
=> Using ACTION
=> Processing stage with 4 blocks residual
SA:  26306674688
8
256
=> Using ACTION
SA:  105226698752
8
512
=> Using ACTION
SA:  105226698752
8
512
=> Using ACTION
SA:  105226698752
8
512
=> Using ACTION
=> Processing stage with 6 blocks residual
SA:  105226698752
8
512
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
=> Processing stage with 3 blocks residual
SA:  420906795008
8
1024
=> Using ACTION
SA:  1683627180032
8
2048
=> Using ACTION
SA:  1683627180032
8
2048
=> Using ACTION
not using full clip pretrained model, only visual!
train transforms: [Compose(
    <datasets.transforms_ss.GroupMultiScaleCrop object at 0x2aab4a182610>
    <datasets.transforms_ss.GroupRandomHorizontalFlip object at 0x2aab4a182fd0>
    <datasets.transforms_ss.GroupRandomColorJitter object at 0x2aab4a182f70>
    <datasets.transforms_ss.GroupRandomGrayscale object at 0x2aab4a182f40>
    <datasets.transforms_ss.GroupGaussianBlur object at 0x2aab4a182e50>
    <datasets.transforms_ss.GroupSolarization object at 0x2aab4a182df0>
), Compose(
    <datasets.transforms_ss.Stack object at 0x2aab4a182d00>
    <datasets.transforms_ss.ToTorchFormatTensor object at 0x2aab4a182ca0>
    <datasets.transforms_ss.GroupNormalize object at 0x2aab4a182c40>
)]
val transforms: [Compose(
    <datasets.transforms_ss.GroupScale object at 0x2aab4a182ac0>
    <datasets.transforms_ss.GroupCenterCrop object at 0x2aab4a182a60>
), Compose(
    <datasets.transforms_ss.Stack object at 0x2aab4a1828e0>
    <datasets.transforms_ss.ToTorchFormatTensor object at 0x2aab4a182880>
    <datasets.transforms_ss.GroupNormalize object at 0x2aab4a182820>
)]
layer=6
model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=
CLIP(
  (visual): ModifiedResNet(
    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (relu): ReLU(inplace=True)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Action(
          (net): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(4, 4, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)
          (action_p3_expand): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Action(
          (net): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
          (action_p3_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Action(
          (net): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
          (action_p3_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Action(
          (net): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
          (action_p3_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Action(
          (net): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (action_p3_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Action(
          (net): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (action_p3_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Action(
          (net): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (action_p3_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Action(
          (net): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (action_p3_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Action(
          (net): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,), groups=2048, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (action_p3_expand): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Action(
          (net): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,), groups=2048, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (action_p3_expand): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (attnpool): AttentionPool2d(
      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)
    )
  )
  (transformer): Transformer(
    (resblocks): Sequential(
      (0): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (6): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (7): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (8): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (9): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (10): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (11): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (token_embedding): Embedding(49408, 512)
  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.0, inplace=False)
)
fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=
DataParallel(
  (module): visual_prompt(
    (frame_position_embeddings): Embedding(77, 1024)
    (transformer): TemporalTransformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
      )
    )
  )
)
random_shift:DotMap()
random_shift:DotMap()
=========using KL Loss=and has temperature and * bz==========
=========using KL Loss=and has temperature and * bz==========
5e-06
5e-06
5e-05
AdamW
positional_embedding: True
text_projection: True
logit_scale: True
visual.conv1.weight: True
visual.bn1.weight: True
visual.bn1.bias: True
visual.conv2.weight: True
visual.bn2.weight: True
visual.bn2.bias: True
visual.conv3.weight: True
visual.bn3.weight: True
visual.bn3.bias: True
visual.layer1.0.conv1.net.weight: True
visual.layer1.0.conv1.action_shift.weight: True
visual.layer1.0.conv1.action_p1_conv1.weight: True
visual.layer1.0.conv1.action_p2_squeeze.weight: True
visual.layer1.0.conv1.action_p2_conv1.weight: True
visual.layer1.0.conv1.action_p2_expand.weight: True
visual.layer1.0.conv1.action_p3_squeeze.weight: True
visual.layer1.0.conv1.action_p3_bn1.weight: True
visual.layer1.0.conv1.action_p3_bn1.bias: True
visual.layer1.0.conv1.action_p3_conv1.weight: True
visual.layer1.0.conv1.action_p3_expand.weight: True
visual.layer1.0.bn1.weight: True
visual.layer1.0.bn1.bias: True
visual.layer1.0.conv2.weight: True
visual.layer1.0.bn2.weight: True
visual.layer1.0.bn2.bias: True
visual.layer1.0.conv3.weight: True
visual.layer1.0.bn3.weight: True
visual.layer1.0.bn3.bias: True
visual.layer1.0.downsample.0.weight: True
visual.layer1.0.downsample.1.weight: True
visual.layer1.0.downsample.1.bias: True
visual.layer1.1.conv1.net.weight: True
visual.layer1.1.conv1.action_shift.weight: True
visual.layer1.1.conv1.action_p1_conv1.weight: True
visual.layer1.1.conv1.action_p2_squeeze.weight: True
visual.layer1.1.conv1.action_p2_conv1.weight: True
visual.layer1.1.conv1.action_p2_expand.weight: True
visual.layer1.1.conv1.action_p3_squeeze.weight: True
visual.layer1.1.conv1.action_p3_bn1.weight: True
visual.layer1.1.conv1.action_p3_bn1.bias: True
visual.layer1.1.conv1.action_p3_conv1.weight: True
visual.layer1.1.conv1.action_p3_expand.weight: True
visual.layer1.1.bn1.weight: True
visual.layer1.1.bn1.bias: True
visual.layer1.1.conv2.weight: True
visual.layer1.1.bn2.weight: True
visual.layer1.1.bn2.bias: True
visual.layer1.1.conv3.weight: True
visual.layer1.1.bn3.weight: True
visual.layer1.1.bn3.bias: True
visual.layer1.2.conv1.net.weight: True
visual.layer1.2.conv1.action_shift.weight: True
visual.layer1.2.conv1.action_p1_conv1.weight: True
visual.layer1.2.conv1.action_p2_squeeze.weight: True
visual.layer1.2.conv1.action_p2_conv1.weight: True
visual.layer1.2.conv1.action_p2_expand.weight: True
visual.layer1.2.conv1.action_p3_squeeze.weight: True
visual.layer1.2.conv1.action_p3_bn1.weight: True
visual.layer1.2.conv1.action_p3_bn1.bias: True
visual.layer1.2.conv1.action_p3_conv1.weight: True
visual.layer1.2.conv1.action_p3_expand.weight: True
visual.layer1.2.bn1.weight: True
visual.layer1.2.bn1.bias: True
visual.layer1.2.conv2.weight: True
visual.layer1.2.bn2.weight: True
visual.layer1.2.bn2.bias: True
visual.layer1.2.conv3.weight: True
visual.layer1.2.bn3.weight: True
visual.layer1.2.bn3.bias: True
visual.layer2.0.conv1.net.weight: True
visual.layer2.0.conv1.action_shift.weight: True
visual.layer2.0.conv1.action_p1_conv1.weight: True
visual.layer2.0.conv1.action_p2_squeeze.weight: True
visual.layer2.0.conv1.action_p2_conv1.weight: True
visual.layer2.0.conv1.action_p2_expand.weight: True
visual.layer2.0.conv1.action_p3_squeeze.weight: True
visual.layer2.0.conv1.action_p3_bn1.weight: True
visual.layer2.0.conv1.action_p3_bn1.bias: True
visual.layer2.0.conv1.action_p3_conv1.weight: True
visual.layer2.0.conv1.action_p3_expand.weight: True
visual.layer2.0.bn1.weight: True
visual.layer2.0.bn1.bias: True
visual.layer2.0.conv2.weight: True
visual.layer2.0.bn2.weight: True
visual.layer2.0.bn2.bias: True
visual.layer2.0.conv3.weight: True
visual.layer2.0.bn3.weight: True
visual.layer2.0.bn3.bias: True
visual.layer2.0.downsample.0.weight: True
visual.layer2.0.downsample.1.weight: True
visual.layer2.0.downsample.1.bias: True
visual.layer2.1.conv1.net.weight: True
visual.layer2.1.conv1.action_shift.weight: True
visual.layer2.1.conv1.action_p1_conv1.weight: True
visual.layer2.1.conv1.action_p2_squeeze.weight: True
visual.layer2.1.conv1.action_p2_conv1.weight: True
visual.layer2.1.conv1.action_p2_expand.weight: True
visual.layer2.1.conv1.action_p3_squeeze.weight: True
visual.layer2.1.conv1.action_p3_bn1.weight: True
visual.layer2.1.conv1.action_p3_bn1.bias: True
visual.layer2.1.conv1.action_p3_conv1.weight: True
visual.layer2.1.conv1.action_p3_expand.weight: True
visual.layer2.1.bn1.weight: True
visual.layer2.1.bn1.bias: True
visual.layer2.1.conv2.weight: True
visual.layer2.1.bn2.weight: True
visual.layer2.1.bn2.bias: True
visual.layer2.1.conv3.weight: True
visual.layer2.1.bn3.weight: True
visual.layer2.1.bn3.bias: True
visual.layer2.2.conv1.net.weight: True
visual.layer2.2.conv1.action_shift.weight: True
visual.layer2.2.conv1.action_p1_conv1.weight: True
visual.layer2.2.conv1.action_p2_squeeze.weight: True
visual.layer2.2.conv1.action_p2_conv1.weight: True
visual.layer2.2.conv1.action_p2_expand.weight: True
visual.layer2.2.conv1.action_p3_squeeze.weight: True
visual.layer2.2.conv1.action_p3_bn1.weight: True
visual.layer2.2.conv1.action_p3_bn1.bias: True
visual.layer2.2.conv1.action_p3_conv1.weight: True
visual.layer2.2.conv1.action_p3_expand.weight: True
visual.layer2.2.bn1.weight: True
visual.layer2.2.bn1.bias: True
visual.layer2.2.conv2.weight: True
visual.layer2.2.bn2.weight: True
visual.layer2.2.bn2.bias: True
visual.layer2.2.conv3.weight: True
visual.layer2.2.bn3.weight: True
visual.layer2.2.bn3.bias: True
visual.layer2.3.conv1.net.weight: True
visual.layer2.3.conv1.action_shift.weight: True
visual.layer2.3.conv1.action_p1_conv1.weight: True
visual.layer2.3.conv1.action_p2_squeeze.weight: True
visual.layer2.3.conv1.action_p2_conv1.weight: True
visual.layer2.3.conv1.action_p2_expand.weight: True
visual.layer2.3.conv1.action_p3_squeeze.weight: True
visual.layer2.3.conv1.action_p3_bn1.weight: True
visual.layer2.3.conv1.action_p3_bn1.bias: True
visual.layer2.3.conv1.action_p3_conv1.weight: True
visual.layer2.3.conv1.action_p3_expand.weight: True
visual.layer2.3.bn1.weight: True
visual.layer2.3.bn1.bias: True
visual.layer2.3.conv2.weight: True
visual.layer2.3.bn2.weight: True
visual.layer2.3.bn2.bias: True
visual.layer2.3.conv3.weight: True
visual.layer2.3.bn3.weight: True
visual.layer2.3.bn3.bias: True
visual.layer3.0.conv1.net.weight: True
visual.layer3.0.conv1.action_shift.weight: True
visual.layer3.0.conv1.action_p1_conv1.weight: True
visual.layer3.0.conv1.action_p2_squeeze.weight: True
visual.layer3.0.conv1.action_p2_conv1.weight: True
visual.layer3.0.conv1.action_p2_expand.weight: True
visual.layer3.0.conv1.action_p3_squeeze.weight: True
visual.layer3.0.conv1.action_p3_bn1.weight: True
visual.layer3.0.conv1.action_p3_bn1.bias: True
visual.layer3.0.conv1.action_p3_conv1.weight: True
visual.layer3.0.conv1.action_p3_expand.weight: True
visual.layer3.0.bn1.weight: True
visual.layer3.0.bn1.bias: True
visual.layer3.0.conv2.weight: True
visual.layer3.0.bn2.weight: True
visual.layer3.0.bn2.bias: True
visual.layer3.0.conv3.weight: True
visual.layer3.0.bn3.weight: True
visual.layer3.0.bn3.bias: True
visual.layer3.0.downsample.0.weight: True
visual.layer3.0.downsample.1.weight: True
visual.layer3.0.downsample.1.bias: True
visual.layer3.1.conv1.net.weight: True
visual.layer3.1.conv1.action_shift.weight: True
visual.layer3.1.conv1.action_p1_conv1.weight: True
visual.layer3.1.conv1.action_p2_squeeze.weight: True
visual.layer3.1.conv1.action_p2_conv1.weight: True
visual.layer3.1.conv1.action_p2_expand.weight: True
visual.layer3.1.conv1.action_p3_squeeze.weight: True
visual.layer3.1.conv1.action_p3_bn1.weight: True
visual.layer3.1.conv1.action_p3_bn1.bias: True
visual.layer3.1.conv1.action_p3_conv1.weight: True
visual.layer3.1.conv1.action_p3_expand.weight: True
visual.layer3.1.bn1.weight: True
visual.layer3.1.bn1.bias: True
visual.layer3.1.conv2.weight: True
visual.layer3.1.bn2.weight: True
visual.layer3.1.bn2.bias: True
visual.layer3.1.conv3.weight: True
visual.layer3.1.bn3.weight: True
visual.layer3.1.bn3.bias: True
visual.layer3.2.conv1.net.weight: True
visual.layer3.2.conv1.action_shift.weight: True
visual.layer3.2.conv1.action_p1_conv1.weight: True
visual.layer3.2.conv1.action_p2_squeeze.weight: True
visual.layer3.2.conv1.action_p2_conv1.weight: True
visual.layer3.2.conv1.action_p2_expand.weight: True
visual.layer3.2.conv1.action_p3_squeeze.weight: True
visual.layer3.2.conv1.action_p3_bn1.weight: True
visual.layer3.2.conv1.action_p3_bn1.bias: True
visual.layer3.2.conv1.action_p3_conv1.weight: True
visual.layer3.2.conv1.action_p3_expand.weight: True
visual.layer3.2.bn1.weight: True
visual.layer3.2.bn1.bias: True
visual.layer3.2.conv2.weight: True
visual.layer3.2.bn2.weight: True
visual.layer3.2.bn2.bias: True
visual.layer3.2.conv3.weight: True
visual.layer3.2.bn3.weight: True
visual.layer3.2.bn3.bias: True
visual.layer3.3.conv1.net.weight: True
visual.layer3.3.conv1.action_shift.weight: True
visual.layer3.3.conv1.action_p1_conv1.weight: True
visual.layer3.3.conv1.action_p2_squeeze.weight: True
visual.layer3.3.conv1.action_p2_conv1.weight: True
visual.layer3.3.conv1.action_p2_expand.weight: True
visual.layer3.3.conv1.action_p3_squeeze.weight: True
visual.layer3.3.conv1.action_p3_bn1.weight: True
visual.layer3.3.conv1.action_p3_bn1.bias: True
visual.layer3.3.conv1.action_p3_conv1.weight: True
visual.layer3.3.conv1.action_p3_expand.weight: True
visual.layer3.3.bn1.weight: True
visual.layer3.3.bn1.bias: True
visual.layer3.3.conv2.weight: True
visual.layer3.3.bn2.weight: True
visual.layer3.3.bn2.bias: True
visual.layer3.3.conv3.weight: True
visual.layer3.3.bn3.weight: True
visual.layer3.3.bn3.bias: True
visual.layer3.4.conv1.net.weight: True
visual.layer3.4.conv1.action_shift.weight: True
visual.layer3.4.conv1.action_p1_conv1.weight: True
visual.layer3.4.conv1.action_p2_squeeze.weight: True
visual.layer3.4.conv1.action_p2_conv1.weight: True
visual.layer3.4.conv1.action_p2_expand.weight: True
visual.layer3.4.conv1.action_p3_squeeze.weight: True
visual.layer3.4.conv1.action_p3_bn1.weight: True
visual.layer3.4.conv1.action_p3_bn1.bias: True
visual.layer3.4.conv1.action_p3_conv1.weight: True
visual.layer3.4.conv1.action_p3_expand.weight: True
visual.layer3.4.bn1.weight: True
visual.layer3.4.bn1.bias: True
visual.layer3.4.conv2.weight: True
visual.layer3.4.bn2.weight: True
visual.layer3.4.bn2.bias: True
visual.layer3.4.conv3.weight: True
visual.layer3.4.bn3.weight: True
visual.layer3.4.bn3.bias: True
visual.layer3.5.conv1.net.weight: True
visual.layer3.5.conv1.action_shift.weight: True
visual.layer3.5.conv1.action_p1_conv1.weight: True
visual.layer3.5.conv1.action_p2_squeeze.weight: True
visual.layer3.5.conv1.action_p2_conv1.weight: True
visual.layer3.5.conv1.action_p2_expand.weight: True
visual.layer3.5.conv1.action_p3_squeeze.weight: True
visual.layer3.5.conv1.action_p3_bn1.weight: True
visual.layer3.5.conv1.action_p3_bn1.bias: True
visual.layer3.5.conv1.action_p3_conv1.weight: True
visual.layer3.5.conv1.action_p3_expand.weight: True
visual.layer3.5.bn1.weight: True
visual.layer3.5.bn1.bias: True
visual.layer3.5.conv2.weight: True
visual.layer3.5.bn2.weight: True
visual.layer3.5.bn2.bias: True
visual.layer3.5.conv3.weight: True
visual.layer3.5.bn3.weight: True
visual.layer3.5.bn3.bias: True
visual.layer4.0.conv1.net.weight: True
visual.layer4.0.conv1.action_shift.weight: True
visual.layer4.0.conv1.action_p1_conv1.weight: True
visual.layer4.0.conv1.action_p2_squeeze.weight: True
visual.layer4.0.conv1.action_p2_conv1.weight: True
visual.layer4.0.conv1.action_p2_expand.weight: True
visual.layer4.0.conv1.action_p3_squeeze.weight: True
visual.layer4.0.conv1.action_p3_bn1.weight: True
visual.layer4.0.conv1.action_p3_bn1.bias: True
visual.layer4.0.conv1.action_p3_conv1.weight: True
visual.layer4.0.conv1.action_p3_expand.weight: True
visual.layer4.0.bn1.weight: True
visual.layer4.0.bn1.bias: True
visual.layer4.0.conv2.weight: True
visual.layer4.0.bn2.weight: True
visual.layer4.0.bn2.bias: True
visual.layer4.0.conv3.weight: True
visual.layer4.0.bn3.weight: True
visual.layer4.0.bn3.bias: True
visual.layer4.0.downsample.0.weight: True
visual.layer4.0.downsample.1.weight: True
visual.layer4.0.downsample.1.bias: True
visual.layer4.1.conv1.net.weight: True
visual.layer4.1.conv1.action_shift.weight: True
visual.layer4.1.conv1.action_p1_conv1.weight: True
visual.layer4.1.conv1.action_p2_squeeze.weight: True
visual.layer4.1.conv1.action_p2_conv1.weight: True
visual.layer4.1.conv1.action_p2_expand.weight: True
visual.layer4.1.conv1.action_p3_squeeze.weight: True
visual.layer4.1.conv1.action_p3_bn1.weight: True
visual.layer4.1.conv1.action_p3_bn1.bias: True
visual.layer4.1.conv1.action_p3_conv1.weight: True
visual.layer4.1.conv1.action_p3_expand.weight: True
visual.layer4.1.bn1.weight: True
visual.layer4.1.bn1.bias: True
visual.layer4.1.conv2.weight: True
visual.layer4.1.bn2.weight: True
visual.layer4.1.bn2.bias: True
visual.layer4.1.conv3.weight: True
visual.layer4.1.bn3.weight: True
visual.layer4.1.bn3.bias: True
visual.layer4.2.conv1.net.weight: True
visual.layer4.2.conv1.action_shift.weight: True
visual.layer4.2.conv1.action_p1_conv1.weight: True
visual.layer4.2.conv1.action_p2_squeeze.weight: True
visual.layer4.2.conv1.action_p2_conv1.weight: True
visual.layer4.2.conv1.action_p2_expand.weight: True
visual.layer4.2.conv1.action_p3_squeeze.weight: True
visual.layer4.2.conv1.action_p3_bn1.weight: True
visual.layer4.2.conv1.action_p3_bn1.bias: True
visual.layer4.2.conv1.action_p3_conv1.weight: True
visual.layer4.2.conv1.action_p3_expand.weight: True
visual.layer4.2.bn1.weight: True
visual.layer4.2.bn1.bias: True
visual.layer4.2.conv2.weight: True
visual.layer4.2.bn2.weight: True
visual.layer4.2.bn2.bias: True
visual.layer4.2.conv3.weight: True
visual.layer4.2.bn3.weight: True
visual.layer4.2.bn3.bias: True
visual.attnpool.positional_embedding: True
visual.attnpool.k_proj.weight: True
visual.attnpool.k_proj.bias: True
visual.attnpool.q_proj.weight: True
visual.attnpool.q_proj.bias: True
visual.attnpool.v_proj.weight: True
visual.attnpool.v_proj.bias: True
visual.attnpool.c_proj.weight: True
visual.attnpool.c_proj.bias: True
transformer.resblocks.0.attn.in_proj_weight: True
transformer.resblocks.0.attn.in_proj_bias: True
transformer.resblocks.0.attn.out_proj.weight: True
transformer.resblocks.0.attn.out_proj.bias: True
transformer.resblocks.0.ln_1.weight: True
transformer.resblocks.0.ln_1.bias: True
transformer.resblocks.0.mlp.c_fc.weight: True
transformer.resblocks.0.mlp.c_fc.bias: True
transformer.resblocks.0.mlp.c_proj.weight: True
transformer.resblocks.0.mlp.c_proj.bias: True
transformer.resblocks.0.ln_2.weight: True
transformer.resblocks.0.ln_2.bias: True
transformer.resblocks.1.attn.in_proj_weight: True
transformer.resblocks.1.attn.in_proj_bias: True
transformer.resblocks.1.attn.out_proj.weight: True
transformer.resblocks.1.attn.out_proj.bias: True
transformer.resblocks.1.ln_1.weight: True
transformer.resblocks.1.ln_1.bias: True
transformer.resblocks.1.mlp.c_fc.weight: True
transformer.resblocks.1.mlp.c_fc.bias: True
transformer.resblocks.1.mlp.c_proj.weight: True
transformer.resblocks.1.mlp.c_proj.bias: True
transformer.resblocks.1.ln_2.weight: True
transformer.resblocks.1.ln_2.bias: True
transformer.resblocks.2.attn.in_proj_weight: True
transformer.resblocks.2.attn.in_proj_bias: True
transformer.resblocks.2.attn.out_proj.weight: True
transformer.resblocks.2.attn.out_proj.bias: True
transformer.resblocks.2.ln_1.weight: True
transformer.resblocks.2.ln_1.bias: True
transformer.resblocks.2.mlp.c_fc.weight: True
transformer.resblocks.2.mlp.c_fc.bias: True
transformer.resblocks.2.mlp.c_proj.weight: True
transformer.resblocks.2.mlp.c_proj.bias: True
transformer.resblocks.2.ln_2.weight: True
transformer.resblocks.2.ln_2.bias: True
transformer.resblocks.3.attn.in_proj_weight: True
transformer.resblocks.3.attn.in_proj_bias: True
transformer.resblocks.3.attn.out_proj.weight: True
transformer.resblocks.3.attn.out_proj.bias: True
transformer.resblocks.3.ln_1.weight: True
transformer.resblocks.3.ln_1.bias: True
transformer.resblocks.3.mlp.c_fc.weight: True
transformer.resblocks.3.mlp.c_fc.bias: True
transformer.resblocks.3.mlp.c_proj.weight: True
transformer.resblocks.3.mlp.c_proj.bias: True
transformer.resblocks.3.ln_2.weight: True
transformer.resblocks.3.ln_2.bias: True
transformer.resblocks.4.attn.in_proj_weight: True
transformer.resblocks.4.attn.in_proj_bias: True
transformer.resblocks.4.attn.out_proj.weight: True
transformer.resblocks.4.attn.out_proj.bias: True
transformer.resblocks.4.ln_1.weight: True
transformer.resblocks.4.ln_1.bias: True
transformer.resblocks.4.mlp.c_fc.weight: True
transformer.resblocks.4.mlp.c_fc.bias: True
transformer.resblocks.4.mlp.c_proj.weight: True
transformer.resblocks.4.mlp.c_proj.bias: True
transformer.resblocks.4.ln_2.weight: True
transformer.resblocks.4.ln_2.bias: True
transformer.resblocks.5.attn.in_proj_weight: True
transformer.resblocks.5.attn.in_proj_bias: True
transformer.resblocks.5.attn.out_proj.weight: True
transformer.resblocks.5.attn.out_proj.bias: True
transformer.resblocks.5.ln_1.weight: True
transformer.resblocks.5.ln_1.bias: True
transformer.resblocks.5.mlp.c_fc.weight: True
transformer.resblocks.5.mlp.c_fc.bias: True
transformer.resblocks.5.mlp.c_proj.weight: True
transformer.resblocks.5.mlp.c_proj.bias: True
transformer.resblocks.5.ln_2.weight: True
transformer.resblocks.5.ln_2.bias: True
transformer.resblocks.6.attn.in_proj_weight: True
transformer.resblocks.6.attn.in_proj_bias: True
transformer.resblocks.6.attn.out_proj.weight: True
transformer.resblocks.6.attn.out_proj.bias: True
transformer.resblocks.6.ln_1.weight: True
transformer.resblocks.6.ln_1.bias: True
transformer.resblocks.6.mlp.c_fc.weight: True
transformer.resblocks.6.mlp.c_fc.bias: True
transformer.resblocks.6.mlp.c_proj.weight: True
transformer.resblocks.6.mlp.c_proj.bias: True
transformer.resblocks.6.ln_2.weight: True
transformer.resblocks.6.ln_2.bias: True
transformer.resblocks.7.attn.in_proj_weight: True
transformer.resblocks.7.attn.in_proj_bias: True
transformer.resblocks.7.attn.out_proj.weight: True
transformer.resblocks.7.attn.out_proj.bias: True
transformer.resblocks.7.ln_1.weight: True
transformer.resblocks.7.ln_1.bias: True
transformer.resblocks.7.mlp.c_fc.weight: True
transformer.resblocks.7.mlp.c_fc.bias: True
transformer.resblocks.7.mlp.c_proj.weight: True
transformer.resblocks.7.mlp.c_proj.bias: True
transformer.resblocks.7.ln_2.weight: True
transformer.resblocks.7.ln_2.bias: True
transformer.resblocks.8.attn.in_proj_weight: True
transformer.resblocks.8.attn.in_proj_bias: True
transformer.resblocks.8.attn.out_proj.weight: True
transformer.resblocks.8.attn.out_proj.bias: True
transformer.resblocks.8.ln_1.weight: True
transformer.resblocks.8.ln_1.bias: True
transformer.resblocks.8.mlp.c_fc.weight: True
transformer.resblocks.8.mlp.c_fc.bias: True
transformer.resblocks.8.mlp.c_proj.weight: True
transformer.resblocks.8.mlp.c_proj.bias: True
transformer.resblocks.8.ln_2.weight: True
transformer.resblocks.8.ln_2.bias: True
transformer.resblocks.9.attn.in_proj_weight: True
transformer.resblocks.9.attn.in_proj_bias: True
transformer.resblocks.9.attn.out_proj.weight: True
transformer.resblocks.9.attn.out_proj.bias: True
transformer.resblocks.9.ln_1.weight: True
transformer.resblocks.9.ln_1.bias: True
transformer.resblocks.9.mlp.c_fc.weight: True
transformer.resblocks.9.mlp.c_fc.bias: True
transformer.resblocks.9.mlp.c_proj.weight: True
transformer.resblocks.9.mlp.c_proj.bias: True
transformer.resblocks.9.ln_2.weight: True
transformer.resblocks.9.ln_2.bias: True
transformer.resblocks.10.attn.in_proj_weight: True
transformer.resblocks.10.attn.in_proj_bias: True
transformer.resblocks.10.attn.out_proj.weight: True
transformer.resblocks.10.attn.out_proj.bias: True
transformer.resblocks.10.ln_1.weight: True
transformer.resblocks.10.ln_1.bias: True
transformer.resblocks.10.mlp.c_fc.weight: True
transformer.resblocks.10.mlp.c_fc.bias: True
transformer.resblocks.10.mlp.c_proj.weight: True
transformer.resblocks.10.mlp.c_proj.bias: True
transformer.resblocks.10.ln_2.weight: True
transformer.resblocks.10.ln_2.bias: True
transformer.resblocks.11.attn.in_proj_weight: True
transformer.resblocks.11.attn.in_proj_bias: True
transformer.resblocks.11.attn.out_proj.weight: True
transformer.resblocks.11.attn.out_proj.bias: True
transformer.resblocks.11.ln_1.weight: True
transformer.resblocks.11.ln_1.bias: True
transformer.resblocks.11.mlp.c_fc.weight: True
transformer.resblocks.11.mlp.c_fc.bias: True
transformer.resblocks.11.mlp.c_proj.weight: True
transformer.resblocks.11.mlp.c_proj.bias: True
transformer.resblocks.11.ln_2.weight: True
transformer.resblocks.11.ln_2.bias: True
token_embedding.weight: True
ln_final.weight: True
ln_final.bias: True
  0% 0/298 [00:00<?, ?it/s]/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
  0% 0/298 [00:16<?, ?it/s]
Traceback (most recent call last):
  File "/home/10501001/projects/ActionCLIP/train.py", line 235, in <module>
    main()
  File "/home/10501001/projects/ActionCLIP/train.py", line 187, in main
    image_embedding = model_image(images)  # (16*8,512)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/_utils.py", line 425, in reraise
    raise self.exc_type(msg)
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/10501001/projects/ActionCLIP/train.py", line 42, in forward
    return self.model.encode_image(image)
  File "/home/10501001/projects/ActionCLIP/clip/model.py", line 417, in encode_image
    ret = self.visual(image.type(self.dtype))
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/10501001/projects/ActionCLIP/clip/model.py", line 295, in forward
    x = self.layer1(x)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/10501001/projects/ActionCLIP/clip/model.py", line 194, in forward
    out = self.relu(self.bn1(self.conv1(x)))
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/10501001/projects/ActionCLIP/ActionNet/action.py", line 123, in forward
    x_p1 = self.action_p1_conv1(x_p1)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 587, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 582, in _conv_forward
    return F.conv3d(
RuntimeError: Input type (torch.cuda.HalfTensor) and weight type (torch.cuda.FloatTensor) should be the same


wandb: Waiting for W&B process to finish, PID 71004... (failed 1). Press ctrl-c to abort syncing.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.07MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.07MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.07MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.07MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.07MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.07MB uploaded (0.00MB deduped)wandb: \ 0.05MB of 0.07MB uploaded (0.00MB deduped)wandb: | 0.07MB of 0.07MB uploaded (0.00MB deduped)wandb: / 0.07MB of 0.07MB uploaded (0.00MB deduped)wandb: - 0.07MB of 0.07MB uploaded (0.00MB deduped)wandb: \ 0.07MB of 0.07MB uploaded (0.00MB deduped)wandb: | 0.07MB of 0.07MB uploaded (0.00MB deduped)wandb: / 0.07MB of 0.07MB uploaded (0.00MB deduped)wandb: - 0.07MB of 0.07MB uploaded (0.00MB deduped)wandb: \ 0.07MB of 0.07MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced 20211019_194518_clip_ucf_RN50_ucf101: https://wandb.ai/wozzq/clip_ucf/runs/pdx9bt8l
wandb: Find logs at: ./wandb/run-20211019_194635-pdx9bt8l/logs/debug.log
wandb: 
