Loading cudnn7.6-cuda10.2/7.6.5.32
  Loading requirement: cuda10.2/toolkit/10.2.89
Loading nccl2-cuda10.2-gcc/2.6.4
  Loading requirement: gcc5/5.5.0
ActionClip boot~
<string>:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
<string>:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
<string>:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
/home/10501001/projects/ActionCLIP/train.py:53: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  config = yaml.load(f)
wandb: Currently logged in as: wozzq (use `wandb login --relogin` to force relogin)
wandb: Tracking run with wandb version 0.12.4
wandb: Syncing run 20211030_104154_clip_k400_RN50_kinetics400
wandb:  View project at https://wandb.ai/wozzq/clip_k400
wandb:  View run at https://wandb.ai/wozzq/clip_k400/runs/x0gyuhws
wandb: Run data is saved locally in /home/10501001/projects/ActionCLIP/wandb/run-20211030_104157-x0gyuhws
wandb: Run `wandb offline` to turn off syncing.

--------------------------------------------------------------------------------
                     working dir: ./exp/clip_k400/RN50/kinetics400/20211030_104154
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
                               Config
{   'data': {   'batch_size': 16,
                'dataset': 'kinetics400',
                'image_tmpl': 'img_{:05d}.jpg',
                'index_bias': 1,
                'input_size': 224,
                'label_list': 'lists/kinetics_400_labels.csv',
                'modality': 'RGB',
                'num_classes': 400,
                'num_segments': 8,
                'randaug': {'M': 9, 'N': 2},
                'random_shift': True,
                'seg_length': 1,
                'train_list': 'lists/k4001/train_frames.txt',
                'val_list': 'lists/k4001/val_frames.txt',
                'workers': 16},
    'logging': {'eval_freq': 1, 'print_freq': 10},
    'network': {   'arch': 'RN50',
                   'describe': None,
                   'drop_out': 0.0,
                   'emb_dropout': 0.0,
                   'init': False,
                   'is_action': True,
                   'joint': False,
                   'sim_header': 'Transf',
                   'tsm': False,
                   'type': 'clip_k400'},
    'pretrain': None,
    'resume': None,
    'seed': 1024,
    'solver': {   'clip_gradient': 20,
                  'epoch_offset': 0,
                  'epochs': 50,
                  'evaluate': False,
                  'f_ratio': 10,
                  'loss_type': 'nll',
                  'lr': 5e-06,
                  'lr_decay_factor': 0.1,
                  'lr_decay_step': 15,
                  'lr_warmup_step': 5,
                  'momentum': 0.9,
                  'optim': 'adamw',
                  'ratio': 1,
                  'start_epoch': 0,
                  'type': 'cosine',
                  'weight_decay': 0.2}}
--------------------------------------------------------------------------------
dropout used:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
not using full clip pretrained model, only visual!
Adding action...
params in make_temporal_shift: 
n_segment:  8
n_div:  8
place:  blockres
temporal_pool:  False
=> n_segment per stage: [8, 8, 8, 8]
=> Processing stage with 3 blocks residual
SA:  1644167168
8
64
=> Using ACTION
SA:  26306674688
8
256
=> Using ACTION
SA:  26306674688
8
256
=> Using ACTION
=> Processing stage with 4 blocks residual
SA:  26306674688
8
256
=> Using ACTION
SA:  105226698752
8
512
=> Using ACTION
SA:  105226698752
8
512
=> Using ACTION
SA:  105226698752
8
512
=> Using ACTION
=> Processing stage with 6 blocks residual
SA:  105226698752
8
512
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
=> Processing stage with 3 blocks residual
SA:  420906795008
8
1024
=> Using ACTION
SA:  1683627180032
8
2048
=> Using ACTION
SA:  1683627180032
8
2048
=> Using ACTION
Using RandAugment!
train transforms: [<utils.Augmentation.GroupTransform object at 0x2aab4a1736a0>, Compose(
    <datasets.transforms_ss.GroupMultiScaleCrop object at 0x2aab4890f6d0>
    <datasets.transforms_ss.GroupRandomHorizontalFlip object at 0x2aab4890f3d0>
    <datasets.transforms_ss.GroupRandomColorJitter object at 0x2aab4a173d30>
    <datasets.transforms_ss.GroupRandomGrayscale object at 0x2aab4a173f70>
    <datasets.transforms_ss.GroupGaussianBlur object at 0x2aab4a173e80>
    <datasets.transforms_ss.GroupSolarization object at 0x2aab4a173e20>
), Compose(
    <datasets.transforms_ss.Stack object at 0x2aab4a173130>
    <datasets.transforms_ss.ToTorchFormatTensor object at 0x2aab4a173d00>
    <datasets.transforms_ss.GroupNormalize object at 0x2aab4a173be0>
)]
val transforms: [Compose(
    <datasets.transforms_ss.GroupScale object at 0x2aab4a1739a0>
    <datasets.transforms_ss.GroupCenterCrop object at 0x2aab4a173a60>
), Compose(
    <datasets.transforms_ss.Stack object at 0x2aab4a1738e0>
    <datasets.transforms_ss.ToTorchFormatTensor object at 0x2aab4a173880>
    <datasets.transforms_ss.GroupNormalize object at 0x2aab4a173700>
)]
layer=6
model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=
CLIP(
  (visual): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Action(
          (net): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(4, 4, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)
          (action_p3_expand): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Action(
          (net): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
          (action_p3_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Action(
          (net): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
          (action_p3_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Action(
          (net): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
          (action_p3_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Action(
          (net): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (action_p3_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Action(
          (net): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (action_p3_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Action(
          (net): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (action_p3_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Action(
          (net): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (action_p3_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Action(
          (net): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,), groups=2048, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (action_p3_expand): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Action(
          (net): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,), groups=2048, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (action_p3_expand): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (transformer): Transformer(
    (resblocks): Sequential(
      (0): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (6): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (7): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (8): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (9): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (10): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (11): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (token_embedding): Embedding(49408, 512)
  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.0, inplace=False)
)
fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=
DataParallel(
  (module): visual_prompt(
    (frame_position_embeddings): Embedding(77, 1024)
    (transformer): TemporalTransformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
      )
    )
  )
)
random_shift:DotMap()
/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
random_shift:DotMap()
=========using KL Loss=and has temperature and * bz==========
=========using KL Loss=and has temperature and * bz==========
5e-06
5e-06
5e-05
AdamW
positional_embedding: True
text_projection: True
logit_scale: True
visual.conv1.weight: True
visual.bn1.weight: True
visual.bn1.bias: True
visual.layer1.0.conv1.net.weight: True
visual.layer1.0.conv1.action_shift.weight: True
visual.layer1.0.conv1.action_p1_conv1.weight: True
visual.layer1.0.conv1.action_p2_squeeze.weight: True
visual.layer1.0.conv1.action_p2_conv1.weight: True
visual.layer1.0.conv1.action_p2_expand.weight: True
visual.layer1.0.conv1.action_p3_squeeze.weight: True
visual.layer1.0.conv1.action_p3_bn1.weight: True
visual.layer1.0.conv1.action_p3_bn1.bias: True
visual.layer1.0.conv1.action_p3_conv1.weight: True
visual.layer1.0.conv1.action_p3_expand.weight: True
visual.layer1.0.bn1.weight: True
visual.layer1.0.bn1.bias: True
visual.layer1.0.conv2.weight: True
visual.layer1.0.bn2.weight: True
visual.layer1.0.bn2.bias: True
visual.layer1.0.conv3.weight: True
visual.layer1.0.bn3.weight: True
visual.layer1.0.bn3.bias: True
visual.layer1.0.downsample.0.weight: True
visual.layer1.0.downsample.1.weight: True
visual.layer1.0.downsample.1.bias: True
visual.layer1.1.conv1.net.weight: True
visual.layer1.1.conv1.action_shift.weight: True
visual.layer1.1.conv1.action_p1_conv1.weight: True
visual.layer1.1.conv1.action_p2_squeeze.weight: True
visual.layer1.1.conv1.action_p2_conv1.weight: True
visual.layer1.1.conv1.action_p2_expand.weight: True
visual.layer1.1.conv1.action_p3_squeeze.weight: True
visual.layer1.1.conv1.action_p3_bn1.weight: True
visual.layer1.1.conv1.action_p3_bn1.bias: True
visual.layer1.1.conv1.action_p3_conv1.weight: True
visual.layer1.1.conv1.action_p3_expand.weight: True
visual.layer1.1.bn1.weight: True
visual.layer1.1.bn1.bias: True
visual.layer1.1.conv2.weight: True
visual.layer1.1.bn2.weight: True
visual.layer1.1.bn2.bias: True
visual.layer1.1.conv3.weight: True
visual.layer1.1.bn3.weight: True
visual.layer1.1.bn3.bias: True
visual.layer1.2.conv1.net.weight: True
visual.layer1.2.conv1.action_shift.weight: True
visual.layer1.2.conv1.action_p1_conv1.weight: True
visual.layer1.2.conv1.action_p2_squeeze.weight: True
visual.layer1.2.conv1.action_p2_conv1.weight: True
visual.layer1.2.conv1.action_p2_expand.weight: True
visual.layer1.2.conv1.action_p3_squeeze.weight: True
visual.layer1.2.conv1.action_p3_bn1.weight: True
visual.layer1.2.conv1.action_p3_bn1.bias: True
visual.layer1.2.conv1.action_p3_conv1.weight: True
visual.layer1.2.conv1.action_p3_expand.weight: True
visual.layer1.2.bn1.weight: True
visual.layer1.2.bn1.bias: True
visual.layer1.2.conv2.weight: True
visual.layer1.2.bn2.weight: True
visual.layer1.2.bn2.bias: True
visual.layer1.2.conv3.weight: True
visual.layer1.2.bn3.weight: True
visual.layer1.2.bn3.bias: True
visual.layer2.0.conv1.net.weight: True
visual.layer2.0.conv1.action_shift.weight: True
visual.layer2.0.conv1.action_p1_conv1.weight: True
visual.layer2.0.conv1.action_p2_squeeze.weight: True
visual.layer2.0.conv1.action_p2_conv1.weight: True
visual.layer2.0.conv1.action_p2_expand.weight: True
visual.layer2.0.conv1.action_p3_squeeze.weight: True
visual.layer2.0.conv1.action_p3_bn1.weight: True
visual.layer2.0.conv1.action_p3_bn1.bias: True
visual.layer2.0.conv1.action_p3_conv1.weight: True
visual.layer2.0.conv1.action_p3_expand.weight: True
visual.layer2.0.bn1.weight: True
visual.layer2.0.bn1.bias: True
visual.layer2.0.conv2.weight: True
visual.layer2.0.bn2.weight: True
visual.layer2.0.bn2.bias: True
visual.layer2.0.conv3.weight: True
visual.layer2.0.bn3.weight: True
visual.layer2.0.bn3.bias: True
visual.layer2.0.downsample.0.weight: True
visual.layer2.0.downsample.1.weight: True
visual.layer2.0.downsample.1.bias: True
visual.layer2.1.conv1.net.weight: True
visual.layer2.1.conv1.action_shift.weight: True
visual.layer2.1.conv1.action_p1_conv1.weight: True
visual.layer2.1.conv1.action_p2_squeeze.weight: True
visual.layer2.1.conv1.action_p2_conv1.weight: True
visual.layer2.1.conv1.action_p2_expand.weight: True
visual.layer2.1.conv1.action_p3_squeeze.weight: True
visual.layer2.1.conv1.action_p3_bn1.weight: True
visual.layer2.1.conv1.action_p3_bn1.bias: True
visual.layer2.1.conv1.action_p3_conv1.weight: True
visual.layer2.1.conv1.action_p3_expand.weight: True
visual.layer2.1.bn1.weight: True
visual.layer2.1.bn1.bias: True
visual.layer2.1.conv2.weight: True
visual.layer2.1.bn2.weight: True
visual.layer2.1.bn2.bias: True
visual.layer2.1.conv3.weight: True
visual.layer2.1.bn3.weight: True
visual.layer2.1.bn3.bias: True
visual.layer2.2.conv1.net.weight: True
visual.layer2.2.conv1.action_shift.weight: True
visual.layer2.2.conv1.action_p1_conv1.weight: True
visual.layer2.2.conv1.action_p2_squeeze.weight: True
visual.layer2.2.conv1.action_p2_conv1.weight: True
visual.layer2.2.conv1.action_p2_expand.weight: True
visual.layer2.2.conv1.action_p3_squeeze.weight: True
visual.layer2.2.conv1.action_p3_bn1.weight: True
visual.layer2.2.conv1.action_p3_bn1.bias: True
visual.layer2.2.conv1.action_p3_conv1.weight: True
visual.layer2.2.conv1.action_p3_expand.weight: True
visual.layer2.2.bn1.weight: True
visual.layer2.2.bn1.bias: True
visual.layer2.2.conv2.weight: True
visual.layer2.2.bn2.weight: True
visual.layer2.2.bn2.bias: True
visual.layer2.2.conv3.weight: True
visual.layer2.2.bn3.weight: True
visual.layer2.2.bn3.bias: True
visual.layer2.3.conv1.net.weight: True
visual.layer2.3.conv1.action_shift.weight: True
visual.layer2.3.conv1.action_p1_conv1.weight: True
visual.layer2.3.conv1.action_p2_squeeze.weight: True
visual.layer2.3.conv1.action_p2_conv1.weight: True
visual.layer2.3.conv1.action_p2_expand.weight: True
visual.layer2.3.conv1.action_p3_squeeze.weight: True
visual.layer2.3.conv1.action_p3_bn1.weight: True
visual.layer2.3.conv1.action_p3_bn1.bias: True
visual.layer2.3.conv1.action_p3_conv1.weight: True
visual.layer2.3.conv1.action_p3_expand.weight: True
visual.layer2.3.bn1.weight: True
visual.layer2.3.bn1.bias: True
visual.layer2.3.conv2.weight: True
visual.layer2.3.bn2.weight: True
visual.layer2.3.bn2.bias: True
visual.layer2.3.conv3.weight: True
visual.layer2.3.bn3.weight: True
visual.layer2.3.bn3.bias: True
visual.layer3.0.conv1.net.weight: True
visual.layer3.0.conv1.action_shift.weight: True
visual.layer3.0.conv1.action_p1_conv1.weight: True
visual.layer3.0.conv1.action_p2_squeeze.weight: True
visual.layer3.0.conv1.action_p2_conv1.weight: True
visual.layer3.0.conv1.action_p2_expand.weight: True
visual.layer3.0.conv1.action_p3_squeeze.weight: True
visual.layer3.0.conv1.action_p3_bn1.weight: True
visual.layer3.0.conv1.action_p3_bn1.bias: True
visual.layer3.0.conv1.action_p3_conv1.weight: True
visual.layer3.0.conv1.action_p3_expand.weight: True
visual.layer3.0.bn1.weight: True
visual.layer3.0.bn1.bias: True
visual.layer3.0.conv2.weight: True
visual.layer3.0.bn2.weight: True
visual.layer3.0.bn2.bias: True
visual.layer3.0.conv3.weight: True
visual.layer3.0.bn3.weight: True
visual.layer3.0.bn3.bias: True
visual.layer3.0.downsample.0.weight: True
visual.layer3.0.downsample.1.weight: True
visual.layer3.0.downsample.1.bias: True
visual.layer3.1.conv1.net.weight: True
visual.layer3.1.conv1.action_shift.weight: True
visual.layer3.1.conv1.action_p1_conv1.weight: True
visual.layer3.1.conv1.action_p2_squeeze.weight: True
visual.layer3.1.conv1.action_p2_conv1.weight: True
visual.layer3.1.conv1.action_p2_expand.weight: True
visual.layer3.1.conv1.action_p3_squeeze.weight: True
visual.layer3.1.conv1.action_p3_bn1.weight: True
visual.layer3.1.conv1.action_p3_bn1.bias: True
visual.layer3.1.conv1.action_p3_conv1.weight: True
visual.layer3.1.conv1.action_p3_expand.weight: True
visual.layer3.1.bn1.weight: True
visual.layer3.1.bn1.bias: True
visual.layer3.1.conv2.weight: True
visual.layer3.1.bn2.weight: True
visual.layer3.1.bn2.bias: True
visual.layer3.1.conv3.weight: True
visual.layer3.1.bn3.weight: True
visual.layer3.1.bn3.bias: True
visual.layer3.2.conv1.net.weight: True
visual.layer3.2.conv1.action_shift.weight: True
visual.layer3.2.conv1.action_p1_conv1.weight: True
visual.layer3.2.conv1.action_p2_squeeze.weight: True
visual.layer3.2.conv1.action_p2_conv1.weight: True
visual.layer3.2.conv1.action_p2_expand.weight: True
visual.layer3.2.conv1.action_p3_squeeze.weight: True
visual.layer3.2.conv1.action_p3_bn1.weight: True
visual.layer3.2.conv1.action_p3_bn1.bias: True
visual.layer3.2.conv1.action_p3_conv1.weight: True
visual.layer3.2.conv1.action_p3_expand.weight: True
visual.layer3.2.bn1.weight: True
visual.layer3.2.bn1.bias: True
visual.layer3.2.conv2.weight: True
visual.layer3.2.bn2.weight: True
visual.layer3.2.bn2.bias: True
visual.layer3.2.conv3.weight: True
visual.layer3.2.bn3.weight: True
visual.layer3.2.bn3.bias: True
visual.layer3.3.conv1.net.weight: True
visual.layer3.3.conv1.action_shift.weight: True
visual.layer3.3.conv1.action_p1_conv1.weight: True
visual.layer3.3.conv1.action_p2_squeeze.weight: True
visual.layer3.3.conv1.action_p2_conv1.weight: True
visual.layer3.3.conv1.action_p2_expand.weight: True
visual.layer3.3.conv1.action_p3_squeeze.weight: True
visual.layer3.3.conv1.action_p3_bn1.weight: True
visual.layer3.3.conv1.action_p3_bn1.bias: True
visual.layer3.3.conv1.action_p3_conv1.weight: True
visual.layer3.3.conv1.action_p3_expand.weight: True
visual.layer3.3.bn1.weight: True
visual.layer3.3.bn1.bias: True
visual.layer3.3.conv2.weight: True
visual.layer3.3.bn2.weight: True
visual.layer3.3.bn2.bias: True
visual.layer3.3.conv3.weight: True
visual.layer3.3.bn3.weight: True
visual.layer3.3.bn3.bias: True
visual.layer3.4.conv1.net.weight: True
visual.layer3.4.conv1.action_shift.weight: True
visual.layer3.4.conv1.action_p1_conv1.weight: True
visual.layer3.4.conv1.action_p2_squeeze.weight: True
visual.layer3.4.conv1.action_p2_conv1.weight: True
visual.layer3.4.conv1.action_p2_expand.weight: True
visual.layer3.4.conv1.action_p3_squeeze.weight: True
visual.layer3.4.conv1.action_p3_bn1.weight: True
visual.layer3.4.conv1.action_p3_bn1.bias: True
visual.layer3.4.conv1.action_p3_conv1.weight: True
visual.layer3.4.conv1.action_p3_expand.weight: True
visual.layer3.4.bn1.weight: True
visual.layer3.4.bn1.bias: True
visual.layer3.4.conv2.weight: True
visual.layer3.4.bn2.weight: True
visual.layer3.4.bn2.bias: True
visual.layer3.4.conv3.weight: True
visual.layer3.4.bn3.weight: True
visual.layer3.4.bn3.bias: True
visual.layer3.5.conv1.net.weight: True
visual.layer3.5.conv1.action_shift.weight: True
visual.layer3.5.conv1.action_p1_conv1.weight: True
visual.layer3.5.conv1.action_p2_squeeze.weight: True
visual.layer3.5.conv1.action_p2_conv1.weight: True
visual.layer3.5.conv1.action_p2_expand.weight: True
visual.layer3.5.conv1.action_p3_squeeze.weight: True
visual.layer3.5.conv1.action_p3_bn1.weight: True
visual.layer3.5.conv1.action_p3_bn1.bias: True
visual.layer3.5.conv1.action_p3_conv1.weight: True
visual.layer3.5.conv1.action_p3_expand.weight: True
visual.layer3.5.bn1.weight: True
visual.layer3.5.bn1.bias: True
visual.layer3.5.conv2.weight: True
visual.layer3.5.bn2.weight: True
visual.layer3.5.bn2.bias: True
visual.layer3.5.conv3.weight: True
visual.layer3.5.bn3.weight: True
visual.layer3.5.bn3.bias: True
visual.layer4.0.conv1.net.weight: True
visual.layer4.0.conv1.action_shift.weight: True
visual.layer4.0.conv1.action_p1_conv1.weight: True
visual.layer4.0.conv1.action_p2_squeeze.weight: True
visual.layer4.0.conv1.action_p2_conv1.weight: True
visual.layer4.0.conv1.action_p2_expand.weight: True
visual.layer4.0.conv1.action_p3_squeeze.weight: True
visual.layer4.0.conv1.action_p3_bn1.weight: True
visual.layer4.0.conv1.action_p3_bn1.bias: True
visual.layer4.0.conv1.action_p3_conv1.weight: True
visual.layer4.0.conv1.action_p3_expand.weight: True
visual.layer4.0.bn1.weight: True
visual.layer4.0.bn1.bias: True
visual.layer4.0.conv2.weight: True
visual.layer4.0.bn2.weight: True
visual.layer4.0.bn2.bias: True
visual.layer4.0.conv3.weight: True
visual.layer4.0.bn3.weight: True
visual.layer4.0.bn3.bias: True
visual.layer4.0.downsample.0.weight: True
visual.layer4.0.downsample.1.weight: True
visual.layer4.0.downsample.1.bias: True
visual.layer4.1.conv1.net.weight: True
visual.layer4.1.conv1.action_shift.weight: True
visual.layer4.1.conv1.action_p1_conv1.weight: True
visual.layer4.1.conv1.action_p2_squeeze.weight: True
visual.layer4.1.conv1.action_p2_conv1.weight: True
visual.layer4.1.conv1.action_p2_expand.weight: True
visual.layer4.1.conv1.action_p3_squeeze.weight: True
visual.layer4.1.conv1.action_p3_bn1.weight: True
visual.layer4.1.conv1.action_p3_bn1.bias: True
visual.layer4.1.conv1.action_p3_conv1.weight: True
visual.layer4.1.conv1.action_p3_expand.weight: True
visual.layer4.1.bn1.weight: True
visual.layer4.1.bn1.bias: True
visual.layer4.1.conv2.weight: True
visual.layer4.1.bn2.weight: True
visual.layer4.1.bn2.bias: True
visual.layer4.1.conv3.weight: True
visual.layer4.1.bn3.weight: True
visual.layer4.1.bn3.bias: True
visual.layer4.2.conv1.net.weight: True
visual.layer4.2.conv1.action_shift.weight: True
visual.layer4.2.conv1.action_p1_conv1.weight: True
visual.layer4.2.conv1.action_p2_squeeze.weight: True
visual.layer4.2.conv1.action_p2_conv1.weight: True
visual.layer4.2.conv1.action_p2_expand.weight: True
visual.layer4.2.conv1.action_p3_squeeze.weight: True
visual.layer4.2.conv1.action_p3_bn1.weight: True
visual.layer4.2.conv1.action_p3_bn1.bias: True
visual.layer4.2.conv1.action_p3_conv1.weight: True
visual.layer4.2.conv1.action_p3_expand.weight: True
visual.layer4.2.bn1.weight: True
visual.layer4.2.bn1.bias: True
visual.layer4.2.conv2.weight: True
visual.layer4.2.bn2.weight: True
visual.layer4.2.bn2.bias: True
visual.layer4.2.conv3.weight: True
visual.layer4.2.bn3.weight: True
visual.layer4.2.bn3.bias: True
visual.fc.weight: True
visual.fc.bias: True
transformer.resblocks.0.attn.in_proj_weight: True
transformer.resblocks.0.attn.in_proj_bias: True
transformer.resblocks.0.attn.out_proj.weight: True
transformer.resblocks.0.attn.out_proj.bias: True
transformer.resblocks.0.ln_1.weight: True
transformer.resblocks.0.ln_1.bias: True
transformer.resblocks.0.mlp.c_fc.weight: True
transformer.resblocks.0.mlp.c_fc.bias: True
transformer.resblocks.0.mlp.c_proj.weight: True
transformer.resblocks.0.mlp.c_proj.bias: True
transformer.resblocks.0.ln_2.weight: True
transformer.resblocks.0.ln_2.bias: True
transformer.resblocks.1.attn.in_proj_weight: True
transformer.resblocks.1.attn.in_proj_bias: True
transformer.resblocks.1.attn.out_proj.weight: True
transformer.resblocks.1.attn.out_proj.bias: True
transformer.resblocks.1.ln_1.weight: True
transformer.resblocks.1.ln_1.bias: True
transformer.resblocks.1.mlp.c_fc.weight: True
transformer.resblocks.1.mlp.c_fc.bias: True
transformer.resblocks.1.mlp.c_proj.weight: True
transformer.resblocks.1.mlp.c_proj.bias: True
transformer.resblocks.1.ln_2.weight: True
transformer.resblocks.1.ln_2.bias: True
transformer.resblocks.2.attn.in_proj_weight: True
transformer.resblocks.2.attn.in_proj_bias: True
transformer.resblocks.2.attn.out_proj.weight: True
transformer.resblocks.2.attn.out_proj.bias: True
transformer.resblocks.2.ln_1.weight: True
transformer.resblocks.2.ln_1.bias: True
transformer.resblocks.2.mlp.c_fc.weight: True
transformer.resblocks.2.mlp.c_fc.bias: True
transformer.resblocks.2.mlp.c_proj.weight: True
transformer.resblocks.2.mlp.c_proj.bias: True
transformer.resblocks.2.ln_2.weight: True
transformer.resblocks.2.ln_2.bias: True
transformer.resblocks.3.attn.in_proj_weight: True
transformer.resblocks.3.attn.in_proj_bias: True
transformer.resblocks.3.attn.out_proj.weight: True
transformer.resblocks.3.attn.out_proj.bias: True
transformer.resblocks.3.ln_1.weight: True
transformer.resblocks.3.ln_1.bias: True
transformer.resblocks.3.mlp.c_fc.weight: True
transformer.resblocks.3.mlp.c_fc.bias: True
transformer.resblocks.3.mlp.c_proj.weight: True
transformer.resblocks.3.mlp.c_proj.bias: True
transformer.resblocks.3.ln_2.weight: True
transformer.resblocks.3.ln_2.bias: True
transformer.resblocks.4.attn.in_proj_weight: True
transformer.resblocks.4.attn.in_proj_bias: True
transformer.resblocks.4.attn.out_proj.weight: True
transformer.resblocks.4.attn.out_proj.bias: True
transformer.resblocks.4.ln_1.weight: True
transformer.resblocks.4.ln_1.bias: True
transformer.resblocks.4.mlp.c_fc.weight: True
transformer.resblocks.4.mlp.c_fc.bias: True
transformer.resblocks.4.mlp.c_proj.weight: True
transformer.resblocks.4.mlp.c_proj.bias: True
transformer.resblocks.4.ln_2.weight: True
transformer.resblocks.4.ln_2.bias: True
transformer.resblocks.5.attn.in_proj_weight: True
transformer.resblocks.5.attn.in_proj_bias: True
transformer.resblocks.5.attn.out_proj.weight: True
transformer.resblocks.5.attn.out_proj.bias: True
transformer.resblocks.5.ln_1.weight: True
transformer.resblocks.5.ln_1.bias: True
transformer.resblocks.5.mlp.c_fc.weight: True
transformer.resblocks.5.mlp.c_fc.bias: True
transformer.resblocks.5.mlp.c_proj.weight: True
transformer.resblocks.5.mlp.c_proj.bias: True
transformer.resblocks.5.ln_2.weight: True
transformer.resblocks.5.ln_2.bias: True
transformer.resblocks.6.attn.in_proj_weight: True
transformer.resblocks.6.attn.in_proj_bias: True
transformer.resblocks.6.attn.out_proj.weight: True
transformer.resblocks.6.attn.out_proj.bias: True
transformer.resblocks.6.ln_1.weight: True
transformer.resblocks.6.ln_1.bias: True
transformer.resblocks.6.mlp.c_fc.weight: True
transformer.resblocks.6.mlp.c_fc.bias: True
transformer.resblocks.6.mlp.c_proj.weight: True
transformer.resblocks.6.mlp.c_proj.bias: True
transformer.resblocks.6.ln_2.weight: True
transformer.resblocks.6.ln_2.bias: True
transformer.resblocks.7.attn.in_proj_weight: True
transformer.resblocks.7.attn.in_proj_bias: True
transformer.resblocks.7.attn.out_proj.weight: True
transformer.resblocks.7.attn.out_proj.bias: True
transformer.resblocks.7.ln_1.weight: True
transformer.resblocks.7.ln_1.bias: True
transformer.resblocks.7.mlp.c_fc.weight: True
transformer.resblocks.7.mlp.c_fc.bias: True
transformer.resblocks.7.mlp.c_proj.weight: True
transformer.resblocks.7.mlp.c_proj.bias: True
transformer.resblocks.7.ln_2.weight: True
transformer.resblocks.7.ln_2.bias: True
transformer.resblocks.8.attn.in_proj_weight: True
transformer.resblocks.8.attn.in_proj_bias: True
transformer.resblocks.8.attn.out_proj.weight: True
transformer.resblocks.8.attn.out_proj.bias: True
transformer.resblocks.8.ln_1.weight: True
transformer.resblocks.8.ln_1.bias: True
transformer.resblocks.8.mlp.c_fc.weight: True
transformer.resblocks.8.mlp.c_fc.bias: True
transformer.resblocks.8.mlp.c_proj.weight: True
transformer.resblocks.8.mlp.c_proj.bias: True
transformer.resblocks.8.ln_2.weight: True
transformer.resblocks.8.ln_2.bias: True
transformer.resblocks.9.attn.in_proj_weight: True
transformer.resblocks.9.attn.in_proj_bias: True
transformer.resblocks.9.attn.out_proj.weight: True
transformer.resblocks.9.attn.out_proj.bias: True
transformer.resblocks.9.ln_1.weight: True
transformer.resblocks.9.ln_1.bias: True
transformer.resblocks.9.mlp.c_fc.weight: True
transformer.resblocks.9.mlp.c_fc.bias: True
transformer.resblocks.9.mlp.c_proj.weight: True
transformer.resblocks.9.mlp.c_proj.bias: True
transformer.resblocks.9.ln_2.weight: True
transformer.resblocks.9.ln_2.bias: True
transformer.resblocks.10.attn.in_proj_weight: True
transformer.resblocks.10.attn.in_proj_bias: True
transformer.resblocks.10.attn.out_proj.weight: True
transformer.resblocks.10.attn.out_proj.bias: True
transformer.resblocks.10.ln_1.weight: True
transformer.resblocks.10.ln_1.bias: True
transformer.resblocks.10.mlp.c_fc.weight: True
transformer.resblocks.10.mlp.c_fc.bias: True
transformer.resblocks.10.mlp.c_proj.weight: True
transformer.resblocks.10.mlp.c_proj.bias: True
transformer.resblocks.10.ln_2.weight: True
transformer.resblocks.10.ln_2.bias: True
transformer.resblocks.11.attn.in_proj_weight: True
transformer.resblocks.11.attn.in_proj_bias: True
transformer.resblocks.11.attn.out_proj.weight: True
transformer.resblocks.11.attn.out_proj.bias: True
transformer.resblocks.11.ln_1.weight: True
transformer.resblocks.11.ln_1.bias: True
transformer.resblocks.11.mlp.c_fc.weight: True
transformer.resblocks.11.mlp.c_fc.bias: True
transformer.resblocks.11.mlp.c_proj.weight: True
transformer.resblocks.11.mlp.c_proj.bias: True
transformer.resblocks.11.ln_2.weight: True
transformer.resblocks.11.ln_2.bias: True
token_embedding.weight: True
ln_final.weight: True
ln_final.bias: True
  0% 0/14661 [00:00<?, ?it/s]/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
image_embedding size:  torch.Size([16, 1024])
text_embedding size:  torch.Size([16, 1024])
/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/functional.py:2741: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
  0% 1/14661 [00:12<52:54:26, 12.99s/it]  0% 2/14661 [00:13<23:38:19,  5.81s/it]  0% 3/14661 [00:14<14:17:55,  3.51s/it]  0% 4/14661 [00:15<9:54:05,  2.43s/it]   0% 5/14661 [00:16<7:28:33,  1.84s/it]  0% 6/14661 [00:16<6:01:49,  1.48s/it]  0% 7/14661 [00:17<5:07:36,  1.26s/it]  0% 8/14661 [00:18<4:30:41,  1.11s/it]  0% 9/14661 [00:19<4:04:41,  1.00s/it]  0% 10/14661 [00:20<3:46:39,  1.08it/s]  0% 11/14661 [00:20<3:36:14,  1.13it/s]  0% 12/14661 [00:21<3:27:39,  1.18it/s]  0% 13/14661 [00:22<3:22:11,  1.21it/s]  0% 14/14661 [00:23<3:17:40,  1.23it/s]  0% 15/14661 [00:23<3:14:28,  1.26it/s]  0% 16/14661 [00:24<3:14:22,  1.26it/s]  0% 17/14661 [00:25<3:15:05,  1.25it/s]  0% 18/14661 [00:26<3:12:14,  1.27it/s]  0% 19/14661 [00:27<3:11:35,  1.27it/s]  0% 20/14661 [00:27<3:09:35,  1.29it/s]  0% 21/14661 [00:28<3:08:32,  1.29it/s]  0% 22/14661 [00:29<3:08:38,  1.29it/s]  0% 23/14661 [00:30<3:07:56,  1.30it/s]  0% 24/14661 [00:30<3:07:11,  1.30it/s]  0% 25/14661 [00:31<3:06:35,  1.31it/s]  0% 26/14661 [00:32<3:06:09,  1.31it/s]  0% 27/14661 [00:33<3:06:03,  1.31it/s]  0% 28/14661 [00:33<3:06:01,  1.31it/s]  0% 29/14661 [00:34<3:06:45,  1.31it/s]  0% 30/14661 [00:35<3:06:52,  1.30it/s]  0% 31/14661 [00:36<3:06:44,  1.31it/s]  0% 32/14661 [00:36<3:07:05,  1.30it/s]  0% 33/14661 [00:37<3:06:43,  1.31it/s]  0% 34/14661 [00:38<3:06:09,  1.31it/s]  0% 35/14661 [00:39<3:07:04,  1.30it/s]  0% 36/14661 [00:40<3:08:33,  1.29it/s]  0% 37/14661 [00:40<3:07:49,  1.30it/s]  0% 38/14661 [00:41<3:07:32,  1.30it/s]  0% 39/14661 [00:42<3:07:28,  1.30it/s]  0% 40/14661 [00:43<3:09:44,  1.28it/s]  0% 41/14661 [00:43<3:11:09,  1.27it/s]  0% 42/14661 [00:44<3:09:54,  1.28it/s]  0% 43/14661 [00:45<3:09:05,  1.29it/s]  0% 44/14661 [00:46<3:07:56,  1.30it/s]  0% 45/14661 [00:47<3:07:44,  1.30it/s]  0% 46/14661 [00:47<3:06:54,  1.30it/s]  0% 47/14661 [00:48<3:06:19,  1.31it/s]  0% 48/14661 [00:49<3:05:42,  1.31it/s]  0% 49/14661 [00:50<3:05:19,  1.31it/s]  0% 50/14661 [00:50<3:05:38,  1.31it/s]  0% 51/14661 [00:51<3:07:26,  1.30it/s]  0% 52/14661 [00:52<3:09:06,  1.29it/s]  0% 53/14661 [00:53<3:10:34,  1.28it/s]  0% 54/14661 [00:53<3:11:13,  1.27it/s]  0% 55/14661 [00:54<3:09:36,  1.28it/s]  0% 56/14661 [00:55<3:09:10,  1.29it/s]  0% 57/14661 [00:56<3:08:58,  1.29it/s]  0% 58/14661 [00:57<3:09:14,  1.29it/s]  0% 59/14661 [00:57<3:09:18,  1.29it/s]  0% 60/14661 [00:58<3:08:29,  1.29it/s]  0% 61/14661 [00:59<3:07:35,  1.30it/s]  0% 62/14661 [01:00<3:07:51,  1.30it/s]  0% 63/14661 [01:00<3:08:22,  1.29it/s]  0% 64/14661 [01:01<3:08:12,  1.29it/s]  0% 65/14661 [01:02<3:07:16,  1.30it/s]  0% 66/14661 [01:03<3:06:55,  1.30it/s]  0% 67/14661 [01:03<3:06:29,  1.30it/s]  0% 68/14661 [01:04<3:06:12,  1.31it/s]  0% 69/14661 [01:05<3:05:18,  1.31it/s]  0% 70/14661 [01:06<3:05:04,  1.31it/s]  0% 71/14661 [01:07<3:04:53,  1.32it/s]  0% 72/14661 [01:07<3:06:12,  1.31it/s]  0% 73/14661 [01:08<3:06:54,  1.30it/s]  1% 74/14661 [01:09<3:06:56,  1.30it/s]  1% 75/14661 [01:10<3:06:13,  1.31it/s]  1% 76/14661 [01:10<3:05:33,  1.31it/s]  1% 77/14661 [01:11<3:05:04,  1.31it/s]  1% 78/14661 [01:12<3:07:49,  1.29it/s]  1% 79/14661 [01:13<3:07:34,  1.30it/s]  1% 80/14661 [01:13<3:07:42,  1.29it/s]  1% 81/14661 [01:14<3:08:14,  1.29it/s]  1% 82/14661 [01:15<3:07:38,  1.29it/s]  1% 83/14661 [01:16<3:06:52,  1.30it/s]  1% 84/14661 [01:17<3:06:42,  1.30it/s]  1% 85/14661 [01:17<3:07:04,  1.30it/s]  1% 86/14661 [01:18<3:06:25,  1.30it/s]  1% 87/14661 [01:19<3:06:37,  1.30it/s]  1% 88/14661 [01:20<3:06:10,  1.30it/s]  1% 89/14661 [01:20<3:06:57,  1.30it/s]  1% 90/14661 [01:21<3:08:25,  1.29it/s]  1% 91/14661 [01:22<3:08:41,  1.29it/s]  1% 92/14661 [01:23<3:08:52,  1.29it/s]  1% 93/14661 [01:24<3:08:29,  1.29it/s]  1% 94/14661 [01:24<3:07:04,  1.30it/s]  1% 95/14661 [01:25<3:05:59,  1.31it/s]  1% 96/14661 [01:26<3:05:23,  1.31it/s]  1% 97/14661 [01:27<3:04:51,  1.31it/s]  1% 98/14661 [01:27<3:04:37,  1.31it/s]  1% 99/14661 [01:28<3:04:31,  1.32it/s]  1% 100/14661 [01:29<3:04:47,  1.31it/s]  1% 101/14661 [01:30<3:06:46,  1.30it/s]  1% 102/14661 [01:30<3:06:52,  1.30it/s]  1% 103/14661 [01:31<3:06:46,  1.30it/s]  1% 104/14661 [01:32<3:06:10,  1.30it/s]  1% 105/14661 [01:33<3:06:20,  1.30it/s]  1% 106/14661 [01:33<3:06:14,  1.30it/s]  1% 107/14661 [01:34<3:08:35,  1.29it/s]  1% 108/14661 [01:35<3:07:51,  1.29it/s]  1% 109/14661 [01:36<3:06:35,  1.30it/s]  1% 110/14661 [01:37<3:05:50,  1.30it/s]  1% 111/14661 [01:37<3:05:35,  1.31it/s]  1% 112/14661 [01:38<3:04:50,  1.31it/s]  1% 113/14661 [01:39<3:04:37,  1.31it/s]  1% 114/14661 [01:40<3:04:15,  1.32it/s]  1% 115/14661 [01:40<3:03:44,  1.32it/s]  1% 116/14661 [01:41<3:03:48,  1.32it/s]  1% 117/14661 [01:42<3:04:01,  1.32it/s]  1% 118/14661 [01:43<3:04:25,  1.31it/s]  1% 119/14661 [01:43<3:04:29,  1.31it/s]  1% 120/14661 [01:44<3:04:27,  1.31it/s]  1% 121/14661 [01:45<3:04:16,  1.32it/s]  1% 122/14661 [01:46<3:04:23,  1.31it/s]  1% 123/14661 [01:46<3:07:48,  1.29it/s]  1% 124/14661 [01:47<3:07:31,  1.29it/s]  1% 125/14661 [01:48<3:08:23,  1.29it/s]  1% 126/14661 [01:49<3:07:45,  1.29it/s]  1% 127/14661 [01:50<3:09:30,  1.28it/s]  1% 128/14661 [01:50<3:11:18,  1.27it/s]  1% 129/14661 [01:51<3:13:20,  1.25it/s]  1% 130/14661 [01:52<3:11:58,  1.26it/s]  1% 131/14661 [01:53<3:10:26,  1.27it/s]  1% 132/14661 [01:54<3:08:22,  1.29it/s]  1% 133/14661 [01:54<3:07:59,  1.29it/s]  1% 134/14661 [01:55<3:07:45,  1.29it/s]  1% 135/14661 [01:56<3:06:34,  1.30it/s]  1% 136/14661 [01:57<3:05:41,  1.30it/s]  1% 137/14661 [01:57<3:05:17,  1.31it/s]  1% 138/14661 [01:58<3:07:47,  1.29it/s]  1% 139/14661 [01:59<3:06:41,  1.30it/s]  1% 140/14661 [02:00<3:05:55,  1.30it/s]  1% 141/14661 [02:00<3:05:14,  1.31it/s]  1% 142/14661 [02:01<3:05:45,  1.30it/s]  1% 143/14661 [02:02<3:06:02,  1.30it/s]  1% 144/14661 [02:03<3:06:26,  1.30it/s]  1% 145/14661 [02:04<3:11:53,  1.26it/s]  1% 146/14661 [02:04<3:11:04,  1.27it/s]  1% 147/14661 [02:05<3:08:37,  1.28it/s]  1% 148/14661 [02:06<3:07:05,  1.29it/s]  1% 149/14661 [02:07<3:05:41,  1.30it/s]  1% 150/14661 [02:07<3:04:45,  1.31it/s]  1% 151/14661 [02:08<3:04:27,  1.31it/s]  1% 152/14661 [02:09<3:04:14,  1.31it/s]  1% 153/14661 [02:10<3:03:56,  1.31it/s]  1% 154/14661 [02:10<3:03:45,  1.32it/s]  1% 155/14661 [02:11<3:03:49,  1.32it/s]  1% 156/14661 [02:12<3:03:49,  1.32it/s]  1% 157/14661 [02:13<3:04:10,  1.31it/s]  1% 158/14661 [02:13<3:03:36,  1.32it/s]  1% 159/14661 [02:14<3:04:23,  1.31it/s]  1% 160/14661 [02:15<3:05:11,  1.31it/s]  1% 161/14661 [02:16<3:05:34,  1.30it/s]  1% 162/14661 [02:17<3:05:43,  1.30it/s]  1% 163/14661 [02:17<3:06:59,  1.29it/s]  1% 164/14661 [02:18<3:06:35,  1.29it/s]  1% 165/14661 [02:19<3:06:02,  1.30it/s]  1% 166/14661 [02:20<3:06:38,  1.29it/s]  1% 167/14661 [02:20<3:08:25,  1.28it/s]  1% 168/14661 [02:21<3:08:24,  1.28it/s]  1% 169/14661 [02:22<3:07:19,  1.29it/s]  1% 170/14661 [02:23<3:05:49,  1.30it/s]  1% 171/14661 [02:24<3:05:02,  1.31it/s]  1% 172/14661 [02:24<3:04:13,  1.31it/s]  1% 173/14661 [02:25<3:03:46,  1.31it/s]  1% 174/14661 [02:26<3:03:41,  1.31it/s]  1% 175/14661 [02:27<3:03:33,  1.32it/s]  1% 176/14661 [02:27<3:04:06,  1.31it/s]  1% 177/14661 [02:28<3:04:04,  1.31it/s]  1% 178/14661 [02:29<3:03:59,  1.31it/s]  1% 179/14661 [02:30<3:03:59,  1.31it/s]  1% 180/14661 [02:30<3:03:56,  1.31it/s]  1% 181/14661 [02:31<3:03:54,  1.31it/s]  1% 182/14661 [02:32<3:04:03,  1.31it/s]  1% 183/14661 [02:33<3:04:07,  1.31it/s]  1% 184/14661 [02:33<3:04:03,  1.31it/s]  1% 185/14661 [02:34<3:07:59,  1.28it/s]  1% 186/14661 [02:35<3:08:13,  1.28it/s]  1% 187/14661 [02:36<3:07:54,  1.28it/s]  1% 188/14661 [02:37<3:07:44,  1.28it/s]  1% 189/14661 [02:37<3:09:52,  1.27it/s]  1% 190/14661 [02:38<3:09:21,  1.27it/s]  1% 191/14661 [02:39<3:08:29,  1.28it/s]  1% 192/14661 [02:40<3:07:45,  1.28it/s]  1% 193/14661 [02:40<3:08:06,  1.28it/s]  1% 194/14661 [02:41<3:07:05,  1.29it/s]  1% 195/14661 [02:42<3:07:08,  1.29it/s]  1% 196/14661 [02:43<3:07:08,  1.29it/s]  1% 197/14661 [02:44<3:06:02,  1.30it/s]  1% 198/14661 [02:44<3:06:47,  1.29it/s]  1% 199/14661 [02:45<3:06:21,  1.29it/s]  1% 200/14661 [02:46<3:06:28,  1.29it/s]  1% 201/14661 [02:47<3:06:49,  1.29it/s]  1% 202/14661 [02:47<3:06:20,  1.29it/s]  1% 203/14661 [02:48<3:06:51,  1.29it/s]  1% 204/14661 [02:49<3:06:15,  1.29it/s]  1% 205/14661 [02:50<3:06:57,  1.29it/s]  1% 206/14661 [02:51<3:08:04,  1.28it/s]  1% 207/14661 [02:51<3:10:25,  1.27it/s]  1% 208/14661 [02:52<3:08:21,  1.28it/s]  1% 209/14661 [02:53<3:08:14,  1.28it/s]  1% 210/14661 [02:54<3:06:53,  1.29it/s]  1% 211/14661 [02:54<3:05:41,  1.30it/s]  1% 212/14661 [02:55<3:05:51,  1.30it/s]  1% 213/14661 [02:56<3:05:50,  1.30it/s]  1% 214/14661 [02:57<3:05:31,  1.30it/s]  1% 215/14661 [02:58<3:06:50,  1.29it/s]  1% 216/14661 [02:58<3:08:14,  1.28it/s]  1% 217/14661 [02:59<3:07:35,  1.28it/s]  1% 218/14661 [03:00<3:06:33,  1.29it/s]  1% 219/14661 [03:01<3:05:54,  1.29it/s]  2% 220/14661 [03:01<3:05:38,  1.30it/s]  2% 221/14661 [03:02<3:06:35,  1.29it/s]  2% 222/14661 [03:03<3:07:31,  1.28it/s]  2% 223/14661 [03:04<3:09:11,  1.27it/s]  2% 224/14661 [03:05<3:08:37,  1.28it/s]  2% 225/14661 [03:05<3:07:20,  1.28it/s]  2% 226/14661 [03:06<3:06:08,  1.29it/s]  2% 227/14661 [03:07<3:06:06,  1.29it/s]  2% 228/14661 [03:08<3:05:28,  1.30it/s]  2% 229/14661 [03:08<3:05:21,  1.30it/s]  2% 230/14661 [03:09<3:07:24,  1.28it/s]  2% 231/14661 [03:10<3:07:28,  1.28it/s]  2% 232/14661 [03:11<3:07:03,  1.29it/s]  2% 233/14661 [03:12<3:06:10,  1.29it/s]  2% 234/14661 [03:12<3:06:33,  1.29it/s]  2% 235/14661 [03:13<3:05:40,  1.29it/s]  2% 236/14661 [03:14<3:06:08,  1.29it/s]  2% 237/14661 [03:15<3:08:06,  1.28it/s]  2% 238/14661 [03:15<3:07:00,  1.29it/s]  2% 239/14661 [03:16<3:06:52,  1.29it/s]  2% 240/14661 [03:17<3:06:31,  1.29it/s]  2% 241/14661 [03:18<3:07:34,  1.28it/s]  2% 242/14661 [03:19<3:06:28,  1.29it/s]  2% 243/14661 [03:19<3:05:16,  1.30it/s]  2% 244/14661 [03:20<3:05:43,  1.29it/s]  2% 245/14661 [03:21<3:05:32,  1.29it/s]  2% 246/14661 [03:22<3:05:02,  1.30it/s]  2% 247/14661 [03:22<3:04:36,  1.30it/s]  2% 248/14661 [03:23<3:05:12,  1.30it/s]  2% 249/14661 [03:24<3:06:16,  1.29it/s]  2% 250/14661 [03:25<3:07:37,  1.28it/s]  2% 251/14661 [03:25<3:07:35,  1.28it/s]  2% 252/14661 [03:26<3:08:06,  1.28it/s]  2% 253/14661 [03:27<3:07:58,  1.28it/s]  2% 254/14661 [03:28<3:07:06,  1.28it/s]  2% 255/14661 [03:29<3:06:16,  1.29it/s]  2% 256/14661 [03:29<3:05:18,  1.30it/s]  2% 257/14661 [03:30<3:04:13,  1.30it/s]  2% 258/14661 [03:31<3:05:03,  1.30it/s]  2% 259/14661 [03:32<3:04:55,  1.30it/s]  2% 260/14661 [03:32<3:05:24,  1.29it/s]  2% 261/14661 [03:33<3:05:30,  1.29it/s]  2% 262/14661 [03:34<3:04:52,  1.30it/s]  2% 263/14661 [03:35<3:04:03,  1.30it/s]  2% 264/14661 [03:36<3:04:06,  1.30it/s]  2% 265/14661 [03:36<3:04:01,  1.30it/s]  2% 266/14661 [03:37<3:04:06,  1.30it/s]  2% 267/14661 [03:38<3:04:46,  1.30it/s]  2% 268/14661 [03:39<3:04:42,  1.30it/s]  2% 269/14661 [03:39<3:04:15,  1.30it/s]  2% 270/14661 [03:40<3:03:51,  1.30it/s]  2% 271/14661 [03:41<3:03:28,  1.31it/s]  2% 272/14661 [03:42<3:03:19,  1.31it/s]  2% 273/14661 [03:42<3:03:12,  1.31it/s]  2% 274/14661 [03:43<3:03:56,  1.30it/s]  2% 275/14661 [03:44<3:05:30,  1.29it/s]  2% 276/14661 [03:45<3:06:29,  1.29it/s]  2% 277/14661 [03:46<3:05:53,  1.29it/s]  2% 278/14661 [03:46<3:07:41,  1.28it/s]  2% 279/14661 [03:47<3:07:10,  1.28it/s]  2% 280/14661 [03:48<3:06:20,  1.29it/s]  2% 281/14661 [03:49<3:05:52,  1.29it/s]  2% 282/14661 [03:49<3:05:33,  1.29it/s]  2% 283/14661 [03:50<3:06:50,  1.28it/s]  2% 284/14661 [03:51<3:05:46,  1.29it/s]  2% 285/14661 [03:52<3:05:19,  1.29it/s]  2% 286/14661 [03:53<3:05:06,  1.29it/s]  2% 287/14661 [03:53<3:04:53,  1.30it/s]  2% 288/14661 [03:54<3:04:15,  1.30it/s]  2% 289/14661 [03:55<3:05:02,  1.29it/s]  2% 290/14661 [03:56<3:05:46,  1.29it/s]  2% 291/14661 [03:56<3:04:40,  1.30it/s]  2% 292/14661 [03:57<3:05:24,  1.29it/s]  2% 293/14661 [03:58<3:05:36,  1.29it/s]  2% 294/14661 [03:59<3:05:34,  1.29it/s]  2% 295/14661 [04:00<3:07:01,  1.28it/s]  2% 296/14661 [04:00<3:06:19,  1.28it/s]  2% 297/14661 [04:01<3:06:09,  1.29it/s]  2% 298/14661 [04:02<3:05:55,  1.29it/s]  2% 299/14661 [04:03<3:05:07,  1.29it/s]  2% 300/14661 [04:03<3:04:29,  1.30it/s]  2% 301/14661 [04:04<3:04:31,  1.30it/s]  2% 302/14661 [04:05<3:04:17,  1.30it/s]  2% 303/14661 [04:06<3:04:47,  1.29it/s]  2% 304/14661 [04:06<3:05:47,  1.29it/s]  2% 305/14661 [04:07<3:04:47,  1.29it/s]  2% 306/14661 [04:08<3:06:09,  1.29it/s]  2% 307/14661 [04:09<3:06:29,  1.28it/s]  2% 308/14661 [04:10<3:06:19,  1.28it/s]  2% 309/14661 [04:10<3:06:49,  1.28it/s]  2% 310/14661 [04:11<3:08:07,  1.27it/s]  2% 311/14661 [04:12<3:06:44,  1.28it/s]  2% 312/14661 [04:13<3:05:26,  1.29it/s]  2% 313/14661 [04:13<3:04:30,  1.30it/s]  2% 314/14661 [04:14<3:03:55,  1.30it/s]  2% 315/14661 [04:15<3:03:37,  1.30it/s]  2% 316/14661 [04:16<3:03:51,  1.30it/s]  2% 317/14661 [04:17<3:04:10,  1.30it/s]  2% 318/14661 [04:17<3:04:49,  1.29it/s]  2% 319/14661 [04:18<3:06:17,  1.28it/s]  2% 320/14661 [04:19<3:06:52,  1.28it/s]  2% 321/14661 [04:20<3:08:38,  1.27it/s]  2% 322/14661 [04:20<3:08:26,  1.27it/s]  2% 323/14661 [04:21<3:07:13,  1.28it/s]  2% 324/14661 [04:22<3:08:23,  1.27it/s]  2% 325/14661 [04:23<3:08:43,  1.27it/s]  2% 326/14661 [04:24<3:08:26,  1.27it/s]  2% 327/14661 [04:24<3:07:36,  1.27it/s]  2% 328/14661 [04:25<3:07:08,  1.28it/s]  2% 329/14661 [04:26<3:06:35,  1.28it/s]  2% 330/14661 [04:27<3:05:31,  1.29it/s]  2% 331/14661 [04:27<3:05:07,  1.29it/s]  2% 332/14661 [04:28<3:05:03,  1.29it/s]  2% 333/14661 [04:29<3:06:09,  1.28it/s]  2% 334/14661 [04:30<3:05:59,  1.28it/s]  2% 335/14661 [04:31<3:05:46,  1.29it/s]  2% 336/14661 [04:31<3:05:37,  1.29it/s]  2% 337/14661 [04:32<3:05:28,  1.29it/s]  2% 338/14661 [04:33<3:07:12,  1.28it/s]  2% 339/14661 [04:34<3:07:03,  1.28it/s]  2% 340/14661 [04:35<3:07:19,  1.27it/s]  2% 341/14661 [04:35<3:06:19,  1.28it/s]  2% 342/14661 [04:36<3:08:21,  1.27it/s]  2% 343/14661 [04:37<3:08:08,  1.27it/s]  2% 344/14661 [04:38<3:07:55,  1.27it/s]  2% 345/14661 [04:38<3:07:01,  1.28it/s]  2% 346/14661 [04:39<3:06:03,  1.28it/s]  2% 347/14661 [04:40<3:06:41,  1.28it/s]  2% 348/14661 [04:41<3:07:13,  1.27it/s]  2% 349/14661 [04:42<3:06:17,  1.28it/s]  2% 350/14661 [04:42<3:05:29,  1.29it/s]  2% 351/14661 [04:43<3:04:53,  1.29it/s]  2% 352/14661 [04:44<3:04:12,  1.29it/s]  2% 353/14661 [04:45<3:04:04,  1.30it/s]  2% 354/14661 [04:45<3:04:15,  1.29it/s]  2% 355/14661 [04:46<3:05:19,  1.29it/s]  2% 356/14661 [04:47<3:06:35,  1.28it/s]  2% 357/14661 [04:48<3:07:55,  1.27it/s]  2% 358/14661 [04:49<3:08:55,  1.26it/s]  2% 359/14661 [04:49<3:09:07,  1.26it/s]  2% 360/14661 [04:50<3:08:03,  1.27it/s]  2% 361/14661 [04:51<3:09:44,  1.26it/s]  2% 362/14661 [04:52<3:09:23,  1.26it/s]  2% 363/14661 [04:53<3:08:58,  1.26it/s]  2% 364/14661 [04:53<3:07:17,  1.27it/s]  2% 365/14661 [04:54<3:06:18,  1.28it/s]  2% 366/14661 [04:55<3:05:23,  1.29it/s]  3% 367/14661 [04:56<3:04:48,  1.29it/s]  3% 368/14661 [04:56<3:04:36,  1.29it/s]  3% 369/14661 [04:57<3:04:09,  1.29it/s]  3% 370/14661 [04:58<3:03:51,  1.30it/s]  3% 371/14661 [04:59<3:03:45,  1.30it/s]  3% 372/14661 [05:00<3:03:32,  1.30it/s]  3% 373/14661 [05:00<3:03:17,  1.30it/s]  3% 374/14661 [05:01<3:03:13,  1.30it/s]  3% 375/14661 [05:02<3:03:01,  1.30it/s]  3% 376/14661 [05:03<3:03:12,  1.30it/s]  3% 377/14661 [05:03<3:03:13,  1.30it/s]  3% 378/14661 [05:04<3:03:06,  1.30it/s]  3% 379/14661 [05:05<3:03:17,  1.30it/s]  3% 380/14661 [05:06<3:03:14,  1.30it/s]  3% 381/14661 [05:06<3:05:22,  1.28it/s]  3% 382/14661 [05:07<3:06:12,  1.28it/s]  3% 383/14661 [05:08<3:06:19,  1.28it/s]  3% 384/14661 [05:09<3:06:20,  1.28it/s]  3% 385/14661 [05:10<3:07:12,  1.27it/s]  3% 386/14661 [05:10<3:07:41,  1.27it/s]  3% 387/14661 [05:11<3:07:30,  1.27it/s]  3% 388/14661 [05:12<3:06:27,  1.28it/s]  3% 389/14661 [05:13<3:05:36,  1.28it/s]  3% 390/14661 [05:14<3:04:46,  1.29it/s]  3% 391/14661 [05:14<3:04:32,  1.29it/s]  3% 392/14661 [05:15<3:04:09,  1.29it/s]  3% 393/14661 [05:16<3:04:45,  1.29it/s]  3% 394/14661 [05:17<3:05:30,  1.28it/s]  3% 395/14661 [05:17<3:04:56,  1.29it/s]  3% 396/14661 [05:18<3:05:28,  1.28it/s]  3% 397/14661 [05:19<3:06:17,  1.28it/s]  3% 398/14661 [05:20<3:06:12,  1.28it/s]  3% 399/14661 [05:21<3:07:13,  1.27it/s]  3% 400/14661 [05:21<3:07:03,  1.27it/s]  3% 401/14661 [05:22<3:06:57,  1.27it/s]  3% 402/14661 [05:23<3:06:36,  1.27it/s]  3% 403/14661 [05:24<3:06:33,  1.27it/s]  3% 404/14661 [05:25<3:06:41,  1.27it/s]  3% 405/14661 [05:25<3:05:29,  1.28it/s]  3% 406/14661 [05:26<3:05:25,  1.28it/s]  3% 407/14661 [05:27<3:05:17,  1.28it/s]  3% 408/14661 [05:28<3:05:04,  1.28it/s]  3% 409/14661 [05:28<3:04:59,  1.28it/s]  3% 410/14661 [05:29<3:05:26,  1.28it/s]  3% 411/14661 [05:30<3:05:15,  1.28it/s]  3% 412/14661 [05:31<3:04:47,  1.29it/s]  3% 413/14661 [05:32<3:05:03,  1.28it/s]  3% 414/14661 [05:32<3:06:05,  1.28it/s]  3% 415/14661 [05:33<3:05:06,  1.28it/s]  3% 416/14661 [05:34<3:04:26,  1.29it/s]  3% 417/14661 [05:35<3:03:49,  1.29it/s]  3% 418/14661 [05:35<3:03:24,  1.29it/s]  3% 419/14661 [05:36<3:03:16,  1.30it/s]  3% 420/14661 [05:37<3:03:02,  1.30it/s]  3% 421/14661 [05:38<3:02:57,  1.30it/s]  3% 422/14661 [05:38<3:02:56,  1.30it/s]  3% 423/14661 [05:39<3:02:44,  1.30it/s]  3% 424/14661 [05:40<3:02:39,  1.30it/s]  3% 425/14661 [05:41<3:04:13,  1.29it/s]  3% 426/14661 [05:42<3:04:05,  1.29it/s]  3% 427/14661 [05:42<3:04:04,  1.29it/s]  3% 428/14661 [05:43<3:04:35,  1.29it/s]  3% 429/14661 [05:44<3:03:54,  1.29it/s]  3% 430/14661 [05:45<3:03:18,  1.29it/s]  3% 431/14661 [05:45<3:02:53,  1.30it/s]  3% 432/14661 [05:46<3:03:41,  1.29it/s]  3% 433/14661 [05:47<3:04:11,  1.29it/s]  3% 434/14661 [05:48<3:03:52,  1.29it/s]  3% 435/14661 [05:49<3:03:06,  1.29it/s]  3% 436/14661 [05:49<3:02:51,  1.30it/s]  3% 437/14661 [05:50<3:02:49,  1.30it/s]  3% 438/14661 [05:51<3:03:08,  1.29it/s]  3% 439/14661 [05:52<3:03:40,  1.29it/s]  3% 440/14661 [05:52<3:03:16,  1.29it/s]  3% 441/14661 [05:53<3:03:35,  1.29it/s]  3% 442/14661 [05:54<3:02:58,  1.30it/s]  3% 443/14661 [05:55<3:02:37,  1.30it/s]  3% 444/14661 [05:55<3:02:29,  1.30it/s]  3% 445/14661 [05:56<3:01:56,  1.30it/s]  3% 446/14661 [05:57<3:01:52,  1.30it/s]  3% 447/14661 [05:58<3:01:38,  1.30it/s]  3% 448/14661 [05:59<3:01:40,  1.30it/s]  3% 449/14661 [05:59<3:02:19,  1.30it/s]  3% 450/14661 [06:00<3:04:42,  1.28it/s]  3% 451/14661 [06:01<3:03:41,  1.29it/s]  3% 452/14661 [06:02<3:03:39,  1.29it/s]  3% 453/14661 [06:02<3:04:00,  1.29it/s]  3% 454/14661 [06:03<3:05:02,  1.28it/s]  3% 455/14661 [06:04<3:04:52,  1.28it/s]  3% 456/14661 [06:05<3:04:04,  1.29it/s]  3% 457/14661 [06:06<3:04:37,  1.28it/s]  3% 458/14661 [06:06<3:05:07,  1.28it/s]  3% 459/14661 [06:07<3:04:59,  1.28it/s]  3% 460/14661 [06:08<3:05:50,  1.27it/s]  3% 461/14661 [06:09<3:09:04,  1.25it/s]  3% 462/14661 [06:10<3:07:35,  1.26it/s]  3% 463/14661 [06:10<3:07:47,  1.26it/s]  3% 464/14661 [06:11<3:07:56,  1.26it/s]  3% 465/14661 [06:12<3:06:57,  1.27it/s]  3% 466/14661 [06:13<3:05:12,  1.28it/s]  3% 467/14661 [06:13<3:03:59,  1.29it/s]  3% 468/14661 [06:14<3:03:27,  1.29it/s]  3% 469/14661 [06:15<3:04:40,  1.28it/s]  3% 470/14661 [06:16<3:03:39,  1.29it/s]  3% 471/14661 [06:17<3:03:00,  1.29it/s]  3% 472/14661 [06:17<3:02:35,  1.30it/s]  3% 473/14661 [06:18<3:02:01,  1.30it/s]  3% 474/14661 [06:19<3:02:13,  1.30it/s]  3% 475/14661 [06:20<3:02:30,  1.30it/s]  3% 476/14661 [06:20<3:02:45,  1.29it/s]  3% 477/14661 [06:21<3:03:04,  1.29it/s]  3% 478/14661 [06:22<3:03:20,  1.29it/s]  3% 479/14661 [06:23<3:04:58,  1.28it/s]  3% 480/14661 [06:24<3:04:41,  1.28it/s]  3% 481/14661 [06:24<3:04:05,  1.28it/s]  3% 482/14661 [06:25<3:03:44,  1.29it/s]  3% 483/14661 [06:26<3:03:44,  1.29it/s]  3% 484/14661 [06:27<3:03:19,  1.29it/s]  3% 485/14661 [06:27<3:03:13,  1.29it/s]  3% 486/14661 [06:28<3:03:35,  1.29it/s]  3% 487/14661 [06:29<3:03:02,  1.29it/s]  3% 488/14661 [06:30<3:02:48,  1.29it/s]  3% 489/14661 [06:30<3:02:57,  1.29it/s]  3% 490/14661 [06:31<3:04:07,  1.28it/s]  3% 491/14661 [06:32<3:03:36,  1.29it/s]  3% 492/14661 [06:33<3:03:17,  1.29it/s]  3% 493/14661 [06:34<3:02:37,  1.29it/s]  3% 494/14661 [06:34<3:02:37,  1.29it/s]  3% 495/14661 [06:35<3:03:02,  1.29it/s]  3% 496/14661 [06:36<3:02:43,  1.29it/s]  3% 497/14661 [06:37<3:02:33,  1.29it/s]  3% 498/14661 [06:37<3:04:07,  1.28it/s]  3% 499/14661 [06:38<3:05:43,  1.27it/s]  3% 500/14661 [06:39<3:06:05,  1.27it/s]  3% 501/14661 [06:40<3:05:10,  1.27it/s]  3% 502/14661 [06:41<3:04:32,  1.28it/s]  3% 503/14661 [06:41<3:03:48,  1.28it/s]  3% 504/14661 [06:42<3:03:05,  1.29it/s]  3% 505/14661 [06:43<3:03:06,  1.29it/s]  3% 506/14661 [06:44<3:02:34,  1.29it/s]  3% 507/14661 [06:45<3:03:21,  1.29it/s]  3% 508/14661 [06:45<3:03:57,  1.28it/s]  3% 509/14661 [06:46<3:04:36,  1.28it/s]  3% 510/14661 [06:47<3:04:03,  1.28it/s]  3% 511/14661 [06:48<3:04:41,  1.28it/s]  3% 512/14661 [06:48<3:04:14,  1.28it/s]  3% 513/14661 [06:49<3:04:03,  1.28it/s]  4% 514/14661 [06:50<3:04:22,  1.28it/s]  4% 515/14661 [06:51<3:05:07,  1.27it/s]  4% 516/14661 [06:52<3:09:15,  1.25it/s]  4% 517/14661 [06:52<3:09:54,  1.24it/s]  4% 518/14661 [06:53<3:09:29,  1.24it/s]  4% 519/14661 [06:54<3:07:00,  1.26it/s]  4% 520/14661 [06:55<3:06:42,  1.26it/s]  4% 521/14661 [06:56<3:06:40,  1.26it/s]  4% 522/14661 [06:56<3:05:54,  1.27it/s]  4% 523/14661 [06:57<3:05:52,  1.27it/s]  4% 524/14661 [06:58<3:05:08,  1.27it/s]  4% 525/14661 [06:59<3:04:11,  1.28it/s]  4% 526/14661 [06:59<3:05:08,  1.27it/s]  4% 527/14661 [07:00<3:05:56,  1.27it/s]  4% 528/14661 [07:01<3:05:55,  1.27it/s]  4% 529/14661 [07:02<3:04:44,  1.27it/s]  4% 530/14661 [07:03<3:04:54,  1.27it/s]  4% 531/14661 [07:03<3:03:35,  1.28it/s]  4% 532/14661 [07:04<3:05:44,  1.27it/s]  4% 533/14661 [07:05<3:06:40,  1.26it/s]  4% 534/14661 [07:06<3:07:09,  1.26it/s]  4% 535/14661 [07:07<3:06:31,  1.26it/s]  4% 536/14661 [07:07<3:05:22,  1.27it/s]  4% 537/14661 [07:08<3:05:25,  1.27it/s]  4% 538/14661 [07:09<3:05:48,  1.27it/s]  4% 539/14661 [07:10<3:05:28,  1.27it/s]  4% 540/14661 [07:11<3:06:13,  1.26it/s]  4% 541/14661 [07:11<3:05:22,  1.27it/s]  4% 542/14661 [07:12<3:05:14,  1.27it/s]  4% 543/14661 [07:13<3:05:25,  1.27it/s]  4% 544/14661 [07:14<3:04:02,  1.28it/s]  4% 545/14661 [07:14<3:03:32,  1.28it/s]  4% 546/14661 [07:15<3:03:32,  1.28it/s]  4% 547/14661 [07:16<3:03:14,  1.28it/s]  4% 548/14661 [07:17<3:03:11,  1.28it/s]  4% 549/14661 [07:18<3:03:13,  1.28it/s]  4% 550/14661 [07:18<3:03:05,  1.28it/s]  4% 551/14661 [07:19<3:02:45,  1.29it/s]  4% 552/14661 [07:20<3:01:40,  1.29it/s]  4% 553/14661 [07:21<3:03:49,  1.28it/s]  4% 554/14661 [07:21<3:02:52,  1.29it/s]  4% 555/14661 [07:22<3:04:25,  1.27it/s]  4% 556/14661 [07:23<3:03:42,  1.28it/s]  4% 557/14661 [07:24<3:02:58,  1.28it/s]  4% 558/14661 [07:25<3:02:21,  1.29it/s]  4% 559/14661 [07:25<3:01:43,  1.29it/s]  4% 560/14661 [07:26<3:02:31,  1.29it/s]  4% 561/14661 [07:27<3:01:42,  1.29it/s]  4% 562/14661 [07:28<3:01:44,  1.29it/s]  4% 563/14661 [07:28<3:00:52,  1.30it/s]  4% 564/14661 [07:29<3:00:36,  1.30it/s]  4% 565/14661 [07:30<3:00:48,  1.30it/s]  4% 566/14661 [07:31<3:00:26,  1.30it/s]  4% 567/14661 [07:31<3:00:09,  1.30it/s]  4% 568/14661 [07:32<2:59:33,  1.31it/s]  4% 569/14661 [07:33<2:59:42,  1.31it/s]  4% 570/14661 [07:34<2:59:38,  1.31it/s]  4% 571/14661 [07:35<2:59:43,  1.31it/s]  4% 572/14661 [07:35<2:59:04,  1.31it/s]  4% 573/14661 [07:36<3:01:16,  1.30it/s]  4% 574/14661 [07:37<3:03:23,  1.28it/s]  4% 575/14661 [07:38<3:03:02,  1.28it/s]  4% 576/14661 [07:38<3:03:04,  1.28it/s]  4% 577/14661 [07:39<3:04:03,  1.28it/s]  4% 578/14661 [07:40<3:04:24,  1.27it/s]  4% 579/14661 [07:41<3:04:28,  1.27it/s]  4% 580/14661 [07:42<3:03:15,  1.28it/s]  4% 581/14661 [07:42<3:03:37,  1.28it/s]  4% 582/14661 [07:43<3:03:55,  1.28it/s]  4% 583/14661 [07:44<3:04:33,  1.27it/s]  4% 584/14661 [07:45<3:04:50,  1.27it/s]  4% 585/14661 [07:46<3:05:15,  1.27it/s]  4% 586/14661 [07:46<3:02:55,  1.28it/s]  4% 587/14661 [07:47<3:02:56,  1.28it/s]  4% 588/14661 [07:48<3:03:28,  1.28it/s]  4% 589/14661 [07:49<3:05:37,  1.26it/s]  4% 590/14661 [07:49<3:05:45,  1.26it/s]  4% 591/14661 [07:50<3:03:49,  1.28it/s]  4% 592/14661 [07:51<3:04:25,  1.27it/s]  4% 593/14661 [07:52<3:07:06,  1.25it/s]  4% 594/14661 [07:53<3:06:42,  1.26it/s]  4% 595/14661 [07:53<3:06:58,  1.25it/s]  4% 596/14661 [07:54<3:07:45,  1.25it/s]  4% 597/14661 [07:55<3:05:42,  1.26it/s]  4% 598/14661 [07:56<3:05:46,  1.26it/s]  4% 599/14661 [07:57<3:06:01,  1.26it/s]  4% 600/14661 [07:57<3:05:33,  1.26it/s]  4% 601/14661 [07:58<3:07:40,  1.25it/s]  4% 602/14661 [07:59<3:06:47,  1.25it/s]  4% 603/14661 [08:00<3:07:13,  1.25it/s]  4% 604/14661 [08:01<3:06:39,  1.26it/s]  4% 605/14661 [08:01<3:06:13,  1.26it/s]  4% 606/14661 [08:02<3:06:03,  1.26it/s]  4% 607/14661 [08:03<3:06:00,  1.26it/s]  4% 608/14661 [08:04<3:05:27,  1.26it/s]  4% 609/14661 [08:05<3:04:44,  1.27it/s]  4% 610/14661 [08:05<3:04:26,  1.27it/s]  4% 611/14661 [08:06<3:06:37,  1.25it/s]  4% 612/14661 [08:07<3:07:17,  1.25it/s]  4% 613/14661 [08:08<3:06:43,  1.25it/s]  4% 614/14661 [08:09<3:05:08,  1.26it/s]  4% 615/14661 [08:09<3:03:46,  1.27it/s]  4% 616/14661 [08:10<3:03:22,  1.28it/s]  4% 617/14661 [08:11<3:03:16,  1.28it/s]  4% 618/14661 [08:12<3:02:59,  1.28it/s]  4% 619/14661 [08:12<3:02:53,  1.28it/s]  4% 620/14661 [08:13<3:03:56,  1.27it/s]  4% 621/14661 [08:14<3:03:09,  1.28it/s]  4% 622/14661 [08:15<3:02:18,  1.28it/s]  4% 623/14661 [08:16<3:03:51,  1.27it/s]  4% 624/14661 [08:16<3:03:44,  1.27it/s]  4% 625/14661 [08:17<3:03:09,  1.28it/s]  4% 626/14661 [08:18<3:02:18,  1.28it/s]  4% 627/14661 [08:19<3:02:25,  1.28it/s]  4% 628/14661 [08:19<3:02:25,  1.28it/s]  4% 629/14661 [08:20<3:03:40,  1.27it/s]  4% 630/14661 [08:21<3:03:40,  1.27it/s]  4% 631/14661 [08:22<3:02:47,  1.28it/s]  4% 632/14661 [08:23<3:02:18,  1.28it/s]  4% 633/14661 [08:23<3:01:54,  1.29it/s]  4% 634/14661 [08:24<3:01:52,  1.29it/s]  4% 635/14661 [08:25<3:01:34,  1.29it/s]  4% 636/14661 [08:26<3:02:33,  1.28it/s]  4% 637/14661 [08:27<3:03:04,  1.28it/s]  4% 638/14661 [08:27<3:02:43,  1.28it/s]  4% 639/14661 [08:28<3:02:23,  1.28it/s]  4% 640/14661 [08:29<3:02:22,  1.28it/s]  4% 641/14661 [08:30<3:03:21,  1.27it/s]  4% 642/14661 [08:30<3:02:39,  1.28it/s]  4% 643/14661 [08:31<3:03:27,  1.27it/s]  4% 644/14661 [08:32<3:03:41,  1.27it/s]  4% 645/14661 [08:33<3:02:38,  1.28it/s]  4% 646/14661 [08:34<3:01:48,  1.28it/s]  4% 647/14661 [08:34<3:02:43,  1.28it/s]  4% 648/14661 [08:35<3:02:43,  1.28it/s]  4% 649/14661 [08:36<3:04:14,  1.27it/s]  4% 650/14661 [08:37<3:04:53,  1.26it/s]  4% 651/14661 [08:37<3:04:54,  1.26it/s]  4% 652/14661 [08:38<3:04:44,  1.26it/s]  4% 653/14661 [08:39<3:04:32,  1.27it/s]  4% 654/14661 [08:40<3:04:39,  1.26it/s]  4% 655/14661 [08:41<3:04:56,  1.26it/s]  4% 656/14661 [08:41<3:03:25,  1.27it/s]  4% 657/14661 [08:42<3:02:20,  1.28it/s]  4% 658/14661 [08:43<3:02:08,  1.28it/s]  4% 659/14661 [08:44<3:02:27,  1.28it/s]  5% 660/14661 [08:45<3:02:24,  1.28it/s]  5% 661/14661 [08:45<3:02:41,  1.28it/s]  5% 662/14661 [08:46<3:02:26,  1.28it/s]  5% 663/14661 [08:47<3:02:48,  1.28it/s]  5% 664/14661 [08:48<3:02:01,  1.28it/s]  5% 665/14661 [08:48<3:01:45,  1.28it/s]  5% 666/14661 [08:49<3:01:49,  1.28it/s]  5% 667/14661 [08:50<3:02:19,  1.28it/s]  5% 668/14661 [08:51<3:01:11,  1.29it/s]  5% 669/14661 [08:52<3:01:45,  1.28it/s]  5% 670/14661 [08:52<3:02:50,  1.28it/s]  5% 671/14661 [08:53<3:02:18,  1.28it/s]  5% 672/14661 [08:54<3:01:15,  1.29it/s]  5% 673/14661 [08:55<3:00:38,  1.29it/s]  5% 674/14661 [08:55<3:00:15,  1.29it/s]  5% 675/14661 [08:56<3:00:35,  1.29it/s]  5% 676/14661 [08:57<3:00:49,  1.29it/s]  5% 677/14661 [08:58<3:02:23,  1.28it/s]  5% 678/14661 [08:59<3:01:55,  1.28it/s]  5% 679/14661 [08:59<3:02:00,  1.28it/s]  5% 680/14661 [09:00<3:02:14,  1.28it/s]  5% 681/14661 [09:01<3:02:36,  1.28it/s]  5% 682/14661 [09:02<3:01:42,  1.28it/s]  5% 683/14661 [09:03<3:02:48,  1.27it/s]  5% 684/14661 [09:03<3:01:54,  1.28it/s]  5% 685/14661 [09:04<3:02:44,  1.27it/s]  5% 686/14661 [09:05<3:01:39,  1.28it/s]  5% 687/14661 [09:06<3:01:25,  1.28it/s]  5% 688/14661 [09:06<3:01:11,  1.29it/s]  5% 689/14661 [09:07<3:00:40,  1.29it/s]  5% 690/14661 [09:08<3:01:13,  1.28it/s]  5% 691/14661 [09:09<3:00:45,  1.29it/s]  5% 692/14661 [09:09<3:00:34,  1.29it/s]  5% 693/14661 [09:10<3:01:17,  1.28it/s]  5% 694/14661 [09:11<3:01:29,  1.28it/s]  5% 695/14661 [09:12<3:01:31,  1.28it/s]  5% 696/14661 [09:13<3:02:23,  1.28it/s]  5% 697/14661 [09:13<3:03:18,  1.27it/s]  5% 698/14661 [09:14<3:01:59,  1.28it/s]  5% 699/14661 [09:15<3:01:24,  1.28it/s]  5% 700/14661 [09:16<3:01:27,  1.28it/s]  5% 701/14661 [09:17<3:01:09,  1.28it/s]  5% 702/14661 [09:17<3:01:29,  1.28it/s]  5% 703/14661 [09:18<3:01:33,  1.28it/s]  5% 704/14661 [09:19<3:01:50,  1.28it/s]  5% 705/14661 [09:20<3:01:55,  1.28it/s]  5% 706/14661 [09:20<3:02:20,  1.28it/s]  5% 707/14661 [09:21<3:02:05,  1.28it/s]  5% 708/14661 [09:22<3:03:14,  1.27it/s]  5% 709/14661 [09:23<3:02:19,  1.28it/s]  5% 710/14661 [09:24<3:01:23,  1.28it/s]  5% 711/14661 [09:24<3:01:25,  1.28it/s]  5% 712/14661 [09:25<3:01:42,  1.28it/s]  5% 713/14661 [09:26<3:00:58,  1.28it/s]  5% 714/14661 [09:27<3:01:00,  1.28it/s]  5% 715/14661 [09:27<3:01:17,  1.28it/s]  5% 716/14661 [09:28<3:01:45,  1.28it/s]  5% 717/14661 [09:29<3:01:41,  1.28it/s]  5% 718/14661 [09:30<3:02:35,  1.27it/s]  5% 719/14661 [09:31<3:02:28,  1.27it/s]  5% 720/14661 [09:31<3:01:37,  1.28it/s]  5% 721/14661 [09:32<3:03:11,  1.27it/s]  5% 722/14661 [09:33<3:04:48,  1.26it/s]  5% 723/14661 [09:34<3:02:47,  1.27it/s]  5% 724/14661 [09:35<3:01:24,  1.28it/s]  5% 725/14661 [09:35<3:00:28,  1.29it/s]  5% 726/14661 [09:36<2:59:45,  1.29it/s]  5% 727/14661 [09:37<2:59:38,  1.29it/s]  5% 728/14661 [09:38<2:59:58,  1.29it/s]  5% 729/14661 [09:38<2:59:31,  1.29it/s]  5% 730/14661 [09:39<2:59:19,  1.29it/s]  5% 731/14661 [09:40<2:59:07,  1.30it/s]  5% 732/14661 [09:41<2:58:50,  1.30it/s]  5% 733/14661 [09:41<2:58:38,  1.30it/s]  5% 734/14661 [09:42<2:58:19,  1.30it/s]  5% 735/14661 [09:43<2:58:16,  1.30it/s]  5% 736/14661 [09:44<2:58:29,  1.30it/s]  5% 737/14661 [09:45<2:58:42,  1.30it/s]  5% 738/14661 [09:45<2:58:38,  1.30it/s]  5% 739/14661 [09:46<2:58:59,  1.30it/s]  5% 740/14661 [09:47<3:01:28,  1.28it/s]  5% 741/14661 [09:48<3:00:48,  1.28it/s]  5% 742/14661 [09:48<3:00:05,  1.29it/s]  5% 743/14661 [09:49<2:59:45,  1.29it/s]  5% 744/14661 [09:50<2:59:38,  1.29it/s]  5% 745/14661 [09:51<2:59:20,  1.29it/s]  5% 746/14661 [09:52<2:58:58,  1.30it/s]  5% 747/14661 [09:52<2:59:09,  1.29it/s]  5% 748/14661 [09:53<2:58:49,  1.30it/s]  5% 749/14661 [09:54<2:58:28,  1.30it/s]  5% 750/14661 [09:55<2:58:47,  1.30it/s]  5% 751/14661 [09:55<2:59:07,  1.29it/s]  5% 752/14661 [09:56<3:00:59,  1.28it/s]  5% 753/14661 [09:57<3:01:34,  1.28it/s]  5% 754/14661 [09:58<3:01:34,  1.28it/s]  5% 755/14661 [09:59<3:01:51,  1.27it/s]  5% 756/14661 [09:59<3:03:02,  1.27it/s]  5% 757/14661 [10:00<3:02:45,  1.27it/s]  5% 758/14661 [10:01<3:02:03,  1.27it/s]  5% 759/14661 [10:02<3:02:40,  1.27it/s]  5% 760/14661 [10:03<3:04:48,  1.25it/s]  5% 761/14661 [10:03<3:05:50,  1.25it/s]  5% 762/14661 [10:04<3:04:32,  1.26it/s]  5% 763/14661 [10:05<3:02:41,  1.27it/s]  5% 764/14661 [10:06<3:01:45,  1.27it/s]  5% 765/14661 [10:06<3:00:24,  1.28it/s]  5% 766/14661 [10:07<2:59:31,  1.29it/s]  5% 767/14661 [10:08<2:59:05,  1.29it/s]  5% 768/14661 [10:09<2:58:44,  1.30it/s]  5% 769/14661 [10:10<2:58:25,  1.30it/s]  5% 770/14661 [10:10<2:58:24,  1.30it/s]  5% 771/14661 [10:11<2:58:10,  1.30it/s]  5% 772/14661 [10:12<2:59:37,  1.29it/s]  5% 773/14661 [10:13<3:00:06,  1.29it/s]  5% 774/14661 [10:13<2:59:31,  1.29it/s]  5% 775/14661 [10:14<2:58:46,  1.29it/s]  5% 776/14661 [10:15<2:58:38,  1.30it/s]  5% 777/14661 [10:16<2:59:45,  1.29it/s]  5% 778/14661 [10:16<3:00:15,  1.28it/s]  5% 779/14661 [10:17<3:00:43,  1.28it/s]  5% 780/14661 [10:18<3:01:28,  1.27it/s]  5% 781/14661 [10:19<3:01:44,  1.27it/s]  5% 782/14661 [10:20<3:02:50,  1.27it/s]  5% 783/14661 [10:20<3:01:47,  1.27it/s]  5% 784/14661 [10:21<3:00:10,  1.28it/s]  5% 785/14661 [10:22<3:01:14,  1.28it/s]  5% 786/14661 [10:23<3:01:33,  1.27it/s]  5% 787/14661 [10:24<3:01:19,  1.28it/s]  5% 788/14661 [10:24<3:00:33,  1.28it/s]  5% 789/14661 [10:25<3:00:27,  1.28it/s]  5% 790/14661 [10:26<3:01:03,  1.28it/s]  5% 791/14661 [10:27<3:00:36,  1.28it/s]  5% 792/14661 [10:27<2:59:36,  1.29it/s]  5% 793/14661 [10:28<2:58:59,  1.29it/s]  5% 794/14661 [10:29<2:58:48,  1.29it/s]  5% 795/14661 [10:30<2:58:39,  1.29it/s]  5% 796/14661 [10:31<2:58:18,  1.30it/s]  5% 797/14661 [10:31<3:01:29,  1.27it/s]  5% 798/14661 [10:32<3:01:03,  1.28it/s]  5% 799/14661 [10:33<3:00:54,  1.28it/s]  5% 800/14661 [10:34<3:01:14,  1.27it/s]  5% 801/14661 [10:34<3:00:37,  1.28it/s]  5% 802/14661 [10:35<3:00:41,  1.28it/s]  5% 803/14661 [10:36<3:00:07,  1.28it/s]  5% 804/14661 [10:37<2:59:32,  1.29it/s]  5% 805/14661 [10:38<3:00:17,  1.28it/s]  5% 806/14661 [10:38<3:00:47,  1.28it/s]  6% 807/14661 [10:39<2:59:42,  1.28it/s]  6% 808/14661 [10:40<2:59:59,  1.28it/s]  6% 809/14661 [10:41<2:59:15,  1.29it/s]  6% 810/14661 [10:41<2:58:34,  1.29it/s]  6% 811/14661 [10:42<2:58:02,  1.30it/s]  6% 812/14661 [10:43<2:59:12,  1.29it/s]  6% 813/14661 [10:44<2:59:03,  1.29it/s]  6% 814/14661 [10:45<2:59:32,  1.29it/s]  6% 815/14661 [10:45<3:00:51,  1.28it/s]  6% 816/14661 [10:46<3:01:50,  1.27it/s]  6% 817/14661 [10:47<3:00:34,  1.28it/s]  6% 818/14661 [10:48<3:01:04,  1.27it/s]  6% 819/14661 [10:49<3:00:06,  1.28it/s]  6% 820/14661 [10:49<3:01:29,  1.27it/s]  6% 821/14661 [10:50<3:00:46,  1.28it/s]  6% 822/14661 [10:51<3:00:05,  1.28it/s]  6% 823/14661 [10:52<2:59:29,  1.28it/s]  6% 824/14661 [10:52<2:58:54,  1.29it/s]  6% 825/14661 [10:53<2:59:15,  1.29it/s]  6% 826/14661 [10:54<3:00:13,  1.28it/s]  6% 827/14661 [10:55<2:59:38,  1.28it/s]  6% 828/14661 [10:56<2:59:26,  1.28it/s]  6% 829/14661 [10:56<2:59:05,  1.29it/s]  6% 830/14661 [10:57<2:59:40,  1.28it/s]  6% 831/14661 [10:58<3:00:00,  1.28it/s]  6% 832/14661 [10:59<2:59:17,  1.29it/s]  6% 833/14661 [10:59<3:00:16,  1.28it/s]  6% 834/14661 [11:00<3:01:06,  1.27it/s]  6% 835/14661 [11:01<3:00:23,  1.28it/s]  6% 836/14661 [11:02<3:00:25,  1.28it/s]  6% 837/14661 [11:03<3:00:49,  1.27it/s]  6% 838/14661 [11:03<3:04:43,  1.25it/s]  6% 839/14661 [11:04<3:03:06,  1.26it/s]  6% 840/14661 [11:05<3:01:39,  1.27it/s]  6% 841/14661 [11:06<3:01:14,  1.27it/s]  6% 842/14661 [11:07<3:00:53,  1.27it/s]  6% 843/14661 [11:07<2:59:53,  1.28it/s]  6% 844/14661 [11:08<3:00:28,  1.28it/s]  6% 845/14661 [11:09<3:01:56,  1.27it/s]  6% 846/14661 [11:10<3:00:40,  1.27it/s]  6% 847/14661 [11:10<3:00:22,  1.28it/s]  6% 848/14661 [11:11<3:01:46,  1.27it/s]  6% 849/14661 [11:12<3:00:59,  1.27it/s]  6% 850/14661 [11:13<2:59:37,  1.28it/s]  6% 851/14661 [11:14<3:02:57,  1.26it/s]  6% 852/14661 [11:14<3:02:56,  1.26it/s]  6% 853/14661 [11:15<3:01:44,  1.27it/s]  6% 854/14661 [11:16<3:00:17,  1.28it/s]  6% 855/14661 [11:17<2:59:26,  1.28it/s]  6% 856/14661 [11:18<2:58:26,  1.29it/s]  6% 857/14661 [11:18<2:59:07,  1.28it/s]  6% 858/14661 [11:19<2:58:30,  1.29it/s]  6% 859/14661 [11:20<2:59:05,  1.28it/s]  6% 860/14661 [11:21<2:58:22,  1.29it/s]  6% 861/14661 [11:21<2:57:53,  1.29it/s]  6% 862/14661 [11:22<2:57:25,  1.30it/s]  6% 863/14661 [11:23<2:58:03,  1.29it/s]  6% 864/14661 [11:24<2:59:39,  1.28it/s]  6% 865/14661 [11:24<2:58:59,  1.28it/s]  6% 866/14661 [11:25<2:58:51,  1.29it/s]  6% 867/14661 [11:26<2:59:49,  1.28it/s]  6% 868/14661 [11:27<3:01:06,  1.27it/s]  6% 869/14661 [11:28<3:00:12,  1.28it/s]  6% 870/14661 [11:28<2:59:58,  1.28it/s]  6% 871/14661 [11:29<3:00:56,  1.27it/s]  6% 872/14661 [11:30<3:02:22,  1.26it/s]  6% 873/14661 [11:31<3:01:16,  1.27it/s]  6% 874/14661 [11:32<2:59:58,  1.28it/s]  6% 875/14661 [11:32<2:59:03,  1.28it/s]  6% 876/14661 [11:33<2:58:25,  1.29it/s]  6% 877/14661 [11:34<2:57:59,  1.29it/s]  6% 878/14661 [11:35<2:58:34,  1.29it/s]  6% 879/14661 [11:35<2:58:55,  1.28it/s]  6% 880/14661 [11:36<2:58:26,  1.29it/s]  6% 881/14661 [11:37<2:59:06,  1.28it/s]  6% 882/14661 [11:38<2:58:11,  1.29it/s]  6% 883/14661 [11:39<2:57:50,  1.29it/s]  6% 884/14661 [11:39<2:58:29,  1.29it/s]  6% 885/14661 [11:40<2:58:58,  1.28it/s]  6% 886/14661 [11:41<2:59:16,  1.28it/s]  6% 887/14661 [11:42<2:59:39,  1.28it/s]  6% 888/14661 [11:42<2:59:03,  1.28it/s]  6% 889/14661 [11:43<2:58:39,  1.28it/s]  6% 890/14661 [11:44<3:02:28,  1.26it/s]  6% 891/14661 [11:45<3:01:51,  1.26it/s]  6% 892/14661 [11:46<3:00:58,  1.27it/s]  6% 893/14661 [11:46<3:00:30,  1.27it/s]  6% 894/14661 [11:47<3:00:33,  1.27it/s]  6% 895/14661 [11:48<3:00:43,  1.27it/s]  6% 896/14661 [11:49<3:01:41,  1.26it/s]  6% 897/14661 [11:50<3:01:36,  1.26it/s]  6% 898/14661 [11:50<3:00:11,  1.27it/s]  6% 899/14661 [11:51<3:00:25,  1.27it/s]  6% 900/14661 [11:52<2:59:58,  1.27it/s]  6% 901/14661 [11:53<3:01:24,  1.26it/s]  6% 902/14661 [11:54<3:00:02,  1.27it/s]  6% 903/14661 [11:54<2:59:10,  1.28it/s]  6% 904/14661 [11:55<3:00:51,  1.27it/s]  6% 905/14661 [11:56<3:01:09,  1.27it/s]  6% 906/14661 [11:57<3:00:56,  1.27it/s]  6% 907/14661 [11:57<3:00:14,  1.27it/s]  6% 908/14661 [11:58<3:00:10,  1.27it/s]  6% 909/14661 [11:59<2:59:16,  1.28it/s]  6% 910/14661 [12:00<2:58:05,  1.29it/s]  6% 911/14661 [12:01<2:57:52,  1.29it/s]  6% 912/14661 [12:01<2:58:28,  1.28it/s]  6% 913/14661 [12:02<2:58:27,  1.28it/s]  6% 914/14661 [12:03<2:58:25,  1.28it/s]  6% 915/14661 [12:04<2:57:55,  1.29it/s]  6% 916/14661 [12:04<2:57:08,  1.29it/s]  6% 917/14661 [12:05<2:56:47,  1.30it/s]  6% 918/14661 [12:06<2:57:14,  1.29it/s]  6% 919/14661 [12:07<2:57:23,  1.29it/s]  6% 920/14661 [12:08<2:58:01,  1.29it/s]  6% 921/14661 [12:08<2:57:44,  1.29it/s]  6% 922/14661 [12:09<2:57:12,  1.29it/s]  6% 923/14661 [12:10<2:57:31,  1.29it/s]  6% 924/14661 [12:11<2:57:53,  1.29it/s]  6% 925/14661 [12:11<2:57:32,  1.29it/s]  6% 926/14661 [12:12<2:56:51,  1.29it/s]  6% 927/14661 [12:13<2:57:24,  1.29it/s]  6% 928/14661 [12:14<2:57:06,  1.29it/s]  6% 929/14661 [12:14<2:56:41,  1.30it/s]  6% 930/14661 [12:15<2:56:28,  1.30it/s]  6% 931/14661 [12:16<2:56:23,  1.30it/s]  6% 932/14661 [12:17<2:56:41,  1.30it/s]  6% 933/14661 [12:18<2:56:34,  1.30it/s]  6% 934/14661 [12:18<2:57:14,  1.29it/s]  6% 935/14661 [12:19<2:57:10,  1.29it/s]  6% 936/14661 [12:20<2:57:44,  1.29it/s]  6% 937/14661 [12:21<2:58:00,  1.28it/s]  6% 938/14661 [12:21<2:58:07,  1.28it/s]  6% 939/14661 [12:22<3:00:46,  1.27it/s]  6% 940/14661 [12:23<3:03:07,  1.25it/s]  6% 941/14661 [12:24<3:02:27,  1.25it/s]  6% 942/14661 [12:25<3:00:40,  1.27it/s]  6% 943/14661 [12:25<3:02:30,  1.25it/s]  6% 944/14661 [12:26<3:02:26,  1.25it/s]  6% 945/14661 [12:27<3:00:37,  1.27it/s]  6% 946/14661 [12:28<3:00:20,  1.27it/s]  6% 947/14661 [12:29<3:00:54,  1.26it/s]  6% 948/14661 [12:29<3:01:06,  1.26it/s]  6% 949/14661 [12:30<2:59:39,  1.27it/s]  6% 950/14661 [12:31<2:59:09,  1.28it/s]  6% 951/14661 [12:32<2:59:50,  1.27it/s]  6% 952/14661 [12:33<3:01:47,  1.26it/s]  7% 953/14661 [12:33<3:01:11,  1.26it/s]  7% 954/14661 [12:34<2:59:48,  1.27it/s]  7% 955/14661 [12:35<2:58:43,  1.28it/s]  7% 956/14661 [12:36<2:58:18,  1.28it/s]  7% 957/14661 [12:36<2:58:29,  1.28it/s]  7% 958/14661 [12:37<2:58:59,  1.28it/s]  7% 959/14661 [12:38<2:59:43,  1.27it/s]  7% 960/14661 [12:39<2:59:19,  1.27it/s]  7% 961/14661 [12:40<2:59:13,  1.27it/s]  7% 962/14661 [12:40<2:58:22,  1.28it/s]  7% 963/14661 [12:41<2:57:56,  1.28it/s]  7% 964/14661 [12:42<3:00:30,  1.26it/s]  7% 965/14661 [12:43<2:59:52,  1.27it/s]  7% 966/14661 [12:44<2:59:15,  1.27it/s]  7% 967/14661 [12:44<2:59:20,  1.27it/s]  7% 968/14661 [12:45<2:58:55,  1.28it/s]  7% 969/14661 [12:46<2:58:08,  1.28it/s]  7% 970/14661 [12:47<2:58:28,  1.28it/s]  7% 971/14661 [12:47<2:58:14,  1.28it/s]  7% 972/14661 [12:48<3:00:14,  1.27it/s]  7% 973/14661 [12:49<2:58:29,  1.28it/s]  7% 974/14661 [12:50<2:58:30,  1.28it/s]  7% 975/14661 [12:51<3:00:29,  1.26it/s]  7% 976/14661 [12:51<3:00:22,  1.26it/s]  7% 977/14661 [12:52<2:58:38,  1.28it/s]  7% 978/14661 [12:53<2:58:46,  1.28it/s]  7% 979/14661 [12:54<2:59:26,  1.27it/s]  7% 980/14661 [12:55<3:01:54,  1.25it/s]  7% 981/14661 [12:55<3:00:02,  1.27it/s]  7% 982/14661 [12:56<2:58:35,  1.28it/s]  7% 983/14661 [12:57<2:57:51,  1.28it/s]  7% 984/14661 [12:58<2:57:23,  1.29it/s]  7% 985/14661 [12:58<2:57:27,  1.28it/s]  7% 986/14661 [12:59<2:58:29,  1.28it/s]  7% 987/14661 [13:00<2:59:10,  1.27it/s]  7% 988/14661 [13:01<2:58:50,  1.27it/s]  7% 989/14661 [13:02<2:57:34,  1.28it/s]  7% 990/14661 [13:02<2:56:44,  1.29it/s]  7% 991/14661 [13:03<2:55:59,  1.29it/s]  7% 992/14661 [13:04<2:55:32,  1.30it/s]  7% 993/14661 [13:05<2:56:41,  1.29it/s]  7% 994/14661 [13:05<2:57:06,  1.29it/s]  7% 995/14661 [13:06<2:58:13,  1.28it/s]  7% 996/14661 [13:07<2:59:00,  1.27it/s]  7% 997/14661 [13:08<2:59:35,  1.27it/s]  7% 998/14661 [13:09<2:59:47,  1.27it/s]  7% 999/14661 [13:09<2:58:37,  1.27it/s]  7% 1000/14661 [13:10<2:57:37,  1.28it/s]  7% 1001/14661 [13:11<2:57:23,  1.28it/s]  7% 1002/14661 [13:12<2:56:44,  1.29it/s]  7% 1003/14661 [13:13<2:57:18,  1.28it/s]  7% 1004/14661 [13:13<2:56:38,  1.29it/s]  7% 1005/14661 [13:14<2:59:55,  1.27it/s]  7% 1006/14661 [13:15<2:59:15,  1.27it/s]  7% 1007/14661 [13:16<2:58:30,  1.27it/s]  7% 1008/14661 [13:16<2:57:32,  1.28it/s]  7% 1009/14661 [13:17<2:56:58,  1.29it/s]  7% 1010/14661 [13:18<2:56:51,  1.29it/s]  7% 1011/14661 [13:19<2:56:48,  1.29it/s]  7% 1012/14661 [13:20<2:56:53,  1.29it/s]  7% 1013/14661 [13:20<2:59:28,  1.27it/s]  7% 1014/14661 [13:21<2:58:41,  1.27it/s]  7% 1015/14661 [13:22<2:58:55,  1.27it/s]  7% 1016/14661 [13:23<2:59:41,  1.27it/s]  7% 1017/14661 [13:24<2:58:35,  1.27it/s]  7% 1018/14661 [13:24<2:58:27,  1.27it/s]  7% 1019/14661 [13:25<2:58:36,  1.27it/s]  7% 1020/14661 [13:26<3:01:00,  1.26it/s]  7% 1021/14661 [13:27<3:00:08,  1.26it/s]  7% 1022/14661 [13:27<2:58:37,  1.27it/s]  7% 1023/14661 [13:28<2:57:37,  1.28it/s]  7% 1024/14661 [13:29<2:57:13,  1.28it/s]  7% 1025/14661 [13:30<2:56:25,  1.29it/s]  7% 1026/14661 [13:31<2:55:53,  1.29it/s]  7% 1027/14661 [13:31<2:55:18,  1.30it/s]  7% 1028/14661 [13:32<2:54:52,  1.30it/s]  7% 1029/14661 [13:33<2:55:16,  1.30it/s]  7% 1030/14661 [13:34<2:55:42,  1.29it/s]  7% 1031/14661 [13:34<2:56:51,  1.28it/s]  7% 1032/14661 [13:35<2:57:21,  1.28it/s]  7% 1033/14661 [13:36<2:56:41,  1.29it/s]  7% 1034/14661 [13:37<2:56:10,  1.29it/s]  7% 1035/14661 [13:38<2:55:44,  1.29it/s]  7% 1036/14661 [13:38<2:56:19,  1.29it/s]  7% 1037/14661 [13:39<2:56:52,  1.28it/s]  7% 1038/14661 [13:40<2:56:46,  1.28it/s]  7% 1039/14661 [13:41<2:55:52,  1.29it/s]  7% 1040/14661 [13:41<2:55:22,  1.29it/s]  7% 1041/14661 [13:42<2:54:59,  1.30it/s]  7% 1042/14661 [13:43<2:54:39,  1.30it/s]  7% 1043/14661 [13:44<2:54:27,  1.30it/s]  7% 1044/14661 [13:44<2:54:37,  1.30it/s]  7% 1045/14661 [13:45<2:55:12,  1.30it/s]  7% 1046/14661 [13:46<2:55:57,  1.29it/s]  7% 1047/14661 [13:47<2:55:40,  1.29it/s]  7% 1048/14661 [13:48<2:55:35,  1.29it/s]  7% 1049/14661 [13:48<2:56:20,  1.29it/s]  7% 1050/14661 [13:49<2:56:12,  1.29it/s]  7% 1051/14661 [13:50<2:57:27,  1.28it/s]  7% 1052/14661 [13:51<2:57:33,  1.28it/s]  7% 1053/14661 [13:52<3:00:19,  1.26it/s]  7% 1054/14661 [13:52<3:00:03,  1.26it/s]  7% 1055/14661 [13:53<2:58:23,  1.27it/s]  7% 1056/14661 [13:54<2:58:48,  1.27it/s]  7% 1057/14661 [13:55<2:59:42,  1.26it/s]  7% 1058/14661 [13:55<2:59:46,  1.26it/s]  7% 1059/14661 [13:56<2:59:08,  1.27it/s]  7% 1060/14661 [13:57<2:58:27,  1.27it/s]  7% 1061/14661 [13:58<2:57:46,  1.28it/s]  7% 1062/14661 [13:59<2:57:11,  1.28it/s]  7% 1063/14661 [13:59<2:57:36,  1.28it/s]  7% 1064/14661 [14:00<2:58:11,  1.27it/s]  7% 1065/14661 [14:01<2:58:25,  1.27it/s]  7% 1066/14661 [14:02<2:58:41,  1.27it/s]  7% 1067/14661 [14:03<2:58:09,  1.27it/s]  7% 1068/14661 [14:03<2:57:08,  1.28it/s]  7% 1069/14661 [14:04<2:58:03,  1.27it/s]  7% 1070/14661 [14:05<2:57:45,  1.27it/s]  7% 1071/14661 [14:06<2:57:06,  1.28it/s]  7% 1072/14661 [14:06<2:56:58,  1.28it/s]  7% 1073/14661 [14:07<2:57:02,  1.28it/s]  7% 1074/14661 [14:08<2:57:25,  1.28it/s]  7% 1075/14661 [14:09<2:57:48,  1.27it/s]  7% 1076/14661 [14:10<2:59:36,  1.26it/s]  7% 1077/14661 [14:10<2:59:31,  1.26it/s]  7% 1078/14661 [14:11<3:01:38,  1.25it/s]  7% 1079/14661 [14:12<2:59:43,  1.26it/s]  7% 1080/14661 [14:13<2:58:42,  1.27it/s]  7% 1081/14661 [14:14<2:57:49,  1.27it/s]  7% 1082/14661 [14:14<2:58:05,  1.27it/s]  7% 1083/14661 [14:15<2:58:55,  1.26it/s]  7% 1084/14661 [14:16<3:00:00,  1.26it/s]  7% 1085/14661 [14:17<3:00:50,  1.25it/s]  7% 1086/14661 [14:18<2:59:03,  1.26it/s]  7% 1087/14661 [14:18<2:57:42,  1.27it/s]  7% 1088/14661 [14:19<2:57:54,  1.27it/s]  7% 1089/14661 [14:20<2:57:32,  1.27it/s]  7% 1090/14661 [14:21<2:57:48,  1.27it/s]  7% 1091/14661 [14:21<2:58:05,  1.27it/s]  7% 1092/14661 [14:22<2:56:55,  1.28it/s]  7% 1093/14661 [14:23<2:55:55,  1.29it/s]  7% 1094/14661 [14:24<2:55:00,  1.29it/s]  7% 1095/14661 [14:25<2:57:33,  1.27it/s]  7% 1096/14661 [14:25<2:59:07,  1.26it/s]  7% 1097/14661 [14:26<2:58:32,  1.27it/s]  7% 1098/14661 [14:27<2:58:30,  1.27it/s]  7% 1099/14661 [14:28<2:57:11,  1.28it/s]  8% 1100/14661 [14:28<2:56:21,  1.28it/s]  8% 1101/14661 [14:29<2:58:14,  1.27it/s]  8% 1102/14661 [14:30<2:57:28,  1.27it/s]  8% 1103/14661 [14:31<2:57:04,  1.28it/s]  8% 1104/14661 [14:32<2:56:58,  1.28it/s]  8% 1105/14661 [14:32<2:57:33,  1.27it/s]  8% 1106/14661 [14:33<2:56:21,  1.28it/s]  8% 1107/14661 [14:34<2:57:23,  1.27it/s]  8% 1108/14661 [14:35<2:59:20,  1.26it/s]  8% 1109/14661 [14:36<2:59:56,  1.26it/s]  8% 1110/14661 [14:36<2:58:56,  1.26it/s]  8% 1111/14661 [14:37<2:57:01,  1.28it/s]  8% 1112/14661 [14:38<2:56:18,  1.28it/s]  8% 1113/14661 [14:39<2:56:07,  1.28it/s]  8% 1114/14661 [14:39<2:55:23,  1.29it/s]  8% 1115/14661 [14:40<2:55:28,  1.29it/s]  8% 1116/14661 [14:41<2:55:02,  1.29it/s]  8% 1117/14661 [14:42<2:54:13,  1.30it/s]  8% 1118/14661 [14:43<2:53:52,  1.30it/s]  8% 1119/14661 [14:43<2:53:40,  1.30it/s]  8% 1120/14661 [14:44<2:53:35,  1.30it/s]  8% 1121/14661 [14:45<2:53:31,  1.30it/s]  8% 1122/14661 [14:46<2:53:20,  1.30it/s]  8% 1123/14661 [14:46<2:53:19,  1.30it/s]  8% 1124/14661 [14:47<2:53:19,  1.30it/s]  8% 1125/14661 [14:48<2:53:21,  1.30it/s]  8% 1126/14661 [14:49<2:53:02,  1.30it/s]  8% 1127/14661 [14:49<2:53:08,  1.30it/s]  8% 1128/14661 [14:50<2:53:32,  1.30it/s]  8% 1129/14661 [14:51<2:53:58,  1.30it/s]  8% 1130/14661 [14:52<2:53:59,  1.30it/s]  8% 1131/14661 [14:53<2:54:59,  1.29it/s]  8% 1132/14661 [14:53<2:54:24,  1.29it/s]  8% 1133/14661 [14:54<2:55:59,  1.28it/s]  8% 1134/14661 [14:55<2:56:02,  1.28it/s]  8% 1135/14661 [14:56<2:56:31,  1.28it/s]  8% 1136/14661 [14:57<2:56:49,  1.27it/s]  8% 1137/14661 [14:57<2:57:21,  1.27it/s]  8% 1138/14661 [14:58<2:57:54,  1.27it/s]  8% 1139/14661 [14:59<2:56:44,  1.28it/s]  8% 1140/14661 [15:00<2:57:54,  1.27it/s]  8% 1141/14661 [15:00<2:58:37,  1.26it/s]  8% 1142/14661 [15:01<2:57:11,  1.27it/s]  8% 1143/14661 [15:02<2:55:58,  1.28it/s]  8% 1144/14661 [15:03<2:55:25,  1.28it/s]  8% 1145/14661 [15:04<2:54:58,  1.29it/s]  8% 1146/14661 [15:04<2:56:04,  1.28it/s]  8% 1147/14661 [15:05<2:57:54,  1.27it/s]  8% 1148/14661 [15:06<2:58:06,  1.26it/s]  8% 1149/14661 [15:07<2:56:47,  1.27it/s]  8% 1150/14661 [15:08<2:57:42,  1.27it/s]  8% 1151/14661 [15:08<2:58:16,  1.26it/s]  8% 1152/14661 [15:09<2:57:27,  1.27it/s]  8% 1153/14661 [15:10<2:56:47,  1.27it/s]  8% 1154/14661 [15:11<2:56:13,  1.28it/s]  8% 1155/14661 [15:11<2:57:05,  1.27it/s]  8% 1156/14661 [15:12<2:56:35,  1.27it/s]  8% 1157/14661 [15:13<2:55:47,  1.28it/s]  8% 1158/14661 [15:14<2:55:06,  1.29it/s]  8% 1159/14661 [15:15<2:55:01,  1.29it/s]  8% 1160/14661 [15:15<2:56:10,  1.28it/s]  8% 1161/14661 [15:16<2:56:25,  1.28it/s]  8% 1162/14661 [15:17<2:57:03,  1.27it/s]  8% 1163/14661 [15:18<2:55:35,  1.28it/s]  8% 1164/14661 [15:18<2:55:13,  1.28it/s]  8% 1165/14661 [15:19<2:56:40,  1.27it/s]  8% 1166/14661 [15:20<2:56:48,  1.27it/s]  8% 1167/14661 [15:21<2:55:54,  1.28it/s]  8% 1168/14661 [15:22<2:55:18,  1.28it/s]  8% 1169/14661 [15:22<2:55:47,  1.28it/s]  8% 1170/14661 [15:23<2:54:36,  1.29it/s]  8% 1171/14661 [15:24<2:53:34,  1.30it/s]  8% 1172/14661 [15:25<2:52:57,  1.30it/s]  8% 1173/14661 [15:25<2:52:45,  1.30it/s]  8% 1174/14661 [15:26<2:52:32,  1.30it/s]  8% 1175/14661 [15:27<2:52:28,  1.30it/s]  8% 1176/14661 [15:28<2:52:34,  1.30it/s]  8% 1177/14661 [15:29<2:52:25,  1.30it/s]  8% 1178/14661 [15:29<2:52:42,  1.30it/s]  8% 1179/14661 [15:30<2:52:46,  1.30it/s]  8% 1180/14661 [15:31<2:53:07,  1.30it/s]  8% 1181/14661 [15:32<2:52:56,  1.30it/s]  8% 1182/14661 [15:32<2:53:09,  1.30it/s]  8% 1183/14661 [15:33<2:54:07,  1.29it/s]  8% 1184/14661 [15:34<2:55:25,  1.28it/s]  8% 1185/14661 [15:35<2:55:38,  1.28it/s]  8% 1186/14661 [15:36<2:55:13,  1.28it/s]  8% 1187/14661 [15:36<2:55:58,  1.28it/s]  8% 1188/14661 [15:37<2:55:05,  1.28it/s]  8% 1189/14661 [15:38<2:55:11,  1.28it/s]  8% 1190/14661 [15:39<2:54:20,  1.29it/s]  8% 1191/14661 [15:39<2:53:48,  1.29it/s]  8% 1192/14661 [15:40<2:54:01,  1.29it/s]  8% 1193/14661 [15:41<2:54:03,  1.29it/s]  8% 1194/14661 [15:42<2:53:44,  1.29it/s]  8% 1195/14661 [15:42<2:54:30,  1.29it/s]  8% 1196/14661 [15:43<2:54:03,  1.29it/s]  8% 1197/14661 [15:44<2:54:26,  1.29it/s]  8% 1198/14661 [15:45<2:53:43,  1.29it/s]  8% 1199/14661 [15:46<2:53:11,  1.30it/s]  8% 1200/14661 [15:46<2:53:04,  1.30it/s]  8% 1201/14661 [15:47<2:53:29,  1.29it/s]  8% 1202/14661 [15:48<2:55:07,  1.28it/s]  8% 1203/14661 [15:49<2:57:03,  1.27it/s]  8% 1204/14661 [15:50<2:55:27,  1.28it/s]  8% 1205/14661 [15:50<2:54:44,  1.28it/s]  8% 1206/14661 [15:51<2:54:40,  1.28it/s]  8% 1207/14661 [15:52<2:54:25,  1.29it/s]  8% 1208/14661 [15:53<2:53:54,  1.29it/s]  8% 1209/14661 [15:53<2:54:41,  1.28it/s]  8% 1210/14661 [15:54<2:53:56,  1.29it/s]  8% 1211/14661 [15:55<2:53:54,  1.29it/s]  8% 1212/14661 [15:56<2:54:49,  1.28it/s]  8% 1213/14661 [15:57<2:57:57,  1.26it/s]  8% 1214/14661 [15:57<2:57:34,  1.26it/s]  8% 1215/14661 [15:58<2:56:23,  1.27it/s]  8% 1216/14661 [15:59<2:55:26,  1.28it/s]  8% 1217/14661 [16:00<2:56:29,  1.27it/s]  8% 1218/14661 [16:00<2:56:33,  1.27it/s]  8% 1219/14661 [16:01<2:55:20,  1.28it/s]  8% 1220/14661 [16:02<2:58:37,  1.25it/s]  8% 1221/14661 [16:03<2:57:17,  1.26it/s]  8% 1222/14661 [16:04<2:55:53,  1.27it/s]  8% 1223/14661 [16:04<2:54:40,  1.28it/s]  8% 1224/14661 [16:05<2:53:29,  1.29it/s]  8% 1225/14661 [16:06<2:53:02,  1.29it/s]  8% 1226/14661 [16:07<2:52:46,  1.30it/s]  8% 1227/14661 [16:07<2:52:26,  1.30it/s]  8% 1228/14661 [16:08<2:52:35,  1.30it/s]  8% 1229/14661 [16:09<2:53:25,  1.29it/s]  8% 1230/14661 [16:10<2:54:00,  1.29it/s]  8% 1231/14661 [16:11<2:53:46,  1.29it/s]  8% 1232/14661 [16:11<2:55:15,  1.28it/s]  8% 1233/14661 [16:12<2:55:33,  1.27it/s]  8% 1234/14661 [16:13<2:54:55,  1.28it/s]  8% 1235/14661 [16:14<2:54:56,  1.28it/s]  8% 1236/14661 [16:14<2:54:39,  1.28it/s]  8% 1237/14661 [16:15<2:54:13,  1.28it/s]  8% 1238/14661 [16:16<2:53:49,  1.29it/s]  8% 1239/14661 [16:17<2:53:36,  1.29it/s]  8% 1240/14661 [16:18<2:53:17,  1.29it/s]  8% 1241/14661 [16:18<2:53:36,  1.29it/s]  8% 1242/14661 [16:19<2:53:38,  1.29it/s]  8% 1243/14661 [16:20<2:55:37,  1.27it/s]  8% 1244/14661 [16:21<2:54:56,  1.28it/s]  8% 1245/14661 [16:21<2:53:58,  1.29it/s]  8% 1246/14661 [16:22<2:53:27,  1.29it/s]  9% 1247/14661 [16:23<2:53:39,  1.29it/s]  9% 1248/14661 [16:24<2:53:29,  1.29it/s]  9% 1249/14661 [16:25<2:53:37,  1.29it/s]  9% 1250/14661 [16:25<2:52:58,  1.29it/s]  9% 1251/14661 [16:26<2:52:17,  1.30it/s]  9% 1252/14661 [16:27<2:52:50,  1.29it/s]  9% 1253/14661 [16:28<2:52:32,  1.30it/s]  9% 1254/14661 [16:28<2:51:57,  1.30it/s]  9% 1255/14661 [16:29<2:53:41,  1.29it/s]  9% 1256/14661 [16:30<2:52:12,  1.30it/s]  9% 1257/14661 [16:31<2:51:34,  1.30it/s]  9% 1258/14661 [16:32<2:51:01,  1.31it/s]  9% 1259/14661 [16:32<2:50:31,  1.31it/s]  9% 1260/14661 [16:33<2:50:43,  1.31it/s]  9% 1261/14661 [16:34<2:51:33,  1.30it/s]  9% 1262/14661 [16:35<2:51:20,  1.30it/s]  9% 1263/14661 [16:35<2:50:51,  1.31it/s]  9% 1264/14661 [16:36<2:51:16,  1.30it/s]  9% 1265/14661 [16:37<2:53:50,  1.28it/s]  9% 1266/14661 [16:38<2:54:53,  1.28it/s]  9% 1267/14661 [16:38<2:55:40,  1.27it/s]  9% 1268/14661 [16:39<2:54:29,  1.28it/s]  9% 1269/14661 [16:40<2:54:11,  1.28it/s]  9% 1270/14661 [16:41<2:54:17,  1.28it/s]  9% 1271/14661 [16:42<2:54:36,  1.28it/s]  9% 1272/14661 [16:42<2:53:40,  1.28it/s]  9% 1273/14661 [16:43<2:53:40,  1.28it/s]  9% 1274/14661 [16:44<2:54:14,  1.28it/s]  9% 1275/14661 [16:45<2:53:20,  1.29it/s]  9% 1276/14661 [16:45<2:52:17,  1.29it/s]  9% 1277/14661 [16:46<2:52:00,  1.30it/s]  9% 1278/14661 [16:47<2:51:42,  1.30it/s]  9% 1279/14661 [16:48<2:51:32,  1.30it/s]  9% 1280/14661 [16:49<2:51:33,  1.30it/s]  9% 1281/14661 [16:49<2:51:38,  1.30it/s]  9% 1282/14661 [16:50<2:51:27,  1.30it/s]  9% 1283/14661 [16:51<2:51:16,  1.30it/s]  9% 1284/14661 [16:52<2:51:14,  1.30it/s]  9% 1285/14661 [16:52<2:51:03,  1.30it/s]  9% 1286/14661 [16:53<2:51:14,  1.30it/s]  9% 1287/14661 [16:54<2:52:58,  1.29it/s]  9% 1288/14661 [16:55<2:54:11,  1.28it/s]  9% 1289/14661 [16:56<2:53:46,  1.28it/s]  9% 1290/14661 [16:56<2:52:56,  1.29it/s]  9% 1291/14661 [16:57<2:52:47,  1.29it/s]  9% 1292/14661 [16:58<2:52:24,  1.29it/s]  9% 1293/14661 [16:59<2:51:48,  1.30it/s]  9% 1294/14661 [16:59<2:51:35,  1.30it/s]  9% 1295/14661 [17:00<2:51:53,  1.30it/s]  9% 1296/14661 [17:01<2:51:34,  1.30it/s]  9% 1297/14661 [17:02<2:51:32,  1.30it/s]  9% 1298/14661 [17:02<2:51:23,  1.30it/s]  9% 1299/14661 [17:03<2:51:09,  1.30it/s]  9% 1300/14661 [17:04<2:51:38,  1.30it/s]  9% 1301/14661 [17:05<2:51:27,  1.30it/s]  9% 1302/14661 [17:06<2:51:06,  1.30it/s]  9% 1303/14661 [17:06<2:51:20,  1.30it/s]  9% 1304/14661 [17:07<2:53:01,  1.29it/s]  9% 1305/14661 [17:08<2:53:36,  1.28it/s]  9% 1306/14661 [17:09<2:53:35,  1.28it/s]  9% 1307/14661 [17:09<2:52:51,  1.29it/s]  9% 1308/14661 [17:10<2:52:55,  1.29it/s]  9% 1309/14661 [17:11<2:52:11,  1.29it/s]  9% 1310/14661 [17:12<2:52:44,  1.29it/s]  9% 1311/14661 [17:13<2:52:13,  1.29it/s]  9% 1312/14661 [17:13<2:52:09,  1.29it/s]  9% 1313/14661 [17:14<2:52:13,  1.29it/s]  9% 1314/14661 [17:15<2:53:08,  1.28it/s]  9% 1315/14661 [17:16<2:53:20,  1.28it/s]  9% 1316/14661 [17:16<2:53:57,  1.28it/s]  9% 1317/14661 [17:17<2:52:52,  1.29it/s]  9% 1318/14661 [17:18<2:52:13,  1.29it/s]  9% 1319/14661 [17:19<2:51:50,  1.29it/s]  9% 1320/14661 [17:19<2:51:11,  1.30it/s]  9% 1321/14661 [17:20<2:51:12,  1.30it/s]  9% 1322/14661 [17:21<2:51:12,  1.30it/s]  9% 1323/14661 [17:22<2:53:23,  1.28it/s]  9% 1324/14661 [17:23<2:53:43,  1.28it/s]  9% 1325/14661 [17:23<2:54:06,  1.28it/s]  9% 1326/14661 [17:24<2:53:19,  1.28it/s]  9% 1327/14661 [17:25<2:52:47,  1.29it/s]  9% 1328/14661 [17:26<2:53:11,  1.28it/s]  9% 1329/14661 [17:27<2:52:53,  1.29it/s]  9% 1330/14661 [17:27<2:52:11,  1.29it/s]  9% 1331/14661 [17:28<2:55:17,  1.27it/s]  9% 1332/14661 [17:29<2:55:58,  1.26it/s]  9% 1333/14661 [17:30<2:55:39,  1.26it/s]  9% 1334/14661 [17:30<2:54:31,  1.27it/s]  9% 1335/14661 [17:31<2:53:43,  1.28it/s]  9% 1336/14661 [17:32<2:52:48,  1.29it/s]  9% 1337/14661 [17:33<2:52:24,  1.29it/s]  9% 1338/14661 [17:34<2:51:53,  1.29it/s]  9% 1339/14661 [17:34<2:51:49,  1.29it/s]  9% 1340/14661 [17:35<2:51:50,  1.29it/s]  9% 1341/14661 [17:36<2:52:01,  1.29it/s]  9% 1342/14661 [17:37<2:51:53,  1.29it/s]  9% 1343/14661 [17:37<2:51:36,  1.29it/s]  9% 1344/14661 [17:38<2:51:29,  1.29it/s]  9% 1345/14661 [17:39<2:53:14,  1.28it/s]  9% 1346/14661 [17:40<2:55:08,  1.27it/s]  9% 1347/14661 [17:41<2:56:39,  1.26it/s]  9% 1348/14661 [17:41<2:56:01,  1.26it/s]  9% 1349/14661 [17:42<2:54:50,  1.27it/s]  9% 1350/14661 [17:43<2:53:47,  1.28it/s]  9% 1351/14661 [17:44<2:53:18,  1.28it/s]  9% 1352/14661 [17:44<2:53:20,  1.28it/s]  9% 1353/14661 [17:45<2:53:10,  1.28it/s]  9% 1354/14661 [17:46<2:53:40,  1.28it/s]  9% 1355/14661 [17:47<2:53:48,  1.28it/s]  9% 1356/14661 [17:48<2:52:55,  1.28it/s]  9% 1357/14661 [17:48<2:52:33,  1.29it/s]  9% 1358/14661 [17:49<2:52:03,  1.29it/s]  9% 1359/14661 [17:50<2:51:39,  1.29it/s]  9% 1360/14661 [17:51<2:51:13,  1.29it/s]  9% 1361/14661 [17:51<2:51:00,  1.30it/s]  9% 1362/14661 [17:52<2:51:16,  1.29it/s]  9% 1363/14661 [17:53<2:51:23,  1.29it/s]  9% 1364/14661 [17:54<2:51:33,  1.29it/s]  9% 1365/14661 [17:55<2:51:13,  1.29it/s]  9% 1366/14661 [17:55<2:50:38,  1.30it/s]  9% 1367/14661 [17:56<2:50:14,  1.30it/s]  9% 1368/14661 [17:57<2:50:14,  1.30it/s]  9% 1369/14661 [17:58<2:50:06,  1.30it/s]  9% 1370/14661 [17:58<2:51:06,  1.29it/s]  9% 1371/14661 [17:59<2:51:34,  1.29it/s]  9% 1372/14661 [18:00<2:51:32,  1.29it/s]  9% 1373/14661 [18:01<2:52:18,  1.29it/s]  9% 1374/14661 [18:02<2:52:41,  1.28it/s]  9% 1375/14661 [18:02<2:53:04,  1.28it/s]  9% 1376/14661 [18:03<2:52:33,  1.28it/s]  9% 1377/14661 [18:04<2:52:45,  1.28it/s]  9% 1378/14661 [18:05<2:52:40,  1.28it/s]  9% 1379/14661 [18:05<2:52:24,  1.28it/s]  9% 1380/14661 [18:06<2:53:07,  1.28it/s]  9% 1381/14661 [18:07<2:52:39,  1.28it/s]  9% 1382/14661 [18:08<2:54:04,  1.27it/s]  9% 1383/14661 [18:09<2:54:19,  1.27it/s]  9% 1384/14661 [18:09<2:54:16,  1.27it/s]  9% 1385/14661 [18:10<2:53:13,  1.28it/s]  9% 1386/14661 [18:11<2:53:36,  1.27it/s]  9% 1387/14661 [18:12<2:52:48,  1.28it/s]  9% 1388/14661 [18:12<2:52:47,  1.28it/s]  9% 1389/14661 [18:13<2:53:29,  1.27it/s]  9% 1390/14661 [18:14<2:53:20,  1.28it/s]  9% 1391/14661 [18:15<2:52:32,  1.28it/s]  9% 1392/14661 [18:16<2:52:25,  1.28it/s] 10% 1393/14661 [18:16<2:51:29,  1.29it/s] 10% 1394/14661 [18:17<2:50:58,  1.29it/s] 10% 1395/14661 [18:18<2:51:20,  1.29it/s] 10% 1396/14661 [18:19<2:51:07,  1.29it/s] 10% 1397/14661 [18:19<2:51:19,  1.29it/s] 10% 1398/14661 [18:20<2:50:48,  1.29it/s] 10% 1399/14661 [18:21<2:50:55,  1.29it/s] 10% 1400/14661 [18:22<2:52:44,  1.28it/s] 10% 1401/14661 [18:23<2:51:54,  1.29it/s] 10% 1402/14661 [18:23<2:51:34,  1.29it/s] 10% 1403/14661 [18:24<2:54:06,  1.27it/s] 10% 1404/14661 [18:25<2:54:09,  1.27it/s] 10% 1405/14661 [18:26<2:54:00,  1.27it/s] 10% 1406/14661 [18:27<2:53:28,  1.27it/s] 10% 1407/14661 [18:27<2:53:15,  1.27it/s] 10% 1408/14661 [18:28<2:53:48,  1.27it/s] 10% 1409/14661 [18:29<2:53:40,  1.27it/s] 10% 1410/14661 [18:30<2:53:43,  1.27it/s] 10% 1411/14661 [18:30<2:52:29,  1.28it/s] 10% 1412/14661 [18:31<2:51:43,  1.29it/s] 10% 1413/14661 [18:32<2:51:10,  1.29it/s] 10% 1414/14661 [18:33<2:52:49,  1.28it/s] 10% 1415/14661 [18:34<2:52:14,  1.28it/s] 10% 1416/14661 [18:34<2:54:09,  1.27it/s] 10% 1417/14661 [18:35<2:53:11,  1.27it/s] 10% 1418/14661 [18:36<2:52:09,  1.28it/s] 10% 1419/14661 [18:37<2:52:13,  1.28it/s] 10% 1420/14661 [18:37<2:51:38,  1.29it/s] 10% 1421/14661 [18:38<2:51:00,  1.29it/s] 10% 1422/14661 [18:39<2:51:00,  1.29it/s] 10% 1423/14661 [18:40<2:51:44,  1.28it/s] 10% 1424/14661 [18:41<2:51:48,  1.28it/s] 10% 1425/14661 [18:41<2:51:40,  1.29it/s] 10% 1426/14661 [18:42<2:51:41,  1.28it/s] 10% 1427/14661 [18:43<2:51:31,  1.29it/s] 10% 1428/14661 [18:44<2:50:59,  1.29it/s] 10% 1429/14661 [18:44<2:50:08,  1.30it/s] 10% 1430/14661 [18:45<2:50:24,  1.29it/s] 10% 1431/14661 [18:46<2:50:34,  1.29it/s] 10% 1432/14661 [18:47<2:50:22,  1.29it/s] 10% 1433/14661 [18:48<2:50:53,  1.29it/s] 10% 1434/14661 [18:48<2:51:20,  1.29it/s] 10% 1435/14661 [18:49<2:50:49,  1.29it/s] 10% 1436/14661 [18:50<2:50:41,  1.29it/s] 10% 1437/14661 [18:51<2:50:51,  1.29it/s] 10% 1438/14661 [18:51<2:51:12,  1.29it/s] 10% 1439/14661 [18:52<2:52:31,  1.28it/s] 10% 1440/14661 [18:53<2:51:46,  1.28it/s] 10% 1441/14661 [18:54<2:52:23,  1.28it/s] 10% 1442/14661 [18:55<2:52:28,  1.28it/s] 10% 1443/14661 [18:55<2:52:19,  1.28it/s] 10% 1444/14661 [18:56<2:52:03,  1.28it/s] 10% 1445/14661 [18:57<2:51:50,  1.28it/s] 10% 1446/14661 [18:58<2:51:11,  1.29it/s] 10% 1447/14661 [18:58<2:50:44,  1.29it/s] 10% 1448/14661 [18:59<2:50:38,  1.29it/s] 10% 1449/14661 [19:00<2:50:18,  1.29it/s] 10% 1450/14661 [19:01<2:50:40,  1.29it/s] 10% 1451/14661 [19:02<2:50:04,  1.29it/s] 10% 1452/14661 [19:02<2:49:43,  1.30it/s] 10% 1453/14661 [19:03<2:49:34,  1.30it/s] 10% 1454/14661 [19:04<2:49:23,  1.30it/s] 10% 1455/14661 [19:05<2:49:03,  1.30it/s] 10% 1456/14661 [19:05<2:48:58,  1.30it/s] 10% 1457/14661 [19:06<2:48:57,  1.30it/s] 10% 1458/14661 [19:07<2:48:52,  1.30it/s] 10% 1459/14661 [19:08<2:50:07,  1.29it/s] 10% 1460/14661 [19:08<2:51:04,  1.29it/s] 10% 1461/14661 [19:09<2:50:14,  1.29it/s] 10% 1462/14661 [19:10<2:49:36,  1.30it/s] 10% 1463/14661 [19:11<2:49:27,  1.30it/s] 10% 1464/14661 [19:12<2:48:51,  1.30it/s] 10% 1465/14661 [19:12<2:48:25,  1.31it/s] 10% 1466/14661 [19:13<2:48:25,  1.31it/s] 10% 1467/14661 [19:14<2:48:25,  1.31it/s] 10% 1468/14661 [19:15<2:48:36,  1.30it/s] 10% 1469/14661 [19:15<2:48:47,  1.30it/s] 10% 1470/14661 [19:16<2:48:38,  1.30it/s] 10% 1471/14661 [19:17<2:48:38,  1.30it/s] 10% 1472/14661 [19:18<2:48:34,  1.30it/s] 10% 1473/14661 [19:18<2:48:23,  1.31it/s] 10% 1474/14661 [19:19<2:48:19,  1.31it/s] 10% 1475/14661 [19:20<2:48:30,  1.30it/s] 10% 1476/14661 [19:21<2:48:26,  1.30it/s] 10% 1477/14661 [19:22<2:48:41,  1.30it/s] 10% 1478/14661 [19:22<2:48:41,  1.30it/s] 10% 1479/14661 [19:23<2:48:31,  1.30it/s] 10% 1480/14661 [19:24<2:48:36,  1.30it/s]