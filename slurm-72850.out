Loading cudnn7.6-cuda10.2/7.6.5.32
  Loading requirement: cuda10.2/toolkit/10.2.89
Loading nccl2-cuda10.2-gcc/2.6.4
  Loading requirement: gcc5/5.5.0
ActionClip boot~
<string>:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
<string>:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
<string>:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
/home/10501001/projects/ActionCLIP/train.py:53: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  config = yaml.load(f)
wandb: Currently logged in as: wozzq (use `wandb login --relogin` to force relogin)
wandb: Tracking run with wandb version 0.12.4
wandb: Syncing run 20211030_122343_clip_k400_RN50_kinetics400
wandb:  View project at https://wandb.ai/wozzq/clip_k400
wandb:  View run at https://wandb.ai/wozzq/clip_k400/runs/3l7fxriq
wandb: Run data is saved locally in /home/10501001/projects/ActionCLIP/wandb/run-20211030_122348-3l7fxriq
wandb: Run `wandb offline` to turn off syncing.

--------------------------------------------------------------------------------
                     working dir: ./exp/clip_k400/RN50/kinetics400/20211030_122343
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
                               Config
{   'data': {   'batch_size': 16,
                'dataset': 'kinetics400',
                'image_tmpl': 'img_{:05d}.jpg',
                'index_bias': 1,
                'input_size': 224,
                'label_list': 'lists/kinetics_400_labels.csv',
                'modality': 'RGB',
                'num_classes': 400,
                'num_segments': 8,
                'randaug': {'M': 9, 'N': 2},
                'random_shift': True,
                'seg_length': 1,
                'train_list': 'lists/k4001/train_frames.txt',
                'val_list': 'lists/k4001/val_frames.txt',
                'workers': 16},
    'logging': {'eval_freq': 1, 'print_freq': 10},
    'network': {   'arch': 'RN50',
                   'describe': None,
                   'drop_out': 0.0,
                   'emb_dropout': 0.0,
                   'init': False,
                   'is_action': True,
                   'joint': False,
                   'sim_header': 'Transf',
                   'tsm': False,
                   'type': 'clip_k400'},
    'pretrain': None,
    'resume': None,
    'seed': 1024,
    'solver': {   'clip_gradient': 20,
                  'epoch_offset': 0,
                  'epochs': 50,
                  'evaluate': False,
                  'f_ratio': 10,
                  'loss_type': 'nll',
                  'lr': 5e-06,
                  'lr_decay_factor': 0.1,
                  'lr_decay_step': 15,
                  'lr_warmup_step': 5,
                  'momentum': 0.9,
                  'optim': 'adamw',
                  'ratio': 1,
                  'start_epoch': 0,
                  'type': 'cosine',
                  'weight_decay': 0.2}}
--------------------------------------------------------------------------------
dropout used:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
not using full clip pretrained model, only visual!
Adding action...
params in make_temporal_shift: 
n_segment:  8
n_div:  8
place:  blockres
temporal_pool:  False
=> n_segment per stage: [8, 8, 8, 8]
=> Processing stage with 3 blocks residual
SA:  1644167168
8
64
=> Using ACTION
SA:  26306674688
8
256
=> Using ACTION
SA:  26306674688
8
256
=> Using ACTION
=> Processing stage with 4 blocks residual
SA:  26306674688
8
256
=> Using ACTION
SA:  105226698752
8
512
=> Using ACTION
SA:  105226698752
8
512
=> Using ACTION
SA:  105226698752
8
512
=> Using ACTION
=> Processing stage with 6 blocks residual
SA:  105226698752
8
512
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
=> Processing stage with 3 blocks residual
SA:  420906795008
8
1024
=> Using ACTION
SA:  1683627180032
8
2048
=> Using ACTION
SA:  1683627180032
8
2048
=> Using ACTION
Using RandAugment!
train transforms: [<utils.Augmentation.GroupTransform object at 0x2aab4a180550>, Compose(
    <datasets.transforms_ss.GroupMultiScaleCrop object at 0x2aab4a180a90>
    <datasets.transforms_ss.GroupRandomHorizontalFlip object at 0x2aab4a180f10>
    <datasets.transforms_ss.GroupRandomColorJitter object at 0x2aab4a180fd0>
    <datasets.transforms_ss.GroupRandomGrayscale object at 0x2aab4a180dc0>
    <datasets.transforms_ss.GroupGaussianBlur object at 0x2aab4a180df0>
    <datasets.transforms_ss.GroupSolarization object at 0x2aab4a180c40>
), Compose(
    <datasets.transforms_ss.Stack object at 0x2aab4a180ca0>
    <datasets.transforms_ss.ToTorchFormatTensor object at 0x2aab4a180af0>
    <datasets.transforms_ss.GroupNormalize object at 0x2aab4a180c10>
)]
val transforms: [Compose(
    <datasets.transforms_ss.GroupScale object at 0x2aab4a180a30>
    <datasets.transforms_ss.GroupCenterCrop object at 0x2aab4a180970>
), Compose(
    <datasets.transforms_ss.Stack object at 0x2aab4a180790>
    <datasets.transforms_ss.ToTorchFormatTensor object at 0x2aab4a180610>
    <datasets.transforms_ss.GroupNormalize object at 0x2aab4a180730>
)]
layer=6
visual.conv1  :  Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
- torch.float16
visual.bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.0.conv1.net  :  Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer1.0.conv1.action_shift  :  Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64, bias=False)
- torch.float32
visual.layer1.0.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer1.0.conv1.action_p2_squeeze  :  Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.0.conv1.action_p2_conv1  :  Conv1d(4, 4, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer1.0.conv1.action_p2_expand  :  Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.0.conv1.action_p3_squeeze  :  Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.0.conv1.action_p3_bn1  :  BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.0.conv1.action_p3_conv1  :  Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)
- torch.float32
visual.layer1.0.conv1.action_p3_expand  :  Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.0.bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.0.conv2  :  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer1.0.bn2  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.0.conv3  :  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer1.0.bn3  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.0.downsample.0  :  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer1.0.downsample.1  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.1.conv1.net  :  Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer1.1.conv1.action_shift  :  Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256, bias=False)
- torch.float32
visual.layer1.1.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer1.1.conv1.action_p2_squeeze  :  Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.1.conv1.action_p2_conv1  :  Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer1.1.conv1.action_p2_expand  :  Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.1.conv1.action_p3_squeeze  :  Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.1.conv1.action_p3_bn1  :  BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.1.conv1.action_p3_conv1  :  Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
- torch.float32
visual.layer1.1.conv1.action_p3_expand  :  Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.1.bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.1.conv2  :  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer1.1.bn2  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.1.conv3  :  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer1.1.bn3  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.2.conv1.net  :  Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer1.2.conv1.action_shift  :  Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256, bias=False)
- torch.float32
visual.layer1.2.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer1.2.conv1.action_p2_squeeze  :  Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.2.conv1.action_p2_conv1  :  Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer1.2.conv1.action_p2_expand  :  Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.2.conv1.action_p3_squeeze  :  Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.2.conv1.action_p3_bn1  :  BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.2.conv1.action_p3_conv1  :  Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
- torch.float32
visual.layer1.2.conv1.action_p3_expand  :  Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.2.bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.2.conv2  :  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer1.2.bn2  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.2.conv3  :  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer1.2.bn3  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.0.conv1.net  :  Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer2.0.conv1.action_shift  :  Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256, bias=False)
- torch.float32
visual.layer2.0.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer2.0.conv1.action_p2_squeeze  :  Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.0.conv1.action_p2_conv1  :  Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer2.0.conv1.action_p2_expand  :  Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.0.conv1.action_p3_squeeze  :  Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.0.conv1.action_p3_bn1  :  BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.0.conv1.action_p3_conv1  :  Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
- torch.float32
visual.layer2.0.conv1.action_p3_expand  :  Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.0.bn1  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.0.conv2  :  Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
- torch.float16
visual.layer2.0.bn2  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.0.conv3  :  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer2.0.bn3  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.0.downsample.0  :  Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
- torch.float16
visual.layer2.0.downsample.1  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.1.conv1.net  :  Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer2.1.conv1.action_shift  :  Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
- torch.float32
visual.layer2.1.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer2.1.conv1.action_p2_squeeze  :  Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.1.conv1.action_p2_conv1  :  Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer2.1.conv1.action_p2_expand  :  Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.1.conv1.action_p3_squeeze  :  Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.1.conv1.action_p3_bn1  :  BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.1.conv1.action_p3_conv1  :  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
- torch.float32
visual.layer2.1.conv1.action_p3_expand  :  Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.1.bn1  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.1.conv2  :  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer2.1.bn2  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.1.conv3  :  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer2.1.bn3  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.2.conv1.net  :  Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer2.2.conv1.action_shift  :  Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
- torch.float32
visual.layer2.2.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer2.2.conv1.action_p2_squeeze  :  Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.2.conv1.action_p2_conv1  :  Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer2.2.conv1.action_p2_expand  :  Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.2.conv1.action_p3_squeeze  :  Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.2.conv1.action_p3_bn1  :  BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.2.conv1.action_p3_conv1  :  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
- torch.float32
visual.layer2.2.conv1.action_p3_expand  :  Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.2.bn1  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.2.conv2  :  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer2.2.bn2  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.2.conv3  :  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer2.2.bn3  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.3.conv1.net  :  Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer2.3.conv1.action_shift  :  Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
- torch.float32
visual.layer2.3.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer2.3.conv1.action_p2_squeeze  :  Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.3.conv1.action_p2_conv1  :  Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer2.3.conv1.action_p2_expand  :  Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.3.conv1.action_p3_squeeze  :  Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.3.conv1.action_p3_bn1  :  BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.3.conv1.action_p3_conv1  :  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
- torch.float32
visual.layer2.3.conv1.action_p3_expand  :  Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.3.bn1  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.3.conv2  :  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer2.3.bn2  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.3.conv3  :  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer2.3.bn3  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.0.conv1.net  :  Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.0.conv1.action_shift  :  Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
- torch.float32
visual.layer3.0.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer3.0.conv1.action_p2_squeeze  :  Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.0.conv1.action_p2_conv1  :  Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer3.0.conv1.action_p2_expand  :  Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.0.conv1.action_p3_squeeze  :  Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.0.conv1.action_p3_bn1  :  BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.0.conv1.action_p3_conv1  :  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
- torch.float32
visual.layer3.0.conv1.action_p3_expand  :  Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.0.bn1  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.0.conv2  :  Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
- torch.float16
visual.layer3.0.bn2  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.0.conv3  :  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.0.bn3  :  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.0.downsample.0  :  Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
- torch.float16
visual.layer3.0.downsample.1  :  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.1.conv1.net  :  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.1.conv1.action_shift  :  Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
- torch.float32
visual.layer3.1.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer3.1.conv1.action_p2_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.1.conv1.action_p2_conv1  :  Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer3.1.conv1.action_p2_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.1.conv1.action_p3_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.1.conv1.action_p3_bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.1.conv1.action_p3_conv1  :  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
- torch.float32
visual.layer3.1.conv1.action_p3_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.1.bn1  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.1.conv2  :  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer3.1.bn2  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.1.conv3  :  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.1.bn3  :  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.2.conv1.net  :  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.2.conv1.action_shift  :  Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
- torch.float32
visual.layer3.2.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer3.2.conv1.action_p2_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.2.conv1.action_p2_conv1  :  Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer3.2.conv1.action_p2_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.2.conv1.action_p3_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.2.conv1.action_p3_bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.2.conv1.action_p3_conv1  :  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
- torch.float32
visual.layer3.2.conv1.action_p3_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.2.bn1  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.2.conv2  :  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer3.2.bn2  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.2.conv3  :  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.2.bn3  :  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.3.conv1.net  :  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.3.conv1.action_shift  :  Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
- torch.float32
visual.layer3.3.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer3.3.conv1.action_p2_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.3.conv1.action_p2_conv1  :  Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer3.3.conv1.action_p2_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.3.conv1.action_p3_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.3.conv1.action_p3_bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.3.conv1.action_p3_conv1  :  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
- torch.float32
visual.layer3.3.conv1.action_p3_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.3.bn1  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.3.conv2  :  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer3.3.bn2  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.3.conv3  :  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.3.bn3  :  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.4.conv1.net  :  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.4.conv1.action_shift  :  Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
- torch.float32
visual.layer3.4.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer3.4.conv1.action_p2_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.4.conv1.action_p2_conv1  :  Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer3.4.conv1.action_p2_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.4.conv1.action_p3_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.4.conv1.action_p3_bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.4.conv1.action_p3_conv1  :  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
- torch.float32
visual.layer3.4.conv1.action_p3_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.4.bn1  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.4.conv2  :  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer3.4.bn2  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.4.conv3  :  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.4.bn3  :  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.5.conv1.net  :  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.5.conv1.action_shift  :  Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
- torch.float32
visual.layer3.5.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer3.5.conv1.action_p2_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.5.conv1.action_p2_conv1  :  Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer3.5.conv1.action_p2_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.5.conv1.action_p3_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.5.conv1.action_p3_bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.5.conv1.action_p3_conv1  :  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
- torch.float32
visual.layer3.5.conv1.action_p3_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.5.bn1  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.5.conv2  :  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer3.5.bn2  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.5.conv3  :  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.5.bn3  :  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.0.conv1.net  :  Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer4.0.conv1.action_shift  :  Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
- torch.float32
visual.layer4.0.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer4.0.conv1.action_p2_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.0.conv1.action_p2_conv1  :  Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer4.0.conv1.action_p2_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.0.conv1.action_p3_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.0.conv1.action_p3_bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.0.conv1.action_p3_conv1  :  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
- torch.float32
visual.layer4.0.conv1.action_p3_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.0.bn1  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.0.conv2  :  Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
- torch.float16
visual.layer4.0.bn2  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.0.conv3  :  Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer4.0.bn3  :  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.0.downsample.0  :  Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
- torch.float16
visual.layer4.0.downsample.1  :  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.1.conv1.net  :  Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer4.1.conv1.action_shift  :  Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,), groups=2048, bias=False)
- torch.float32
visual.layer4.1.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer4.1.conv1.action_p2_squeeze  :  Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.1.conv1.action_p2_conv1  :  Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer4.1.conv1.action_p2_expand  :  Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.1.conv1.action_p3_squeeze  :  Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.1.conv1.action_p3_bn1  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.1.conv1.action_p3_conv1  :  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
- torch.float32
visual.layer4.1.conv1.action_p3_expand  :  Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.1.bn1  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.1.conv2  :  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer4.1.bn2  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.1.conv3  :  Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer4.1.bn3  :  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.2.conv1.net  :  Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer4.2.conv1.action_shift  :  Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,), groups=2048, bias=False)
- torch.float32
visual.layer4.2.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer4.2.conv1.action_p2_squeeze  :  Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.2.conv1.action_p2_conv1  :  Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer4.2.conv1.action_p2_expand  :  Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.2.conv1.action_p3_squeeze  :  Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.2.conv1.action_p3_bn1  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.2.conv1.action_p3_conv1  :  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
- torch.float32
visual.layer4.2.conv1.action_p3_expand  :  Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.2.bn1  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.2.conv2  :  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer4.2.bn2  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.2.conv3  :  Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer4.2.bn3  :  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.fc  :  Linear(in_features=2048, out_features=1024, bias=True)
- torch.float16
transformer.resblocks.0.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.0.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.0.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.0.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.0.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.1.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.1.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.1.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.1.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.1.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.2.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.2.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.2.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.2.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.2.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.3.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.3.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.3.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.3.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.3.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.4.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.4.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.4.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.4.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.4.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.5.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.5.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.5.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.5.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.5.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.6.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.6.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.6.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.6.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.6.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.7.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.7.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.7.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.7.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.7.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.8.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.8.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.8.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.8.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.8.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.9.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.9.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.9.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.9.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.9.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.10.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.10.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.10.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.10.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.10.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.11.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.11.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.11.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.11.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.11.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
token_embedding  :  Embedding(49408, 512)
- torch.float32
ln_final  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=
CLIP(
  (visual): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Action(
          (net): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(4, 4, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)
          (action_p3_expand): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Action(
          (net): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
          (action_p3_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Action(
          (net): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
          (action_p3_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Action(
          (net): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
          (action_p3_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Action(
          (net): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (action_p3_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Action(
          (net): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (action_p3_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Action(
          (net): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (action_p3_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Action(
          (net): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (action_p3_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Action(
          (net): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,), groups=2048, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (action_p3_expand): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Action(
          (net): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,), groups=2048, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (action_p3_expand): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (transformer): Transformer(
    (resblocks): Sequential(
      (0): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (6): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (7): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (8): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (9): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (10): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (11): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (token_embedding): Embedding(49408, 512)
  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.0, inplace=False)
)
fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=
DataParallel(
  (module): visual_prompt(
    (frame_position_embeddings): Embedding(77, 1024)
    (transformer): TemporalTransformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
      )
    )
  )
)
random_shift:DotMap()
/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
random_shift:DotMap()
=========using KL Loss=and has temperature and * bz==========
=========using KL Loss=and has temperature and * bz==========
5e-06
5e-06
5e-05
AdamW
positional_embedding: True
text_projection: True
logit_scale: True
visual.conv1.weight: True
visual.bn1.weight: True
visual.bn1.bias: True
visual.layer1.0.conv1.net.weight: True
visual.layer1.0.conv1.action_shift.weight: True
visual.layer1.0.conv1.action_p1_conv1.weight: True
visual.layer1.0.conv1.action_p2_squeeze.weight: True
visual.layer1.0.conv1.action_p2_conv1.weight: True
visual.layer1.0.conv1.action_p2_expand.weight: True
visual.layer1.0.conv1.action_p3_squeeze.weight: True
visual.layer1.0.conv1.action_p3_bn1.weight: True
visual.layer1.0.conv1.action_p3_bn1.bias: True
visual.layer1.0.conv1.action_p3_conv1.weight: True
visual.layer1.0.conv1.action_p3_expand.weight: True
visual.layer1.0.bn1.weight: True
visual.layer1.0.bn1.bias: True
visual.layer1.0.conv2.weight: True
visual.layer1.0.bn2.weight: True
visual.layer1.0.bn2.bias: True
visual.layer1.0.conv3.weight: True
visual.layer1.0.bn3.weight: True
visual.layer1.0.bn3.bias: True
visual.layer1.0.downsample.0.weight: True
visual.layer1.0.downsample.1.weight: True
visual.layer1.0.downsample.1.bias: True
visual.layer1.1.conv1.net.weight: True
visual.layer1.1.conv1.action_shift.weight: True
visual.layer1.1.conv1.action_p1_conv1.weight: True
visual.layer1.1.conv1.action_p2_squeeze.weight: True
visual.layer1.1.conv1.action_p2_conv1.weight: True
visual.layer1.1.conv1.action_p2_expand.weight: True
visual.layer1.1.conv1.action_p3_squeeze.weight: True
visual.layer1.1.conv1.action_p3_bn1.weight: True
visual.layer1.1.conv1.action_p3_bn1.bias: True
visual.layer1.1.conv1.action_p3_conv1.weight: True
visual.layer1.1.conv1.action_p3_expand.weight: True
visual.layer1.1.bn1.weight: True
visual.layer1.1.bn1.bias: True
visual.layer1.1.conv2.weight: True
visual.layer1.1.bn2.weight: True
visual.layer1.1.bn2.bias: True
visual.layer1.1.conv3.weight: True
visual.layer1.1.bn3.weight: True
visual.layer1.1.bn3.bias: True
visual.layer1.2.conv1.net.weight: True
visual.layer1.2.conv1.action_shift.weight: True
visual.layer1.2.conv1.action_p1_conv1.weight: True
visual.layer1.2.conv1.action_p2_squeeze.weight: True
visual.layer1.2.conv1.action_p2_conv1.weight: True
visual.layer1.2.conv1.action_p2_expand.weight: True
visual.layer1.2.conv1.action_p3_squeeze.weight: True
visual.layer1.2.conv1.action_p3_bn1.weight: True
visual.layer1.2.conv1.action_p3_bn1.bias: True
visual.layer1.2.conv1.action_p3_conv1.weight: True
visual.layer1.2.conv1.action_p3_expand.weight: True
visual.layer1.2.bn1.weight: True
visual.layer1.2.bn1.bias: True
visual.layer1.2.conv2.weight: True
visual.layer1.2.bn2.weight: True
visual.layer1.2.bn2.bias: True
visual.layer1.2.conv3.weight: True
visual.layer1.2.bn3.weight: True
visual.layer1.2.bn3.bias: True
visual.layer2.0.conv1.net.weight: True
visual.layer2.0.conv1.action_shift.weight: True
visual.layer2.0.conv1.action_p1_conv1.weight: True
visual.layer2.0.conv1.action_p2_squeeze.weight: True
visual.layer2.0.conv1.action_p2_conv1.weight: True
visual.layer2.0.conv1.action_p2_expand.weight: True
visual.layer2.0.conv1.action_p3_squeeze.weight: True
visual.layer2.0.conv1.action_p3_bn1.weight: True
visual.layer2.0.conv1.action_p3_bn1.bias: True
visual.layer2.0.conv1.action_p3_conv1.weight: True
visual.layer2.0.conv1.action_p3_expand.weight: True
visual.layer2.0.bn1.weight: True
visual.layer2.0.bn1.bias: True
visual.layer2.0.conv2.weight: True
visual.layer2.0.bn2.weight: True
visual.layer2.0.bn2.bias: True
visual.layer2.0.conv3.weight: True
visual.layer2.0.bn3.weight: True
visual.layer2.0.bn3.bias: True
visual.layer2.0.downsample.0.weight: True
visual.layer2.0.downsample.1.weight: True
visual.layer2.0.downsample.1.bias: True
visual.layer2.1.conv1.net.weight: True
visual.layer2.1.conv1.action_shift.weight: True
visual.layer2.1.conv1.action_p1_conv1.weight: True
visual.layer2.1.conv1.action_p2_squeeze.weight: True
visual.layer2.1.conv1.action_p2_conv1.weight: True
visual.layer2.1.conv1.action_p2_expand.weight: True
visual.layer2.1.conv1.action_p3_squeeze.weight: True
visual.layer2.1.conv1.action_p3_bn1.weight: True
visual.layer2.1.conv1.action_p3_bn1.bias: True
visual.layer2.1.conv1.action_p3_conv1.weight: True
visual.layer2.1.conv1.action_p3_expand.weight: True
visual.layer2.1.bn1.weight: True
visual.layer2.1.bn1.bias: True
visual.layer2.1.conv2.weight: True
visual.layer2.1.bn2.weight: True
visual.layer2.1.bn2.bias: True
visual.layer2.1.conv3.weight: True
visual.layer2.1.bn3.weight: True
visual.layer2.1.bn3.bias: True
visual.layer2.2.conv1.net.weight: True
visual.layer2.2.conv1.action_shift.weight: True
visual.layer2.2.conv1.action_p1_conv1.weight: True
visual.layer2.2.conv1.action_p2_squeeze.weight: True
visual.layer2.2.conv1.action_p2_conv1.weight: True
visual.layer2.2.conv1.action_p2_expand.weight: True
visual.layer2.2.conv1.action_p3_squeeze.weight: True
visual.layer2.2.conv1.action_p3_bn1.weight: True
visual.layer2.2.conv1.action_p3_bn1.bias: True
visual.layer2.2.conv1.action_p3_conv1.weight: True
visual.layer2.2.conv1.action_p3_expand.weight: True
visual.layer2.2.bn1.weight: True
visual.layer2.2.bn1.bias: True
visual.layer2.2.conv2.weight: True
visual.layer2.2.bn2.weight: True
visual.layer2.2.bn2.bias: True
visual.layer2.2.conv3.weight: True
visual.layer2.2.bn3.weight: True
visual.layer2.2.bn3.bias: True
visual.layer2.3.conv1.net.weight: True
visual.layer2.3.conv1.action_shift.weight: True
visual.layer2.3.conv1.action_p1_conv1.weight: True
visual.layer2.3.conv1.action_p2_squeeze.weight: True
visual.layer2.3.conv1.action_p2_conv1.weight: True
visual.layer2.3.conv1.action_p2_expand.weight: True
visual.layer2.3.conv1.action_p3_squeeze.weight: True
visual.layer2.3.conv1.action_p3_bn1.weight: True
visual.layer2.3.conv1.action_p3_bn1.bias: True
visual.layer2.3.conv1.action_p3_conv1.weight: True
visual.layer2.3.conv1.action_p3_expand.weight: True
visual.layer2.3.bn1.weight: True
visual.layer2.3.bn1.bias: True
visual.layer2.3.conv2.weight: True
visual.layer2.3.bn2.weight: True
visual.layer2.3.bn2.bias: True
visual.layer2.3.conv3.weight: True
visual.layer2.3.bn3.weight: True
visual.layer2.3.bn3.bias: True
visual.layer3.0.conv1.net.weight: True
visual.layer3.0.conv1.action_shift.weight: True
visual.layer3.0.conv1.action_p1_conv1.weight: True
visual.layer3.0.conv1.action_p2_squeeze.weight: True
visual.layer3.0.conv1.action_p2_conv1.weight: True
visual.layer3.0.conv1.action_p2_expand.weight: True
visual.layer3.0.conv1.action_p3_squeeze.weight: True
visual.layer3.0.conv1.action_p3_bn1.weight: True
visual.layer3.0.conv1.action_p3_bn1.bias: True
visual.layer3.0.conv1.action_p3_conv1.weight: True
visual.layer3.0.conv1.action_p3_expand.weight: True
visual.layer3.0.bn1.weight: True
visual.layer3.0.bn1.bias: True
visual.layer3.0.conv2.weight: True
visual.layer3.0.bn2.weight: True
visual.layer3.0.bn2.bias: True
visual.layer3.0.conv3.weight: True
visual.layer3.0.bn3.weight: True
visual.layer3.0.bn3.bias: True
visual.layer3.0.downsample.0.weight: True
visual.layer3.0.downsample.1.weight: True
visual.layer3.0.downsample.1.bias: True
visual.layer3.1.conv1.net.weight: True
visual.layer3.1.conv1.action_shift.weight: True
visual.layer3.1.conv1.action_p1_conv1.weight: True
visual.layer3.1.conv1.action_p2_squeeze.weight: True
visual.layer3.1.conv1.action_p2_conv1.weight: True
visual.layer3.1.conv1.action_p2_expand.weight: True
visual.layer3.1.conv1.action_p3_squeeze.weight: True
visual.layer3.1.conv1.action_p3_bn1.weight: True
visual.layer3.1.conv1.action_p3_bn1.bias: True
visual.layer3.1.conv1.action_p3_conv1.weight: True
visual.layer3.1.conv1.action_p3_expand.weight: True
visual.layer3.1.bn1.weight: True
visual.layer3.1.bn1.bias: True
visual.layer3.1.conv2.weight: True
visual.layer3.1.bn2.weight: True
visual.layer3.1.bn2.bias: True
visual.layer3.1.conv3.weight: True
visual.layer3.1.bn3.weight: True
visual.layer3.1.bn3.bias: True
visual.layer3.2.conv1.net.weight: True
visual.layer3.2.conv1.action_shift.weight: True
visual.layer3.2.conv1.action_p1_conv1.weight: True
visual.layer3.2.conv1.action_p2_squeeze.weight: True
visual.layer3.2.conv1.action_p2_conv1.weight: True
visual.layer3.2.conv1.action_p2_expand.weight: True
visual.layer3.2.conv1.action_p3_squeeze.weight: True
visual.layer3.2.conv1.action_p3_bn1.weight: True
visual.layer3.2.conv1.action_p3_bn1.bias: True
visual.layer3.2.conv1.action_p3_conv1.weight: True
visual.layer3.2.conv1.action_p3_expand.weight: True
visual.layer3.2.bn1.weight: True
visual.layer3.2.bn1.bias: True
visual.layer3.2.conv2.weight: True
visual.layer3.2.bn2.weight: True
visual.layer3.2.bn2.bias: True
visual.layer3.2.conv3.weight: True
visual.layer3.2.bn3.weight: True
visual.layer3.2.bn3.bias: True
visual.layer3.3.conv1.net.weight: True
visual.layer3.3.conv1.action_shift.weight: True
visual.layer3.3.conv1.action_p1_conv1.weight: True
visual.layer3.3.conv1.action_p2_squeeze.weight: True
visual.layer3.3.conv1.action_p2_conv1.weight: True
visual.layer3.3.conv1.action_p2_expand.weight: True
visual.layer3.3.conv1.action_p3_squeeze.weight: True
visual.layer3.3.conv1.action_p3_bn1.weight: True
visual.layer3.3.conv1.action_p3_bn1.bias: True
visual.layer3.3.conv1.action_p3_conv1.weight: True
visual.layer3.3.conv1.action_p3_expand.weight: True
visual.layer3.3.bn1.weight: True
visual.layer3.3.bn1.bias: True
visual.layer3.3.conv2.weight: True
visual.layer3.3.bn2.weight: True
visual.layer3.3.bn2.bias: True
visual.layer3.3.conv3.weight: True
visual.layer3.3.bn3.weight: True
visual.layer3.3.bn3.bias: True
visual.layer3.4.conv1.net.weight: True
visual.layer3.4.conv1.action_shift.weight: True
visual.layer3.4.conv1.action_p1_conv1.weight: True
visual.layer3.4.conv1.action_p2_squeeze.weight: True
visual.layer3.4.conv1.action_p2_conv1.weight: True
visual.layer3.4.conv1.action_p2_expand.weight: True
visual.layer3.4.conv1.action_p3_squeeze.weight: True
visual.layer3.4.conv1.action_p3_bn1.weight: True
visual.layer3.4.conv1.action_p3_bn1.bias: True
visual.layer3.4.conv1.action_p3_conv1.weight: True
visual.layer3.4.conv1.action_p3_expand.weight: True
visual.layer3.4.bn1.weight: True
visual.layer3.4.bn1.bias: True
visual.layer3.4.conv2.weight: True
visual.layer3.4.bn2.weight: True
visual.layer3.4.bn2.bias: True
visual.layer3.4.conv3.weight: True
visual.layer3.4.bn3.weight: True
visual.layer3.4.bn3.bias: True
visual.layer3.5.conv1.net.weight: True
visual.layer3.5.conv1.action_shift.weight: True
visual.layer3.5.conv1.action_p1_conv1.weight: True
visual.layer3.5.conv1.action_p2_squeeze.weight: True
visual.layer3.5.conv1.action_p2_conv1.weight: True
visual.layer3.5.conv1.action_p2_expand.weight: True
visual.layer3.5.conv1.action_p3_squeeze.weight: True
visual.layer3.5.conv1.action_p3_bn1.weight: True
visual.layer3.5.conv1.action_p3_bn1.bias: True
visual.layer3.5.conv1.action_p3_conv1.weight: True
visual.layer3.5.conv1.action_p3_expand.weight: True
visual.layer3.5.bn1.weight: True
visual.layer3.5.bn1.bias: True
visual.layer3.5.conv2.weight: True
visual.layer3.5.bn2.weight: True
visual.layer3.5.bn2.bias: True
visual.layer3.5.conv3.weight: True
visual.layer3.5.bn3.weight: True
visual.layer3.5.bn3.bias: True
visual.layer4.0.conv1.net.weight: True
visual.layer4.0.conv1.action_shift.weight: True
visual.layer4.0.conv1.action_p1_conv1.weight: True
visual.layer4.0.conv1.action_p2_squeeze.weight: True
visual.layer4.0.conv1.action_p2_conv1.weight: True
visual.layer4.0.conv1.action_p2_expand.weight: True
visual.layer4.0.conv1.action_p3_squeeze.weight: True
visual.layer4.0.conv1.action_p3_bn1.weight: True
visual.layer4.0.conv1.action_p3_bn1.bias: True
visual.layer4.0.conv1.action_p3_conv1.weight: True
visual.layer4.0.conv1.action_p3_expand.weight: True
visual.layer4.0.bn1.weight: True
visual.layer4.0.bn1.bias: True
visual.layer4.0.conv2.weight: True
visual.layer4.0.bn2.weight: True
visual.layer4.0.bn2.bias: True
visual.layer4.0.conv3.weight: True
visual.layer4.0.bn3.weight: True
visual.layer4.0.bn3.bias: True
visual.layer4.0.downsample.0.weight: True
visual.layer4.0.downsample.1.weight: True
visual.layer4.0.downsample.1.bias: True
visual.layer4.1.conv1.net.weight: True
visual.layer4.1.conv1.action_shift.weight: True
visual.layer4.1.conv1.action_p1_conv1.weight: True
visual.layer4.1.conv1.action_p2_squeeze.weight: True
visual.layer4.1.conv1.action_p2_conv1.weight: True
visual.layer4.1.conv1.action_p2_expand.weight: True
visual.layer4.1.conv1.action_p3_squeeze.weight: True
visual.layer4.1.conv1.action_p3_bn1.weight: True
visual.layer4.1.conv1.action_p3_bn1.bias: True
visual.layer4.1.conv1.action_p3_conv1.weight: True
visual.layer4.1.conv1.action_p3_expand.weight: True
visual.layer4.1.bn1.weight: True
visual.layer4.1.bn1.bias: True
visual.layer4.1.conv2.weight: True
visual.layer4.1.bn2.weight: True
visual.layer4.1.bn2.bias: True
visual.layer4.1.conv3.weight: True
visual.layer4.1.bn3.weight: True
visual.layer4.1.bn3.bias: True
visual.layer4.2.conv1.net.weight: True
visual.layer4.2.conv1.action_shift.weight: True
visual.layer4.2.conv1.action_p1_conv1.weight: True
visual.layer4.2.conv1.action_p2_squeeze.weight: True
visual.layer4.2.conv1.action_p2_conv1.weight: True
visual.layer4.2.conv1.action_p2_expand.weight: True
visual.layer4.2.conv1.action_p3_squeeze.weight: True
visual.layer4.2.conv1.action_p3_bn1.weight: True
visual.layer4.2.conv1.action_p3_bn1.bias: True
visual.layer4.2.conv1.action_p3_conv1.weight: True
visual.layer4.2.conv1.action_p3_expand.weight: True
visual.layer4.2.bn1.weight: True
visual.layer4.2.bn1.bias: True
visual.layer4.2.conv2.weight: True
visual.layer4.2.bn2.weight: True
visual.layer4.2.bn2.bias: True
visual.layer4.2.conv3.weight: True
visual.layer4.2.bn3.weight: True
visual.layer4.2.bn3.bias: True
visual.fc.weight: True
visual.fc.bias: True
transformer.resblocks.0.attn.in_proj_weight: True
transformer.resblocks.0.attn.in_proj_bias: True
transformer.resblocks.0.attn.out_proj.weight: True
transformer.resblocks.0.attn.out_proj.bias: True
transformer.resblocks.0.ln_1.weight: True
transformer.resblocks.0.ln_1.bias: True
transformer.resblocks.0.mlp.c_fc.weight: True
transformer.resblocks.0.mlp.c_fc.bias: True
transformer.resblocks.0.mlp.c_proj.weight: True
transformer.resblocks.0.mlp.c_proj.bias: True
transformer.resblocks.0.ln_2.weight: True
transformer.resblocks.0.ln_2.bias: True
transformer.resblocks.1.attn.in_proj_weight: True
transformer.resblocks.1.attn.in_proj_bias: True
transformer.resblocks.1.attn.out_proj.weight: True
transformer.resblocks.1.attn.out_proj.bias: True
transformer.resblocks.1.ln_1.weight: True
transformer.resblocks.1.ln_1.bias: True
transformer.resblocks.1.mlp.c_fc.weight: True
transformer.resblocks.1.mlp.c_fc.bias: True
transformer.resblocks.1.mlp.c_proj.weight: True
transformer.resblocks.1.mlp.c_proj.bias: True
transformer.resblocks.1.ln_2.weight: True
transformer.resblocks.1.ln_2.bias: True
transformer.resblocks.2.attn.in_proj_weight: True
transformer.resblocks.2.attn.in_proj_bias: True
transformer.resblocks.2.attn.out_proj.weight: True
transformer.resblocks.2.attn.out_proj.bias: True
transformer.resblocks.2.ln_1.weight: True
transformer.resblocks.2.ln_1.bias: True
transformer.resblocks.2.mlp.c_fc.weight: True
transformer.resblocks.2.mlp.c_fc.bias: True
transformer.resblocks.2.mlp.c_proj.weight: True
transformer.resblocks.2.mlp.c_proj.bias: True
transformer.resblocks.2.ln_2.weight: True
transformer.resblocks.2.ln_2.bias: True
transformer.resblocks.3.attn.in_proj_weight: True
transformer.resblocks.3.attn.in_proj_bias: True
transformer.resblocks.3.attn.out_proj.weight: True
transformer.resblocks.3.attn.out_proj.bias: True
transformer.resblocks.3.ln_1.weight: True
transformer.resblocks.3.ln_1.bias: True
transformer.resblocks.3.mlp.c_fc.weight: True
transformer.resblocks.3.mlp.c_fc.bias: True
transformer.resblocks.3.mlp.c_proj.weight: True
transformer.resblocks.3.mlp.c_proj.bias: True
transformer.resblocks.3.ln_2.weight: True
transformer.resblocks.3.ln_2.bias: True
transformer.resblocks.4.attn.in_proj_weight: True
transformer.resblocks.4.attn.in_proj_bias: True
transformer.resblocks.4.attn.out_proj.weight: True
transformer.resblocks.4.attn.out_proj.bias: True
transformer.resblocks.4.ln_1.weight: True
transformer.resblocks.4.ln_1.bias: True
transformer.resblocks.4.mlp.c_fc.weight: True
transformer.resblocks.4.mlp.c_fc.bias: True
transformer.resblocks.4.mlp.c_proj.weight: True
transformer.resblocks.4.mlp.c_proj.bias: True
transformer.resblocks.4.ln_2.weight: True
transformer.resblocks.4.ln_2.bias: True
transformer.resblocks.5.attn.in_proj_weight: True
transformer.resblocks.5.attn.in_proj_bias: True
transformer.resblocks.5.attn.out_proj.weight: True
transformer.resblocks.5.attn.out_proj.bias: True
transformer.resblocks.5.ln_1.weight: True
transformer.resblocks.5.ln_1.bias: True
transformer.resblocks.5.mlp.c_fc.weight: True
transformer.resblocks.5.mlp.c_fc.bias: True
transformer.resblocks.5.mlp.c_proj.weight: True
transformer.resblocks.5.mlp.c_proj.bias: True
transformer.resblocks.5.ln_2.weight: True
transformer.resblocks.5.ln_2.bias: True
transformer.resblocks.6.attn.in_proj_weight: True
transformer.resblocks.6.attn.in_proj_bias: True
transformer.resblocks.6.attn.out_proj.weight: True
transformer.resblocks.6.attn.out_proj.bias: True
transformer.resblocks.6.ln_1.weight: True
transformer.resblocks.6.ln_1.bias: True
transformer.resblocks.6.mlp.c_fc.weight: True
transformer.resblocks.6.mlp.c_fc.bias: True
transformer.resblocks.6.mlp.c_proj.weight: True
transformer.resblocks.6.mlp.c_proj.bias: True
transformer.resblocks.6.ln_2.weight: True
transformer.resblocks.6.ln_2.bias: True
transformer.resblocks.7.attn.in_proj_weight: True
transformer.resblocks.7.attn.in_proj_bias: True
transformer.resblocks.7.attn.out_proj.weight: True
transformer.resblocks.7.attn.out_proj.bias: True
transformer.resblocks.7.ln_1.weight: True
transformer.resblocks.7.ln_1.bias: True
transformer.resblocks.7.mlp.c_fc.weight: True
transformer.resblocks.7.mlp.c_fc.bias: True
transformer.resblocks.7.mlp.c_proj.weight: True
transformer.resblocks.7.mlp.c_proj.bias: True
transformer.resblocks.7.ln_2.weight: True
transformer.resblocks.7.ln_2.bias: True
transformer.resblocks.8.attn.in_proj_weight: True
transformer.resblocks.8.attn.in_proj_bias: True
transformer.resblocks.8.attn.out_proj.weight: True
transformer.resblocks.8.attn.out_proj.bias: True
transformer.resblocks.8.ln_1.weight: True
transformer.resblocks.8.ln_1.bias: True
transformer.resblocks.8.mlp.c_fc.weight: True
transformer.resblocks.8.mlp.c_fc.bias: True
transformer.resblocks.8.mlp.c_proj.weight: True
transformer.resblocks.8.mlp.c_proj.bias: True
transformer.resblocks.8.ln_2.weight: True
transformer.resblocks.8.ln_2.bias: True
transformer.resblocks.9.attn.in_proj_weight: True
transformer.resblocks.9.attn.in_proj_bias: True
transformer.resblocks.9.attn.out_proj.weight: True
transformer.resblocks.9.attn.out_proj.bias: True
transformer.resblocks.9.ln_1.weight: True
transformer.resblocks.9.ln_1.bias: True
transformer.resblocks.9.mlp.c_fc.weight: True
transformer.resblocks.9.mlp.c_fc.bias: True
transformer.resblocks.9.mlp.c_proj.weight: True
transformer.resblocks.9.mlp.c_proj.bias: True
transformer.resblocks.9.ln_2.weight: True
transformer.resblocks.9.ln_2.bias: True
transformer.resblocks.10.attn.in_proj_weight: True
transformer.resblocks.10.attn.in_proj_bias: True
transformer.resblocks.10.attn.out_proj.weight: True
transformer.resblocks.10.attn.out_proj.bias: True
transformer.resblocks.10.ln_1.weight: True
transformer.resblocks.10.ln_1.bias: True
transformer.resblocks.10.mlp.c_fc.weight: True
transformer.resblocks.10.mlp.c_fc.bias: True
transformer.resblocks.10.mlp.c_proj.weight: True
transformer.resblocks.10.mlp.c_proj.bias: True
transformer.resblocks.10.ln_2.weight: True
transformer.resblocks.10.ln_2.bias: True
transformer.resblocks.11.attn.in_proj_weight: True
transformer.resblocks.11.attn.in_proj_bias: True
transformer.resblocks.11.attn.out_proj.weight: True
transformer.resblocks.11.attn.out_proj.bias: True
transformer.resblocks.11.ln_1.weight: True
transformer.resblocks.11.ln_1.bias: True
transformer.resblocks.11.mlp.c_fc.weight: True
transformer.resblocks.11.mlp.c_fc.bias: True
transformer.resblocks.11.mlp.c_proj.weight: True
transformer.resblocks.11.mlp.c_proj.bias: True
transformer.resblocks.11.ln_2.weight: True
transformer.resblocks.11.ln_2.bias: True
token_embedding.weight: True
ln_final.weight: True
ln_final.bias: True
  0% 0/14661 [00:00<?, ?it/s]/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
action debug 0: torch.Size([64, 64, 56, 56])
action debug 1:  torch.Size([64, 64, 56, 56])
action debug: 2 torch.Size([64, 64, 56, 56])
action debug: 3 torch.Size([64, 64, 56, 56])
action debug: 4 torch.Size([64, 64, 56, 56])
action debug: 5 torch.Size([64, 64, 56, 56])
action debug 0: torch.Size([64, 256, 56, 56])
action debug 1:  torch.Size([64, 256, 56, 56])
action debug: 2 torch.Size([64, 256, 56, 56])
action debug: 3 torch.Size([64, 256, 56, 56])
action debug: 4 torch.Size([64, 256, 56, 56])
action debug: 5 torch.Size([64, 64, 56, 56])
action debug 0: torch.Size([64, 256, 56, 56])
action debug 1:  torch.Size([64, 256, 56, 56])
action debug: 2 torch.Size([64, 256, 56, 56])
action debug: 3 torch.Size([64, 256, 56, 56])
action debug: 4 torch.Size([64, 256, 56, 56])
action debug: 5 torch.Size([64, 64, 56, 56])
action debug 0: torch.Size([64, 256, 56, 56])
action debug 1:  torch.Size([64, 256, 56, 56])
action debug: 2 torch.Size([64, 256, 56, 56])
action debug: 3 torch.Size([64, 256, 56, 56])
action debug: 4 torch.Size([64, 256, 56, 56])
action debug: 5 torch.Size([64, 128, 56, 56])
action debug 0: torch.Size([64, 512, 28, 28])
action debug 1:  torch.Size([64, 512, 28, 28])
action debug: 2 torch.Size([64, 512, 28, 28])
action debug: 3 torch.Size([64, 512, 28, 28])
action debug: 4 torch.Size([64, 512, 28, 28])
action debug: 5 torch.Size([64, 128, 28, 28])
action debug 0: torch.Size([64, 512, 28, 28])
action debug 1:  torch.Size([64, 512, 28, 28])
action debug: 2 torch.Size([64, 512, 28, 28])
action debug: 3 torch.Size([64, 512, 28, 28])
action debug: 4 torch.Size([64, 512, 28, 28])
action debug: 5 torch.Size([64, 128, 28, 28])
action debug 0: torch.Size([64, 512, 28, 28])
action debug 1:  torch.Size([64, 512, 28, 28])
action debug: 2 torch.Size([64, 512, 28, 28])
action debug: 3 torch.Size([64, 512, 28, 28])
action debug: 4 torch.Size([64, 512, 28, 28])
action debug: 5 torch.Size([64, 128, 28, 28])
action debug 0: torch.Size([64, 512, 28, 28])
action debug 1:  torch.Size([64, 512, 28, 28])
action debug: 2 torch.Size([64, 512, 28, 28])
action debug: 3 torch.Size([64, 512, 28, 28])
action debug: 4 torch.Size([64, 512, 28, 28])
action debug: 5 torch.Size([64, 256, 28, 28])
action debug 0: torch.Size([64, 1024, 14, 14])
action debug 1:  torch.Size([64, 1024, 14, 14])
action debug: 2 torch.Size([64, 1024, 14, 14])
action debug: 3 torch.Size([64, 1024, 14, 14])
action debug: 4 torch.Size([64, 1024, 14, 14])
action debug: 5 torch.Size([64, 256, 14, 14])
action debug 0: torch.Size([64, 1024, 14, 14])
action debug 1:  torch.Size([64, 1024, 14, 14])
action debug: 2 torch.Size([64, 1024, 14, 14])
action debug: 3 torch.Size([64, 1024, 14, 14])
action debug: 4 torch.Size([64, 1024, 14, 14])
action debug: 5 torch.Size([64, 256, 14, 14])
action debug 0: torch.Size([64, 1024, 14, 14])
action debug 1:  torch.Size([64, 1024, 14, 14])
action debug: 2 torch.Size([64, 1024, 14, 14])
action debug: 3 torch.Size([64, 1024, 14, 14])
action debug: 4 torch.Size([64, 1024, 14, 14])
action debug: 5 torch.Size([64, 256, 14, 14])
action debug 0: torch.Size([64, 1024, 14, 14])
action debug 1:  torch.Size([64, 1024, 14, 14])
action debug: 2 torch.Size([64, 1024, 14, 14])
action debug: 3 torch.Size([64, 1024, 14, 14])
action debug: 4 torch.Size([64, 1024, 14, 14])
action debug: 5 torch.Size([64, 256, 14, 14])
action debug 0: torch.Size([64, 1024, 14, 14])
action debug 1:  torch.Size([64, 1024, 14, 14])
action debug: 2 torch.Size([64, 1024, 14, 14])
action debug: 3 torch.Size([64, 1024, 14, 14])
action debug: 4 torch.Size([64, 1024, 14, 14])
action debug: 5 torch.Size([64, 256, 14, 14])
action debug 0: torch.Size([64, 1024, 14, 14])
action debug 1:  torch.Size([64, 1024, 14, 14])
action debug: 2 torch.Size([64, 1024, 14, 14])
action debug: 3 torch.Size([64, 1024, 14, 14])
action debug: 4 torch.Size([64, 1024, 14, 14])
action debug: 5 torch.Size([64, 512, 14, 14])
action debug 0: torch.Size([64, 2048, 7, 7])
action debug 1:  torch.Size([64, 2048, 7, 7])
action debug: 2 torch.Size([64, 2048, 7, 7])
action debug: 3 torch.Size([64, 2048, 7, 7])
action debug: 4 torch.Size([64, 2048, 7, 7])
action debug: 5 torch.Size([64, 512, 7, 7])
action debug 0: torch.Size([64, 2048, 7, 7])
action debug 1:  torch.Size([64, 2048, 7, 7])
action debug: 2 torch.Size([64, 2048, 7, 7])
action debug: 3 torch.Size([64, 2048, 7, 7])
action debug: 4 torch.Size([64, 2048, 7, 7])
action debug: 5 torch.Size([64, 512, 7, 7])
encoded image size:  torch.Size([64, 1024])
action debug 0: torch.Size([64, 64, 56, 56])
action debug 1:  torch.Size([64, 64, 56, 56])
action debug: 2 torch.Size([64, 64, 56, 56])
action debug: 3 torch.Size([64, 64, 56, 56])
action debug: 4 torch.Size([64, 64, 56, 56])
action debug: 5 torch.Size([64, 64, 56, 56])
action debug 0: torch.Size([64, 256, 56, 56])
action debug 1:  torch.Size([64, 256, 56, 56])
action debug: 2 torch.Size([64, 256, 56, 56])
action debug: 3 torch.Size([64, 256, 56, 56])
action debug: 4 torch.Size([64, 256, 56, 56])
action debug: 5 torch.Size([64, 64, 56, 56])
action debug 0: torch.Size([64, 256, 56, 56])
action debug 1:  torch.Size([64, 256, 56, 56])
action debug: 2 torch.Size([64, 256, 56, 56])
action debug: 3 torch.Size([64, 256, 56, 56])
action debug: 4 torch.Size([64, 256, 56, 56])
action debug: 5 torch.Size([64, 64, 56, 56])
action debug 0: torch.Size([64, 256, 56, 56])
action debug 1:  torch.Size([64, 256, 56, 56])
action debug: 2 torch.Size([64, 256, 56, 56])
action debug: 3 torch.Size([64, 256, 56, 56])
action debug: 4 torch.Size([64, 256, 56, 56])
action debug: 5 torch.Size([64, 128, 56, 56])
action debug 0: torch.Size([64, 512, 28, 28])
action debug 1:  torch.Size([64, 512, 28, 28])
action debug: 2 torch.Size([64, 512, 28, 28])
action debug: 3 torch.Size([64, 512, 28, 28])
action debug: 4 torch.Size([64, 512, 28, 28])
action debug: 5 torch.Size([64, 128, 28, 28])
  0% 0/14661 [00:13<?, ?it/s]
Traceback (most recent call last):
  File "/home/10501001/projects/ActionCLIP/train.py", line 252, in <module>
    main()
  File "/home/10501001/projects/ActionCLIP/train.py", line 204, in main
    image_embedding = model_image(images)  # (16*8,512)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/_utils.py", line 425, in reraise
    raise self.exc_type(msg)
RuntimeError: Caught RuntimeError in replica 1 on device 1.
Original Traceback (most recent call last):
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/10501001/projects/ActionCLIP/train.py", line 42, in forward
    return self.model.encode_image(image)
  File "/home/10501001/projects/ActionCLIP/clip/model.py", line 426, in encode_image
    ret = self.visual(image.type(self.dtype))
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torchvision/models/resnet.py", line 156, in forward
    x = self.layer2(x)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torchvision/models/resnet.py", line 87, in forward
    out = self.conv3(out)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 439, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_BAD_PARAM
You can try to repro this exception using the following code snippet. If that doesn't trigger the error, please include your original repro script when reporting this issue.

import torch
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.benchmark = False
torch.backends.cudnn.deterministic = False
torch.backends.cudnn.allow_tf32 = True
data = torch.randn([64, 128, 28, 28], dtype=torch.half, device='cuda', requires_grad=True)
net = torch.nn.Conv2d(128, 512, kernel_size=[1, 1], padding=[0, 0], stride=[1, 1], dilation=[1, 1], groups=1)
net = net.cuda().half()
out = net(data)
out.backward(torch.randn_like(out))
torch.cuda.synchronize()

ConvolutionParams 
    data_type = CUDNN_DATA_HALF
    padding = [0, 0, 0]
    stride = [1, 1, 0]
    dilation = [1, 1, 0]
    groups = 1
    deterministic = false
    allow_tf32 = true
input: TensorDescriptor 0x2aaca37dd6e0
    type = CUDNN_DATA_HALF
    nbDims = 4
    dimA = 64, 128, 28, 28, 
    strideA = 100352, 784, 28, 1, 
output: TensorDescriptor 0x2aaca3956830
    type = CUDNN_DATA_HALF
    nbDims = 4
    dimA = 64, 512, 28, 28, 
    strideA = 401408, 784, 28, 1, 
weight: FilterDescriptor 0x2aaca38bf700
    type = CUDNN_DATA_HALF
    tensor_format = CUDNN_TENSOR_NCHW
    nbDims = 4
    dimA = 512, 128, 1, 1, 
Pointer addresses: 
    input: 0x2aaeda4c0000
    output: 0x2aaef6000000
    weight: 0x2aac974ca256
Forward algorithm: 1



wandb: Waiting for W&B process to finish, PID 68290... (failed 1). Press ctrl-c to abort syncing.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.11MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.11MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.11MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.11MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.11MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.11MB uploaded (0.00MB deduped)wandb: \ 0.05MB of 0.11MB uploaded (0.00MB deduped)wandb: | 0.11MB of 0.11MB uploaded (0.00MB deduped)wandb: / 0.11MB of 0.11MB uploaded (0.00MB deduped)wandb: - 0.11MB of 0.11MB uploaded (0.00MB deduped)wandb: \ 0.11MB of 0.11MB uploaded (0.00MB deduped)wandb: | 0.11MB of 0.11MB uploaded (0.00MB deduped)wandb: / 0.11MB of 0.11MB uploaded (0.00MB deduped)wandb: - 0.11MB of 0.11MB uploaded (0.00MB deduped)wandb: \ 0.11MB of 0.11MB uploaded (0.00MB deduped)wandb: | 0.11MB of 0.11MB uploaded (0.00MB deduped)wandb: / 0.11MB of 0.11MB uploaded (0.00MB deduped)wandb: - 0.11MB of 0.11MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced 20211030_122343_clip_k400_RN50_kinetics400: https://wandb.ai/wozzq/clip_k400/runs/3l7fxriq
wandb: Find logs at: ./wandb/run-20211030_122348-3l7fxriq/logs/debug.log
wandb: 
