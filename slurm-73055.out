Loading cudnn7.6-cuda10.2/7.6.5.32
  Loading requirement: cuda10.2/toolkit/10.2.89
Loading nccl2-cuda10.2-gcc/2.6.4
  Loading requirement: gcc5/5.5.0
/cm/local/apps/slurm/var/spool/job73055/slurm_script: line 20: export: `=': not a valid identifier
/cm/local/apps/slurm/var/spool/job73055/slurm_script: line 21: export: `=': not a valid identifier
/cm/local/apps/slurm/var/spool/job73055/slurm_script: line 21: export: `5678': not a valid identifier
Sun Oct 31 11:43:37 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN RTX           On   | 00000000:1B:00.0 Off |                  N/A |
| 41%   38C    P8    14W / 280W |      0MiB / 24220MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  TITAN RTX           On   | 00000000:3E:00.0 Off |                  N/A |
| 41%   42C    P8    11W / 280W |      0MiB / 24220MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
ActionClip boot~
<string>:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
<string>:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
<string>:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
/home/10501001/projects/ActionCLIP/train.py:53: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  config = yaml.load(f)
wandb: Currently logged in as: wozzq (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.4
wandb: Syncing run 20211031_114337_clip_k400_RN50_kinetics400
wandb:  View project at https://wandb.ai/wozzq/clip_k400
wandb:  View run at https://wandb.ai/wozzq/clip_k400/runs/2svu53m0
wandb: Run data is saved locally in /home/10501001/projects/ActionCLIP/wandb/run-20211031_114342-2svu53m0
wandb: Run `wandb offline` to turn off syncing.

--------------------------------------------------------------------------------
                     working dir: ./exp/clip_k400/RN50/kinetics400/20211031_114337
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
                               Config
{   'data': {   'batch_size': 16,
                'dataset': 'kinetics400',
                'image_tmpl': 'img_{:05d}.jpg',
                'index_bias': 1,
                'input_size': 224,
                'label_list': 'lists/kinetics_400_labels.csv',
                'modality': 'RGB',
                'num_classes': 400,
                'num_segments': 8,
                'randaug': {'M': 9, 'N': 2},
                'random_shift': True,
                'seg_length': 1,
                'train_list': 'lists/k4001/train_frames.txt',
                'val_list': 'lists/k4001/val_frames.txt',
                'workers': 16},
    'logging': {'eval_freq': 1, 'print_freq': 10},
    'network': {   'arch': 'RN50',
                   'describe': None,
                   'drop_out': 0.0,
                   'emb_dropout': 0.0,
                   'init': False,
                   'is_action': True,
                   'joint': False,
                   'sim_header': 'Transf',
                   'tsm': False,
                   'type': 'clip_k400'},
    'pretrain': None,
    'resume': None,
    'seed': 1024,
    'solver': {   'clip_gradient': 20,
                  'epoch_offset': 0,
                  'epochs': 50,
                  'evaluate': False,
                  'f_ratio': 10,
                  'loss_type': 'nll',
                  'lr': 5e-06,
                  'lr_decay_factor': 0.1,
                  'lr_decay_step': 15,
                  'lr_warmup_step': 5,
                  'momentum': 0.9,
                  'optim': 'adamw',
                  'ratio': 1,
                  'start_epoch': 0,
                  'type': 'cosine',
                  'weight_decay': 0.2}}
--------------------------------------------------------------------------------
dropout used:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
not using full clip pretrained model, only visual!
Adding action...
params in make_temporal_shift: 
n_segment:  8
n_div:  8
place:  blockres
temporal_pool:  False
=> n_segment per stage: [8, 8, 8, 8]
=> Processing stage with 3 blocks residual
SA:  1644167168
8
64
=> Using ACTION
SA:  26306674688
8
256
=> Using ACTION
SA:  26306674688
8
256
=> Using ACTION
=> Processing stage with 4 blocks residual
SA:  26306674688
8
256
=> Using ACTION
SA:  105226698752
8
512
=> Using ACTION
SA:  105226698752
8
512
=> Using ACTION
SA:  105226698752
8
512
=> Using ACTION
=> Processing stage with 6 blocks residual
SA:  105226698752
8
512
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
SA:  420906795008
8
1024
=> Using ACTION
=> Processing stage with 3 blocks residual
SA:  420906795008
8
1024
=> Using ACTION
SA:  1683627180032
8
2048
=> Using ACTION
SA:  1683627180032
8
2048
=> Using ACTION
Using RandAugment!
train transforms: [<utils.Augmentation.GroupTransform object at 0x2aab4a188640>, Compose(
    <datasets.transforms_ss.GroupMultiScaleCrop object at 0x2aab387cb8b0>
    <datasets.transforms_ss.GroupRandomHorizontalFlip object at 0x2aab387cb880>
    <datasets.transforms_ss.GroupRandomColorJitter object at 0x2aab4a188f40>
    <datasets.transforms_ss.GroupRandomGrayscale object at 0x2aab4a188fa0>
    <datasets.transforms_ss.GroupGaussianBlur object at 0x2aab4a188eb0>
    <datasets.transforms_ss.GroupSolarization object at 0x2aab4a188e50>
), Compose(
    <datasets.transforms_ss.Stack object at 0x2aab4a188d60>
    <datasets.transforms_ss.ToTorchFormatTensor object at 0x2aab4a188d00>
    <datasets.transforms_ss.GroupNormalize object at 0x2aab4a188c40>
)]
val transforms: [Compose(
    <datasets.transforms_ss.GroupScale object at 0x2aab4a188b20>
    <datasets.transforms_ss.GroupCenterCrop object at 0x2aab4a1889a0>
), Compose(
    <datasets.transforms_ss.Stack object at 0x2aab4a188760>
    <datasets.transforms_ss.ToTorchFormatTensor object at 0x2aab4a188880>
    <datasets.transforms_ss.GroupNormalize object at 0x2aab4a188820>
)]
layer=6
visual.conv1  :  Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
- torch.float16
visual.bn1  :  BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.conv2  :  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.bn2  :  BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.conv3  :  Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.bn3  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.0.conv1.net  :  Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer1.0.conv1.action_shift  :  Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64, bias=False)
- torch.float32
visual.layer1.0.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer1.0.conv1.action_p2_squeeze  :  Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.0.conv1.action_p2_conv1  :  Conv1d(4, 4, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer1.0.conv1.action_p2_expand  :  Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.0.conv1.action_p3_squeeze  :  Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.0.conv1.action_p3_bn1  :  BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.0.conv1.action_p3_conv1  :  Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)
- torch.float32
visual.layer1.0.conv1.action_p3_expand  :  Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.0.bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.0.conv2  :  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer1.0.bn2  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.0.conv3  :  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer1.0.bn3  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.0.downsample.0  :  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer1.0.downsample.1  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.1.conv1.net  :  Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer1.1.conv1.action_shift  :  Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256, bias=False)
- torch.float32
visual.layer1.1.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer1.1.conv1.action_p2_squeeze  :  Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.1.conv1.action_p2_conv1  :  Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer1.1.conv1.action_p2_expand  :  Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.1.conv1.action_p3_squeeze  :  Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.1.conv1.action_p3_bn1  :  BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.1.conv1.action_p3_conv1  :  Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
- torch.float32
visual.layer1.1.conv1.action_p3_expand  :  Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.1.bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.1.conv2  :  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer1.1.bn2  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.1.conv3  :  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer1.1.bn3  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.2.conv1.net  :  Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer1.2.conv1.action_shift  :  Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256, bias=False)
- torch.float32
visual.layer1.2.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer1.2.conv1.action_p2_squeeze  :  Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.2.conv1.action_p2_conv1  :  Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer1.2.conv1.action_p2_expand  :  Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.2.conv1.action_p3_squeeze  :  Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.2.conv1.action_p3_bn1  :  BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.2.conv1.action_p3_conv1  :  Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
- torch.float32
visual.layer1.2.conv1.action_p3_expand  :  Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer1.2.bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.2.conv2  :  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer1.2.bn2  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer1.2.conv3  :  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer1.2.bn3  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.0.conv1.net  :  Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer2.0.conv1.action_shift  :  Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256, bias=False)
- torch.float32
visual.layer2.0.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer2.0.conv1.action_p2_squeeze  :  Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.0.conv1.action_p2_conv1  :  Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer2.0.conv1.action_p2_expand  :  Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.0.conv1.action_p3_squeeze  :  Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.0.conv1.action_p3_bn1  :  BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.0.conv1.action_p3_conv1  :  Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
- torch.float32
visual.layer2.0.conv1.action_p3_expand  :  Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.0.bn1  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.0.conv2  :  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer2.0.bn2  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.0.conv3  :  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer2.0.bn3  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.0.downsample.0  :  Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer2.0.downsample.1  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.1.conv1.net  :  Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer2.1.conv1.action_shift  :  Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
- torch.float32
visual.layer2.1.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer2.1.conv1.action_p2_squeeze  :  Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.1.conv1.action_p2_conv1  :  Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer2.1.conv1.action_p2_expand  :  Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.1.conv1.action_p3_squeeze  :  Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.1.conv1.action_p3_bn1  :  BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.1.conv1.action_p3_conv1  :  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
- torch.float32
visual.layer2.1.conv1.action_p3_expand  :  Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.1.bn1  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.1.conv2  :  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer2.1.bn2  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.1.conv3  :  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer2.1.bn3  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.2.conv1.net  :  Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer2.2.conv1.action_shift  :  Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
- torch.float32
visual.layer2.2.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer2.2.conv1.action_p2_squeeze  :  Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.2.conv1.action_p2_conv1  :  Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer2.2.conv1.action_p2_expand  :  Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.2.conv1.action_p3_squeeze  :  Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.2.conv1.action_p3_bn1  :  BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.2.conv1.action_p3_conv1  :  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
- torch.float32
visual.layer2.2.conv1.action_p3_expand  :  Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.2.bn1  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.2.conv2  :  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer2.2.bn2  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.2.conv3  :  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer2.2.bn3  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.3.conv1.net  :  Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer2.3.conv1.action_shift  :  Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
- torch.float32
visual.layer2.3.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer2.3.conv1.action_p2_squeeze  :  Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.3.conv1.action_p2_conv1  :  Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer2.3.conv1.action_p2_expand  :  Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.3.conv1.action_p3_squeeze  :  Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.3.conv1.action_p3_bn1  :  BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.3.conv1.action_p3_conv1  :  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
- torch.float32
visual.layer2.3.conv1.action_p3_expand  :  Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer2.3.bn1  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.3.conv2  :  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer2.3.bn2  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer2.3.conv3  :  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer2.3.bn3  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.0.conv1.net  :  Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.0.conv1.action_shift  :  Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
- torch.float32
visual.layer3.0.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer3.0.conv1.action_p2_squeeze  :  Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.0.conv1.action_p2_conv1  :  Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer3.0.conv1.action_p2_expand  :  Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.0.conv1.action_p3_squeeze  :  Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.0.conv1.action_p3_bn1  :  BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.0.conv1.action_p3_conv1  :  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
- torch.float32
visual.layer3.0.conv1.action_p3_expand  :  Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.0.bn1  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.0.conv2  :  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer3.0.bn2  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.0.conv3  :  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.0.bn3  :  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.0.downsample.0  :  Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.0.downsample.1  :  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.1.conv1.net  :  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.1.conv1.action_shift  :  Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
- torch.float32
visual.layer3.1.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer3.1.conv1.action_p2_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.1.conv1.action_p2_conv1  :  Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer3.1.conv1.action_p2_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.1.conv1.action_p3_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.1.conv1.action_p3_bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.1.conv1.action_p3_conv1  :  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
- torch.float32
visual.layer3.1.conv1.action_p3_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.1.bn1  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.1.conv2  :  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer3.1.bn2  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.1.conv3  :  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.1.bn3  :  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.2.conv1.net  :  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.2.conv1.action_shift  :  Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
- torch.float32
visual.layer3.2.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer3.2.conv1.action_p2_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.2.conv1.action_p2_conv1  :  Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer3.2.conv1.action_p2_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.2.conv1.action_p3_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.2.conv1.action_p3_bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.2.conv1.action_p3_conv1  :  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
- torch.float32
visual.layer3.2.conv1.action_p3_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.2.bn1  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.2.conv2  :  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer3.2.bn2  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.2.conv3  :  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.2.bn3  :  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.3.conv1.net  :  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.3.conv1.action_shift  :  Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
- torch.float32
visual.layer3.3.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer3.3.conv1.action_p2_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.3.conv1.action_p2_conv1  :  Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer3.3.conv1.action_p2_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.3.conv1.action_p3_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.3.conv1.action_p3_bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.3.conv1.action_p3_conv1  :  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
- torch.float32
visual.layer3.3.conv1.action_p3_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.3.bn1  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.3.conv2  :  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer3.3.bn2  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.3.conv3  :  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.3.bn3  :  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.4.conv1.net  :  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.4.conv1.action_shift  :  Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
- torch.float32
visual.layer3.4.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer3.4.conv1.action_p2_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.4.conv1.action_p2_conv1  :  Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer3.4.conv1.action_p2_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.4.conv1.action_p3_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.4.conv1.action_p3_bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.4.conv1.action_p3_conv1  :  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
- torch.float32
visual.layer3.4.conv1.action_p3_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.4.bn1  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.4.conv2  :  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer3.4.bn2  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.4.conv3  :  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.4.bn3  :  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.5.conv1.net  :  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.5.conv1.action_shift  :  Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
- torch.float32
visual.layer3.5.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer3.5.conv1.action_p2_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.5.conv1.action_p2_conv1  :  Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer3.5.conv1.action_p2_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.5.conv1.action_p3_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.5.conv1.action_p3_bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.5.conv1.action_p3_conv1  :  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
- torch.float32
visual.layer3.5.conv1.action_p3_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer3.5.bn1  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.5.conv2  :  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer3.5.bn2  :  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer3.5.conv3  :  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer3.5.bn3  :  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.0.conv1.net  :  Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer4.0.conv1.action_shift  :  Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
- torch.float32
visual.layer4.0.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer4.0.conv1.action_p2_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.0.conv1.action_p2_conv1  :  Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer4.0.conv1.action_p2_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.0.conv1.action_p3_squeeze  :  Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.0.conv1.action_p3_bn1  :  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.0.conv1.action_p3_conv1  :  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
- torch.float32
visual.layer4.0.conv1.action_p3_expand  :  Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.0.bn1  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.0.conv2  :  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer4.0.bn2  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.0.conv3  :  Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer4.0.bn3  :  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.0.downsample.0  :  Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer4.0.downsample.1  :  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.1.conv1.net  :  Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer4.1.conv1.action_shift  :  Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,), groups=2048, bias=False)
- torch.float32
visual.layer4.1.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer4.1.conv1.action_p2_squeeze  :  Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.1.conv1.action_p2_conv1  :  Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer4.1.conv1.action_p2_expand  :  Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.1.conv1.action_p3_squeeze  :  Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.1.conv1.action_p3_bn1  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.1.conv1.action_p3_conv1  :  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
- torch.float32
visual.layer4.1.conv1.action_p3_expand  :  Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.1.bn1  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.1.conv2  :  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer4.1.bn2  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.1.conv3  :  Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer4.1.bn3  :  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.2.conv1.net  :  Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer4.2.conv1.action_shift  :  Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,), groups=2048, bias=False)
- torch.float32
visual.layer4.2.conv1.action_p1_conv1  :  Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
- torch.float32
visual.layer4.2.conv1.action_p2_squeeze  :  Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.2.conv1.action_p2_conv1  :  Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
- torch.float32
visual.layer4.2.conv1.action_p2_expand  :  Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.2.conv1.action_p3_squeeze  :  Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.2.conv1.action_p3_bn1  :  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.2.conv1.action_p3_conv1  :  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
- torch.float32
visual.layer4.2.conv1.action_p3_expand  :  Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float32
visual.layer4.2.bn1  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.2.conv2  :  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
- torch.float16
visual.layer4.2.bn2  :  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
visual.layer4.2.conv3  :  Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
- torch.float16
visual.layer4.2.bn3  :  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
- torch.float32
transformer.resblocks.0.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.0.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.0.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.0.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.0.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.1.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.1.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.1.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.1.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.1.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.2.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.2.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.2.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.2.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.2.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.3.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.3.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.3.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.3.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.3.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.4.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.4.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.4.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.4.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.4.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.5.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.5.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.5.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.5.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.5.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.6.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.6.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.6.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.6.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.6.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.7.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.7.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.7.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.7.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.7.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.8.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.8.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.8.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.8.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.8.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.9.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.9.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.9.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.9.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.9.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.10.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.10.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.10.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.10.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.10.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.11.attn.out_proj  :  NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
- torch.float16
transformer.resblocks.11.ln_1  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
transformer.resblocks.11.mlp.c_fc  :  Linear(in_features=512, out_features=2048, bias=True)
- torch.float16
transformer.resblocks.11.mlp.c_proj  :  Linear(in_features=2048, out_features=512, bias=True)
- torch.float16
transformer.resblocks.11.ln_2  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
token_embedding  :  Embedding(49408, 512)
- torch.float32
ln_final  :  LayerNorm((512,), eps=1e-05, elementwise_affine=True)
- torch.float32
model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=model=
CLIP(
  (visual): ModifiedResNet(
    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (relu): ReLU(inplace=True)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Action(
          (net): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(4, 4, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)
          (action_p3_expand): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Action(
          (net): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
          (action_p3_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Action(
          (net): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
          (action_p3_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Action(
          (net): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
          (action_p3_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Action(
          (net): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (action_p3_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Action(
          (net): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (action_p3_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Action(
          (net): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (action_p3_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Action(
          (net): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (action_p3_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Action(
          (net): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), groups=1024, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (action_p3_expand): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Action(
          (net): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,), groups=2048, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (action_p3_expand): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Action(
          (net): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (relu): ReLU(inplace=True)
          (sigmoid): Sigmoid()
          (action_shift): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,), groups=2048, bias=False)
          (action_p1_conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
          (action_p2_squeeze): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p2_conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (action_p2_expand): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_squeeze): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (action_p3_bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (action_p3_conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (action_p3_expand): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (avgpool): Identity()
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (attnpool): AttentionPool2d(
      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)
    )
  )
  (transformer): Transformer(
    (resblocks): Sequential(
      (0): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (6): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (7): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (8): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (9): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (10): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (11): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (token_embedding): Embedding(49408, 512)
  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.0, inplace=False)
)
fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=fusion_model=
DistributedDataParallel(
  (module): visual_prompt(
    (frame_position_embeddings): Embedding(77, 1024)
    (transformer): TemporalTransformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
          (ln_1): LayerNorm()
          (mlp): Sequential(
            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (ln_2): LayerNorm()
        )
      )
    )
  )
)
random_shift:DotMap()
/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
random_shift:DotMap()
=========using KL Loss=and has temperature and * bz==========
=========using KL Loss=and has temperature and * bz==========
5e-06
5e-06
5e-05
AdamW
positional_embedding: True
text_projection: True
logit_scale: True
visual.conv1.weight: True
visual.bn1.weight: True
visual.bn1.bias: True
visual.conv2.weight: True
visual.bn2.weight: True
visual.bn2.bias: True
visual.conv3.weight: True
visual.bn3.weight: True
visual.bn3.bias: True
visual.layer1.0.conv1.net.weight: True
visual.layer1.0.conv1.action_shift.weight: True
visual.layer1.0.conv1.action_p1_conv1.weight: True
visual.layer1.0.conv1.action_p2_squeeze.weight: True
visual.layer1.0.conv1.action_p2_conv1.weight: True
visual.layer1.0.conv1.action_p2_expand.weight: True
visual.layer1.0.conv1.action_p3_squeeze.weight: True
visual.layer1.0.conv1.action_p3_bn1.weight: True
visual.layer1.0.conv1.action_p3_bn1.bias: True
visual.layer1.0.conv1.action_p3_conv1.weight: True
visual.layer1.0.conv1.action_p3_expand.weight: True
visual.layer1.0.bn1.weight: True
visual.layer1.0.bn1.bias: True
visual.layer1.0.conv2.weight: True
visual.layer1.0.bn2.weight: True
visual.layer1.0.bn2.bias: True
visual.layer1.0.conv3.weight: True
visual.layer1.0.bn3.weight: True
visual.layer1.0.bn3.bias: True
visual.layer1.0.downsample.0.weight: True
visual.layer1.0.downsample.1.weight: True
visual.layer1.0.downsample.1.bias: True
visual.layer1.1.conv1.net.weight: True
visual.layer1.1.conv1.action_shift.weight: True
visual.layer1.1.conv1.action_p1_conv1.weight: True
visual.layer1.1.conv1.action_p2_squeeze.weight: True
visual.layer1.1.conv1.action_p2_conv1.weight: True
visual.layer1.1.conv1.action_p2_expand.weight: True
visual.layer1.1.conv1.action_p3_squeeze.weight: True
visual.layer1.1.conv1.action_p3_bn1.weight: True
visual.layer1.1.conv1.action_p3_bn1.bias: True
visual.layer1.1.conv1.action_p3_conv1.weight: True
visual.layer1.1.conv1.action_p3_expand.weight: True
visual.layer1.1.bn1.weight: True
visual.layer1.1.bn1.bias: True
visual.layer1.1.conv2.weight: True
visual.layer1.1.bn2.weight: True
visual.layer1.1.bn2.bias: True
visual.layer1.1.conv3.weight: True
visual.layer1.1.bn3.weight: True
visual.layer1.1.bn3.bias: True
visual.layer1.2.conv1.net.weight: True
visual.layer1.2.conv1.action_shift.weight: True
visual.layer1.2.conv1.action_p1_conv1.weight: True
visual.layer1.2.conv1.action_p2_squeeze.weight: True
visual.layer1.2.conv1.action_p2_conv1.weight: True
visual.layer1.2.conv1.action_p2_expand.weight: True
visual.layer1.2.conv1.action_p3_squeeze.weight: True
visual.layer1.2.conv1.action_p3_bn1.weight: True
visual.layer1.2.conv1.action_p3_bn1.bias: True
visual.layer1.2.conv1.action_p3_conv1.weight: True
visual.layer1.2.conv1.action_p3_expand.weight: True
visual.layer1.2.bn1.weight: True
visual.layer1.2.bn1.bias: True
visual.layer1.2.conv2.weight: True
visual.layer1.2.bn2.weight: True
visual.layer1.2.bn2.bias: True
visual.layer1.2.conv3.weight: True
visual.layer1.2.bn3.weight: True
visual.layer1.2.bn3.bias: True
visual.layer2.0.conv1.net.weight: True
visual.layer2.0.conv1.action_shift.weight: True
visual.layer2.0.conv1.action_p1_conv1.weight: True
visual.layer2.0.conv1.action_p2_squeeze.weight: True
visual.layer2.0.conv1.action_p2_conv1.weight: True
visual.layer2.0.conv1.action_p2_expand.weight: True
visual.layer2.0.conv1.action_p3_squeeze.weight: True
visual.layer2.0.conv1.action_p3_bn1.weight: True
visual.layer2.0.conv1.action_p3_bn1.bias: True
visual.layer2.0.conv1.action_p3_conv1.weight: True
visual.layer2.0.conv1.action_p3_expand.weight: True
visual.layer2.0.bn1.weight: True
visual.layer2.0.bn1.bias: True
visual.layer2.0.conv2.weight: True
visual.layer2.0.bn2.weight: True
visual.layer2.0.bn2.bias: True
visual.layer2.0.conv3.weight: True
visual.layer2.0.bn3.weight: True
visual.layer2.0.bn3.bias: True
visual.layer2.0.downsample.0.weight: True
visual.layer2.0.downsample.1.weight: True
visual.layer2.0.downsample.1.bias: True
visual.layer2.1.conv1.net.weight: True
visual.layer2.1.conv1.action_shift.weight: True
visual.layer2.1.conv1.action_p1_conv1.weight: True
visual.layer2.1.conv1.action_p2_squeeze.weight: True
visual.layer2.1.conv1.action_p2_conv1.weight: True
visual.layer2.1.conv1.action_p2_expand.weight: True
visual.layer2.1.conv1.action_p3_squeeze.weight: True
visual.layer2.1.conv1.action_p3_bn1.weight: True
visual.layer2.1.conv1.action_p3_bn1.bias: True
visual.layer2.1.conv1.action_p3_conv1.weight: True
visual.layer2.1.conv1.action_p3_expand.weight: True
visual.layer2.1.bn1.weight: True
visual.layer2.1.bn1.bias: True
visual.layer2.1.conv2.weight: True
visual.layer2.1.bn2.weight: True
visual.layer2.1.bn2.bias: True
visual.layer2.1.conv3.weight: True
visual.layer2.1.bn3.weight: True
visual.layer2.1.bn3.bias: True
visual.layer2.2.conv1.net.weight: True
visual.layer2.2.conv1.action_shift.weight: True
visual.layer2.2.conv1.action_p1_conv1.weight: True
visual.layer2.2.conv1.action_p2_squeeze.weight: True
visual.layer2.2.conv1.action_p2_conv1.weight: True
visual.layer2.2.conv1.action_p2_expand.weight: True
visual.layer2.2.conv1.action_p3_squeeze.weight: True
visual.layer2.2.conv1.action_p3_bn1.weight: True
visual.layer2.2.conv1.action_p3_bn1.bias: True
visual.layer2.2.conv1.action_p3_conv1.weight: True
visual.layer2.2.conv1.action_p3_expand.weight: True
visual.layer2.2.bn1.weight: True
visual.layer2.2.bn1.bias: True
visual.layer2.2.conv2.weight: True
visual.layer2.2.bn2.weight: True
visual.layer2.2.bn2.bias: True
visual.layer2.2.conv3.weight: True
visual.layer2.2.bn3.weight: True
visual.layer2.2.bn3.bias: True
visual.layer2.3.conv1.net.weight: True
visual.layer2.3.conv1.action_shift.weight: True
visual.layer2.3.conv1.action_p1_conv1.weight: True
visual.layer2.3.conv1.action_p2_squeeze.weight: True
visual.layer2.3.conv1.action_p2_conv1.weight: True
visual.layer2.3.conv1.action_p2_expand.weight: True
visual.layer2.3.conv1.action_p3_squeeze.weight: True
visual.layer2.3.conv1.action_p3_bn1.weight: True
visual.layer2.3.conv1.action_p3_bn1.bias: True
visual.layer2.3.conv1.action_p3_conv1.weight: True
visual.layer2.3.conv1.action_p3_expand.weight: True
visual.layer2.3.bn1.weight: True
visual.layer2.3.bn1.bias: True
visual.layer2.3.conv2.weight: True
visual.layer2.3.bn2.weight: True
visual.layer2.3.bn2.bias: True
visual.layer2.3.conv3.weight: True
visual.layer2.3.bn3.weight: True
visual.layer2.3.bn3.bias: True
visual.layer3.0.conv1.net.weight: True
visual.layer3.0.conv1.action_shift.weight: True
visual.layer3.0.conv1.action_p1_conv1.weight: True
visual.layer3.0.conv1.action_p2_squeeze.weight: True
visual.layer3.0.conv1.action_p2_conv1.weight: True
visual.layer3.0.conv1.action_p2_expand.weight: True
visual.layer3.0.conv1.action_p3_squeeze.weight: True
visual.layer3.0.conv1.action_p3_bn1.weight: True
visual.layer3.0.conv1.action_p3_bn1.bias: True
visual.layer3.0.conv1.action_p3_conv1.weight: True
visual.layer3.0.conv1.action_p3_expand.weight: True
visual.layer3.0.bn1.weight: True
visual.layer3.0.bn1.bias: True
visual.layer3.0.conv2.weight: True
visual.layer3.0.bn2.weight: True
visual.layer3.0.bn2.bias: True
visual.layer3.0.conv3.weight: True
visual.layer3.0.bn3.weight: True
visual.layer3.0.bn3.bias: True
visual.layer3.0.downsample.0.weight: True
visual.layer3.0.downsample.1.weight: True
visual.layer3.0.downsample.1.bias: True
visual.layer3.1.conv1.net.weight: True
visual.layer3.1.conv1.action_shift.weight: True
visual.layer3.1.conv1.action_p1_conv1.weight: True
visual.layer3.1.conv1.action_p2_squeeze.weight: True
visual.layer3.1.conv1.action_p2_conv1.weight: True
visual.layer3.1.conv1.action_p2_expand.weight: True
visual.layer3.1.conv1.action_p3_squeeze.weight: True
visual.layer3.1.conv1.action_p3_bn1.weight: True
visual.layer3.1.conv1.action_p3_bn1.bias: True
visual.layer3.1.conv1.action_p3_conv1.weight: True
visual.layer3.1.conv1.action_p3_expand.weight: True
visual.layer3.1.bn1.weight: True
visual.layer3.1.bn1.bias: True
visual.layer3.1.conv2.weight: True
visual.layer3.1.bn2.weight: True
visual.layer3.1.bn2.bias: True
visual.layer3.1.conv3.weight: True
visual.layer3.1.bn3.weight: True
visual.layer3.1.bn3.bias: True
visual.layer3.2.conv1.net.weight: True
visual.layer3.2.conv1.action_shift.weight: True
visual.layer3.2.conv1.action_p1_conv1.weight: True
visual.layer3.2.conv1.action_p2_squeeze.weight: True
visual.layer3.2.conv1.action_p2_conv1.weight: True
visual.layer3.2.conv1.action_p2_expand.weight: True
visual.layer3.2.conv1.action_p3_squeeze.weight: True
visual.layer3.2.conv1.action_p3_bn1.weight: True
visual.layer3.2.conv1.action_p3_bn1.bias: True
visual.layer3.2.conv1.action_p3_conv1.weight: True
visual.layer3.2.conv1.action_p3_expand.weight: True
visual.layer3.2.bn1.weight: True
visual.layer3.2.bn1.bias: True
visual.layer3.2.conv2.weight: True
visual.layer3.2.bn2.weight: True
visual.layer3.2.bn2.bias: True
visual.layer3.2.conv3.weight: True
visual.layer3.2.bn3.weight: True
visual.layer3.2.bn3.bias: True
visual.layer3.3.conv1.net.weight: True
visual.layer3.3.conv1.action_shift.weight: True
visual.layer3.3.conv1.action_p1_conv1.weight: True
visual.layer3.3.conv1.action_p2_squeeze.weight: True
visual.layer3.3.conv1.action_p2_conv1.weight: True
visual.layer3.3.conv1.action_p2_expand.weight: True
visual.layer3.3.conv1.action_p3_squeeze.weight: True
visual.layer3.3.conv1.action_p3_bn1.weight: True
visual.layer3.3.conv1.action_p3_bn1.bias: True
visual.layer3.3.conv1.action_p3_conv1.weight: True
visual.layer3.3.conv1.action_p3_expand.weight: True
visual.layer3.3.bn1.weight: True
visual.layer3.3.bn1.bias: True
visual.layer3.3.conv2.weight: True
visual.layer3.3.bn2.weight: True
visual.layer3.3.bn2.bias: True
visual.layer3.3.conv3.weight: True
visual.layer3.3.bn3.weight: True
visual.layer3.3.bn3.bias: True
visual.layer3.4.conv1.net.weight: True
visual.layer3.4.conv1.action_shift.weight: True
visual.layer3.4.conv1.action_p1_conv1.weight: True
visual.layer3.4.conv1.action_p2_squeeze.weight: True
visual.layer3.4.conv1.action_p2_conv1.weight: True
visual.layer3.4.conv1.action_p2_expand.weight: True
visual.layer3.4.conv1.action_p3_squeeze.weight: True
visual.layer3.4.conv1.action_p3_bn1.weight: True
visual.layer3.4.conv1.action_p3_bn1.bias: True
visual.layer3.4.conv1.action_p3_conv1.weight: True
visual.layer3.4.conv1.action_p3_expand.weight: True
visual.layer3.4.bn1.weight: True
visual.layer3.4.bn1.bias: True
visual.layer3.4.conv2.weight: True
visual.layer3.4.bn2.weight: True
visual.layer3.4.bn2.bias: True
visual.layer3.4.conv3.weight: True
visual.layer3.4.bn3.weight: True
visual.layer3.4.bn3.bias: True
visual.layer3.5.conv1.net.weight: True
visual.layer3.5.conv1.action_shift.weight: True
visual.layer3.5.conv1.action_p1_conv1.weight: True
visual.layer3.5.conv1.action_p2_squeeze.weight: True
visual.layer3.5.conv1.action_p2_conv1.weight: True
visual.layer3.5.conv1.action_p2_expand.weight: True
visual.layer3.5.conv1.action_p3_squeeze.weight: True
visual.layer3.5.conv1.action_p3_bn1.weight: True
visual.layer3.5.conv1.action_p3_bn1.bias: True
visual.layer3.5.conv1.action_p3_conv1.weight: True
visual.layer3.5.conv1.action_p3_expand.weight: True
visual.layer3.5.bn1.weight: True
visual.layer3.5.bn1.bias: True
visual.layer3.5.conv2.weight: True
visual.layer3.5.bn2.weight: True
visual.layer3.5.bn2.bias: True
visual.layer3.5.conv3.weight: True
visual.layer3.5.bn3.weight: True
visual.layer3.5.bn3.bias: True
visual.layer4.0.conv1.net.weight: True
visual.layer4.0.conv1.action_shift.weight: True
visual.layer4.0.conv1.action_p1_conv1.weight: True
visual.layer4.0.conv1.action_p2_squeeze.weight: True
visual.layer4.0.conv1.action_p2_conv1.weight: True
visual.layer4.0.conv1.action_p2_expand.weight: True
visual.layer4.0.conv1.action_p3_squeeze.weight: True
visual.layer4.0.conv1.action_p3_bn1.weight: True
visual.layer4.0.conv1.action_p3_bn1.bias: True
visual.layer4.0.conv1.action_p3_conv1.weight: True
visual.layer4.0.conv1.action_p3_expand.weight: True
visual.layer4.0.bn1.weight: True
visual.layer4.0.bn1.bias: True
visual.layer4.0.conv2.weight: True
visual.layer4.0.bn2.weight: True
visual.layer4.0.bn2.bias: True
visual.layer4.0.conv3.weight: True
visual.layer4.0.bn3.weight: True
visual.layer4.0.bn3.bias: True
visual.layer4.0.downsample.0.weight: True
visual.layer4.0.downsample.1.weight: True
visual.layer4.0.downsample.1.bias: True
visual.layer4.1.conv1.net.weight: True
visual.layer4.1.conv1.action_shift.weight: True
visual.layer4.1.conv1.action_p1_conv1.weight: True
visual.layer4.1.conv1.action_p2_squeeze.weight: True
visual.layer4.1.conv1.action_p2_conv1.weight: True
visual.layer4.1.conv1.action_p2_expand.weight: True
visual.layer4.1.conv1.action_p3_squeeze.weight: True
visual.layer4.1.conv1.action_p3_bn1.weight: True
visual.layer4.1.conv1.action_p3_bn1.bias: True
visual.layer4.1.conv1.action_p3_conv1.weight: True
visual.layer4.1.conv1.action_p3_expand.weight: True
visual.layer4.1.bn1.weight: True
visual.layer4.1.bn1.bias: True
visual.layer4.1.conv2.weight: True
visual.layer4.1.bn2.weight: True
visual.layer4.1.bn2.bias: True
visual.layer4.1.conv3.weight: True
visual.layer4.1.bn3.weight: True
visual.layer4.1.bn3.bias: True
visual.layer4.2.conv1.net.weight: True
visual.layer4.2.conv1.action_shift.weight: True
visual.layer4.2.conv1.action_p1_conv1.weight: True
visual.layer4.2.conv1.action_p2_squeeze.weight: True
visual.layer4.2.conv1.action_p2_conv1.weight: True
visual.layer4.2.conv1.action_p2_expand.weight: True
visual.layer4.2.conv1.action_p3_squeeze.weight: True
visual.layer4.2.conv1.action_p3_bn1.weight: True
visual.layer4.2.conv1.action_p3_bn1.bias: True
visual.layer4.2.conv1.action_p3_conv1.weight: True
visual.layer4.2.conv1.action_p3_expand.weight: True
visual.layer4.2.bn1.weight: True
visual.layer4.2.bn1.bias: True
visual.layer4.2.conv2.weight: True
visual.layer4.2.bn2.weight: True
visual.layer4.2.bn2.bias: True
visual.layer4.2.conv3.weight: True
visual.layer4.2.bn3.weight: True
visual.layer4.2.bn3.bias: True
visual.attnpool.positional_embedding: True
visual.attnpool.k_proj.weight: True
visual.attnpool.k_proj.bias: True
visual.attnpool.q_proj.weight: True
visual.attnpool.q_proj.bias: True
visual.attnpool.v_proj.weight: True
visual.attnpool.v_proj.bias: True
visual.attnpool.c_proj.weight: True
visual.attnpool.c_proj.bias: True
transformer.resblocks.0.attn.in_proj_weight: True
transformer.resblocks.0.attn.in_proj_bias: True
transformer.resblocks.0.attn.out_proj.weight: True
transformer.resblocks.0.attn.out_proj.bias: True
transformer.resblocks.0.ln_1.weight: True
transformer.resblocks.0.ln_1.bias: True
transformer.resblocks.0.mlp.c_fc.weight: True
transformer.resblocks.0.mlp.c_fc.bias: True
transformer.resblocks.0.mlp.c_proj.weight: True
transformer.resblocks.0.mlp.c_proj.bias: True
transformer.resblocks.0.ln_2.weight: True
transformer.resblocks.0.ln_2.bias: True
transformer.resblocks.1.attn.in_proj_weight: True
transformer.resblocks.1.attn.in_proj_bias: True
transformer.resblocks.1.attn.out_proj.weight: True
transformer.resblocks.1.attn.out_proj.bias: True
transformer.resblocks.1.ln_1.weight: True
transformer.resblocks.1.ln_1.bias: True
transformer.resblocks.1.mlp.c_fc.weight: True
transformer.resblocks.1.mlp.c_fc.bias: True
transformer.resblocks.1.mlp.c_proj.weight: True
transformer.resblocks.1.mlp.c_proj.bias: True
transformer.resblocks.1.ln_2.weight: True
transformer.resblocks.1.ln_2.bias: True
transformer.resblocks.2.attn.in_proj_weight: True
transformer.resblocks.2.attn.in_proj_bias: True
transformer.resblocks.2.attn.out_proj.weight: True
transformer.resblocks.2.attn.out_proj.bias: True
transformer.resblocks.2.ln_1.weight: True
transformer.resblocks.2.ln_1.bias: True
transformer.resblocks.2.mlp.c_fc.weight: True
transformer.resblocks.2.mlp.c_fc.bias: True
transformer.resblocks.2.mlp.c_proj.weight: True
transformer.resblocks.2.mlp.c_proj.bias: True
transformer.resblocks.2.ln_2.weight: True
transformer.resblocks.2.ln_2.bias: True
transformer.resblocks.3.attn.in_proj_weight: True
transformer.resblocks.3.attn.in_proj_bias: True
transformer.resblocks.3.attn.out_proj.weight: True
transformer.resblocks.3.attn.out_proj.bias: True
transformer.resblocks.3.ln_1.weight: True
transformer.resblocks.3.ln_1.bias: True
transformer.resblocks.3.mlp.c_fc.weight: True
transformer.resblocks.3.mlp.c_fc.bias: True
transformer.resblocks.3.mlp.c_proj.weight: True
transformer.resblocks.3.mlp.c_proj.bias: True
transformer.resblocks.3.ln_2.weight: True
transformer.resblocks.3.ln_2.bias: True
transformer.resblocks.4.attn.in_proj_weight: True
transformer.resblocks.4.attn.in_proj_bias: True
transformer.resblocks.4.attn.out_proj.weight: True
transformer.resblocks.4.attn.out_proj.bias: True
transformer.resblocks.4.ln_1.weight: True
transformer.resblocks.4.ln_1.bias: True
transformer.resblocks.4.mlp.c_fc.weight: True
transformer.resblocks.4.mlp.c_fc.bias: True
transformer.resblocks.4.mlp.c_proj.weight: True
transformer.resblocks.4.mlp.c_proj.bias: True
transformer.resblocks.4.ln_2.weight: True
transformer.resblocks.4.ln_2.bias: True
transformer.resblocks.5.attn.in_proj_weight: True
transformer.resblocks.5.attn.in_proj_bias: True
transformer.resblocks.5.attn.out_proj.weight: True
transformer.resblocks.5.attn.out_proj.bias: True
transformer.resblocks.5.ln_1.weight: True
transformer.resblocks.5.ln_1.bias: True
transformer.resblocks.5.mlp.c_fc.weight: True
transformer.resblocks.5.mlp.c_fc.bias: True
transformer.resblocks.5.mlp.c_proj.weight: True
transformer.resblocks.5.mlp.c_proj.bias: True
transformer.resblocks.5.ln_2.weight: True
transformer.resblocks.5.ln_2.bias: True
transformer.resblocks.6.attn.in_proj_weight: True
transformer.resblocks.6.attn.in_proj_bias: True
transformer.resblocks.6.attn.out_proj.weight: True
transformer.resblocks.6.attn.out_proj.bias: True
transformer.resblocks.6.ln_1.weight: True
transformer.resblocks.6.ln_1.bias: True
transformer.resblocks.6.mlp.c_fc.weight: True
transformer.resblocks.6.mlp.c_fc.bias: True
transformer.resblocks.6.mlp.c_proj.weight: True
transformer.resblocks.6.mlp.c_proj.bias: True
transformer.resblocks.6.ln_2.weight: True
transformer.resblocks.6.ln_2.bias: True
transformer.resblocks.7.attn.in_proj_weight: True
transformer.resblocks.7.attn.in_proj_bias: True
transformer.resblocks.7.attn.out_proj.weight: True
transformer.resblocks.7.attn.out_proj.bias: True
transformer.resblocks.7.ln_1.weight: True
transformer.resblocks.7.ln_1.bias: True
transformer.resblocks.7.mlp.c_fc.weight: True
transformer.resblocks.7.mlp.c_fc.bias: True
transformer.resblocks.7.mlp.c_proj.weight: True
transformer.resblocks.7.mlp.c_proj.bias: True
transformer.resblocks.7.ln_2.weight: True
transformer.resblocks.7.ln_2.bias: True
transformer.resblocks.8.attn.in_proj_weight: True
transformer.resblocks.8.attn.in_proj_bias: True
transformer.resblocks.8.attn.out_proj.weight: True
transformer.resblocks.8.attn.out_proj.bias: True
transformer.resblocks.8.ln_1.weight: True
transformer.resblocks.8.ln_1.bias: True
transformer.resblocks.8.mlp.c_fc.weight: True
transformer.resblocks.8.mlp.c_fc.bias: True
transformer.resblocks.8.mlp.c_proj.weight: True
transformer.resblocks.8.mlp.c_proj.bias: True
transformer.resblocks.8.ln_2.weight: True
transformer.resblocks.8.ln_2.bias: True
transformer.resblocks.9.attn.in_proj_weight: True
transformer.resblocks.9.attn.in_proj_bias: True
transformer.resblocks.9.attn.out_proj.weight: True
transformer.resblocks.9.attn.out_proj.bias: True
transformer.resblocks.9.ln_1.weight: True
transformer.resblocks.9.ln_1.bias: True
transformer.resblocks.9.mlp.c_fc.weight: True
transformer.resblocks.9.mlp.c_fc.bias: True
transformer.resblocks.9.mlp.c_proj.weight: True
transformer.resblocks.9.mlp.c_proj.bias: True
transformer.resblocks.9.ln_2.weight: True
transformer.resblocks.9.ln_2.bias: True
transformer.resblocks.10.attn.in_proj_weight: True
transformer.resblocks.10.attn.in_proj_bias: True
transformer.resblocks.10.attn.out_proj.weight: True
transformer.resblocks.10.attn.out_proj.bias: True
transformer.resblocks.10.ln_1.weight: True
transformer.resblocks.10.ln_1.bias: True
transformer.resblocks.10.mlp.c_fc.weight: True
transformer.resblocks.10.mlp.c_fc.bias: True
transformer.resblocks.10.mlp.c_proj.weight: True
transformer.resblocks.10.mlp.c_proj.bias: True
transformer.resblocks.10.ln_2.weight: True
transformer.resblocks.10.ln_2.bias: True
transformer.resblocks.11.attn.in_proj_weight: True
transformer.resblocks.11.attn.in_proj_bias: True
transformer.resblocks.11.attn.out_proj.weight: True
transformer.resblocks.11.attn.out_proj.bias: True
transformer.resblocks.11.ln_1.weight: True
transformer.resblocks.11.ln_1.bias: True
transformer.resblocks.11.mlp.c_fc.weight: True
transformer.resblocks.11.mlp.c_fc.bias: True
transformer.resblocks.11.mlp.c_proj.weight: True
transformer.resblocks.11.mlp.c_proj.bias: True
transformer.resblocks.11.ln_2.weight: True
transformer.resblocks.11.ln_2.bias: True
token_embedding.weight: True
ln_final.weight: True
ln_final.bias: True
  0% 0/14661 [00:00<?, ?it/s]/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
action debug 0: torch.Size([128, 64, 56, 56])
cuda:0
action debug 1:  torch.Size([128, 64, 56, 56])
action debug: 2 torch.Size([128, 64, 56, 56])
action debug: 3 torch.Size([128, 64, 56, 56])
action debug: 4 torch.Size([128, 64, 56, 56])
action debug: 5 torch.Size([128, 64, 56, 56])
conv3= Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
device= cuda:0
action debug 0: torch.Size([128, 256, 56, 56])
cuda:0
action debug 1:  torch.Size([128, 256, 56, 56])
action debug: 2 torch.Size([128, 256, 56, 56])
action debug: 3 torch.Size([128, 256, 56, 56])
action debug: 4 torch.Size([128, 256, 56, 56])
action debug: 5 torch.Size([128, 64, 56, 56])
conv3= Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
device= cuda:0
action debug 0: torch.Size([128, 256, 56, 56])
cuda:0
action debug 1:  torch.Size([128, 256, 56, 56])
action debug: 2 torch.Size([128, 256, 56, 56])
action debug: 3 torch.Size([128, 256, 56, 56])
action debug: 4 torch.Size([128, 256, 56, 56])
action debug: 5 torch.Size([128, 64, 56, 56])
conv3= Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
device= cuda:0
action debug 0: torch.Size([128, 256, 56, 56])
cuda:0
action debug 1:  torch.Size([128, 256, 56, 56])
action debug: 2 torch.Size([128, 256, 56, 56])
action debug: 3 torch.Size([128, 256, 56, 56])
action debug: 4 torch.Size([128, 256, 56, 56])
action debug: 5 torch.Size([128, 128, 56, 56])
conv3= Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
device= cuda:0
action debug 0: torch.Size([128, 512, 28, 28])
cuda:0
action debug 1:  torch.Size([128, 512, 28, 28])
action debug: 2 torch.Size([128, 512, 28, 28])
action debug: 3 torch.Size([128, 512, 28, 28])
action debug: 4 torch.Size([128, 512, 28, 28])
action debug: 5 torch.Size([128, 128, 28, 28])
conv3= Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
device= cuda:0
action debug 0: torch.Size([128, 512, 28, 28])
cuda:0
action debug 1:  torch.Size([128, 512, 28, 28])
action debug: 2 torch.Size([128, 512, 28, 28])
action debug: 3 torch.Size([128, 512, 28, 28])
action debug: 4 torch.Size([128, 512, 28, 28])
action debug: 5 torch.Size([128, 128, 28, 28])
conv3= Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
device= cuda:0
action debug 0: torch.Size([128, 512, 28, 28])
cuda:0
action debug 1:  torch.Size([128, 512, 28, 28])
action debug: 2 torch.Size([128, 512, 28, 28])
action debug: 3 torch.Size([128, 512, 28, 28])
action debug: 4 torch.Size([128, 512, 28, 28])
action debug: 5 torch.Size([128, 128, 28, 28])
conv3= Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
device= cuda:0
action debug 0: torch.Size([128, 512, 28, 28])
cuda:0
action debug 1:  torch.Size([128, 512, 28, 28])
action debug: 2 torch.Size([128, 512, 28, 28])
action debug: 3 torch.Size([128, 512, 28, 28])
action debug: 4 torch.Size([128, 512, 28, 28])
action debug: 5 torch.Size([128, 256, 28, 28])
conv3= Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
device= cuda:0
action debug 0: torch.Size([128, 1024, 14, 14])
cuda:0
action debug 1:  torch.Size([128, 1024, 14, 14])
action debug: 2 torch.Size([128, 1024, 14, 14])
action debug: 3 torch.Size([128, 1024, 14, 14])
action debug: 4 torch.Size([128, 1024, 14, 14])
action debug: 5 torch.Size([128, 256, 14, 14])
conv3= Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
device= cuda:0
action debug 0: torch.Size([128, 1024, 14, 14])
cuda:0
action debug 1:  torch.Size([128, 1024, 14, 14])
action debug: 2 torch.Size([128, 1024, 14, 14])
action debug: 3 torch.Size([128, 1024, 14, 14])
action debug: 4 torch.Size([128, 1024, 14, 14])
action debug: 5 torch.Size([128, 256, 14, 14])
conv3= Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
device= cuda:0
action debug 0: torch.Size([128, 1024, 14, 14])
cuda:0
action debug 1:  torch.Size([128, 1024, 14, 14])
action debug: 2 torch.Size([128, 1024, 14, 14])
action debug: 3 torch.Size([128, 1024, 14, 14])
action debug: 4 torch.Size([128, 1024, 14, 14])
action debug: 5 torch.Size([128, 256, 14, 14])
conv3= Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
device= cuda:0
action debug 0: torch.Size([128, 1024, 14, 14])
cuda:0
action debug 1:  torch.Size([128, 1024, 14, 14])
action debug: 2 torch.Size([128, 1024, 14, 14])
action debug: 3 torch.Size([128, 1024, 14, 14])
action debug: 4 torch.Size([128, 1024, 14, 14])
action debug: 5 torch.Size([128, 256, 14, 14])
conv3= Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
device= cuda:0
action debug 0: torch.Size([128, 1024, 14, 14])
cuda:0
action debug 1:  torch.Size([128, 1024, 14, 14])
action debug: 2 torch.Size([128, 1024, 14, 14])
action debug: 3 torch.Size([128, 1024, 14, 14])
action debug: 4 torch.Size([128, 1024, 14, 14])
action debug: 5 torch.Size([128, 256, 14, 14])
conv3= Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
device= cuda:0
action debug 0: torch.Size([128, 1024, 14, 14])
cuda:0
action debug 1:  torch.Size([128, 1024, 14, 14])
action debug: 2 torch.Size([128, 1024, 14, 14])
action debug: 3 torch.Size([128, 1024, 14, 14])
action debug: 4 torch.Size([128, 1024, 14, 14])
action debug: 5 torch.Size([128, 512, 14, 14])
conv3= Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
device= cuda:0
action debug 0: torch.Size([128, 2048, 7, 7])
cuda:0
action debug 1:  torch.Size([128, 2048, 7, 7])
action debug: 2 torch.Size([128, 2048, 7, 7])
action debug: 3 torch.Size([128, 2048, 7, 7])
action debug: 4 torch.Size([128, 2048, 7, 7])
action debug: 5 torch.Size([128, 512, 7, 7])
conv3= Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
device= cuda:0
action debug 0: torch.Size([128, 2048, 7, 7])
cuda:0
action debug 1:  torch.Size([128, 2048, 7, 7])
action debug: 2 torch.Size([128, 2048, 7, 7])
action debug: 3 torch.Size([128, 2048, 7, 7])
action debug: 4 torch.Size([128, 2048, 7, 7])
action debug: 5 torch.Size([128, 512, 7, 7])
conv3= Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
device= cuda:0
encoded image size:  torch.Size([128, 1024])
[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
image_embedding size:  torch.Size([16, 1024])
text_embedding size:  torch.Size([16, 1024])
/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/nn/functional.py:2741: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
  0% 0/14661 [00:17<?, ?it/s]
Traceback (most recent call last):
  File "/home/10501001/projects/ActionCLIP/train.py", line 265, in <module>
    main()
  File "/home/10501001/projects/ActionCLIP/train.py", line 241, in main
    total_loss.backward()
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/_tensor.py", line 255, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/10501001/anaconda3/envs/ACTION-CLIP/lib/python3.9/site-packages/torch/autograd/__init__.py", line 147, in backward
    Variable._execution_engine.run_backward(
RuntimeError: Expected to mark a variable ready only once. This error is caused by one of the following reasons: 1) Use of a module parameter outside the `forward` function. Please make sure model parameters are not shared across multiple concurrent forward-backward passes. or try to use _set_static_graph() as a workaround if this module graph does not change during training loop.2) Reused parameters in multiple reentrant backward passes. For example, if you use multiple `checkpoint` functions to wrap the same part of your model, it would result in the same set of parameters been used by different reentrant backward passes multiple times, and hence marking a variable ready multiple times. DDP does not support such use cases in default. You can try to use _set_static_graph() as a workaround if your module graph does not change over iterations.
Parameter at index 2 has been marked as ready twice. This means that multiple autograd engine  hooks have fired for this particular parameter during this iteration. You can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print parameter names for further debugging.

wandb: Waiting for W&B process to finish, PID 125025... (failed 1). Press ctrl-c to abort syncing.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.10MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.10MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.10MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.10MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.10MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.10MB uploaded (0.00MB deduped)wandb: \ 0.05MB of 0.10MB uploaded (0.00MB deduped)wandb: | 0.10MB of 0.10MB uploaded (0.00MB deduped)wandb: / 0.10MB of 0.10MB uploaded (0.00MB deduped)wandb: - 0.10MB of 0.10MB uploaded (0.00MB deduped)wandb: \ 0.10MB of 0.10MB uploaded (0.00MB deduped)wandb: | 0.10MB of 0.10MB uploaded (0.00MB deduped)wandb: / 0.10MB of 0.10MB uploaded (0.00MB deduped)wandb: - 0.10MB of 0.10MB uploaded (0.00MB deduped)wandb: \ 0.10MB of 0.10MB uploaded (0.00MB deduped)wandb: | 0.10MB of 0.10MB uploaded (0.00MB deduped)wandb: / 0.10MB of 0.10MB uploaded (0.00MB deduped)wandb: - 0.10MB of 0.10MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:                 lr 
wandb:    train_loss_imgs 
wandb:   train_loss_texts 
wandb:   train_total_loss 
wandb: 
wandb: Run summary:
wandb:                 lr 0.0
wandb:    train_loss_imgs 2.70117
wandb:   train_loss_texts 2.69141
wandb:   train_total_loss 2.69531
wandb: 
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced 20211031_114337_clip_k400_RN50_kinetics400: https://wandb.ai/wozzq/clip_k400/runs/2svu53m0
wandb: Find logs at: ./wandb/run-20211031_114342-2svu53m0/logs/debug.log
wandb: 
